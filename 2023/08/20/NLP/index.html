

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="NGC6302">
  <meta name="keywords" content="">
  
    <meta name="description" content="BASE参考链接 NLP_course unigram tokenization12345678910111213141516171819202122232425262728293031323334353637383940def encode_word(word, model):    best_segmentations &#x3D; [&amp;#123;&quot;start&quot;: 0, &quot;">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP&amp;&amp;LLM">
<meta property="og:url" content="http://example.com/2023/08/20/NLP/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="BASE参考链接 NLP_course unigram tokenization12345678910111213141516171819202122232425262728293031323334353637383940def encode_word(word, model):    best_segmentations &#x3D; [&amp;#123;&quot;start&quot;: 0, &quot;">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-08-20T13:39:49.000Z">
<meta property="article:modified_time" content="2023-09-15T06:41:55.171Z">
<meta property="article:author" content="NGC6302">
<meta property="article:tag" content="NLP_hug">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>NLP&amp;&amp;LLM - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.5-a","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="NLP&amp;&amp;LLM"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-08-20 21:39" pubdate>
          2023年8月20日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          43k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          362 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">NLP&amp;&amp;LLM</h1>
            
            
              <div class="markdown-body">
                
                <h2 id="BASE"><a href="#BASE" class="headerlink" title="BASE"></a>BASE</h2><p>参考链接 <a target="_blank" rel="noopener" href="https://huggingface.co/learn/nlp-course/">NLP_course</a></p>
<h3 id="unigram-tokenization"><a href="#unigram-tokenization" class="headerlink" title="unigram tokenization"></a>unigram tokenization</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">encode_word</span>(<span class="hljs-params">word, model</span>):<br>    best_segmentations = [&#123;<span class="hljs-string">&quot;start&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-number">1</span>&#125;] + [<br>        &#123;<span class="hljs-string">&quot;start&quot;</span>: <span class="hljs-literal">None</span>, <span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-literal">None</span>&#125; <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(word))<br>    ]<br>    <span class="hljs-comment">#至少每一种字长都有留下来对应的一个值.同时在位次上对应END,里面的start对应了在这个END中,在哪里有最好的分词的方法.</span><br>    <span class="hljs-keyword">for</span> start_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(word)):<br>        <span class="hljs-comment"># This should be properly filled by the previous steps of the loop</span><br>        best_score_at_start = best_segmentations[start_idx][<span class="hljs-string">&quot;score&quot;</span>]<br>        <span class="hljs-keyword">for</span> end_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(start_idx + <span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(word) + <span class="hljs-number">1</span>):<br>            token = word[start_idx:end_idx] <span class="hljs-comment"># toke截取了一组值,之后通过查表进行比较</span><br>            <span class="hljs-keyword">if</span> token <span class="hljs-keyword">in</span> model <span class="hljs-keyword">and</span> best_score_at_start <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                score = model[token] + best_score_at_start<br>                <span class="hljs-comment"># If we have found a better segmentation ending at end_idx, we update</span><br>                <span class="hljs-keyword">if</span> (<br>                    best_segmentations[end_idx][<span class="hljs-string">&quot;score&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span><br>                    <span class="hljs-keyword">or</span> best_segmentations[end_idx][<span class="hljs-string">&quot;score&quot;</span>] &gt; score<br>                ):<br>                <span class="hljs-comment">#这里取的是-log相当于是一个递减的函数,如果频率高,反而得到的值越低,所以这里选择高频率的留下,</span><br>                <span class="hljs-comment">#关于继承前面的值,这里的含义指的是:start end都含有一定的值,start的分词+新增的词块频率够高的情况才更新END的模块</span><br>                <span class="hljs-comment">#下面对应了两种情况,一种是后续没有end_idx直接打上标签 另一种是在当前的start + 增的 比后续的低则更改??</span><br>                    best_segmentations[end_idx] = &#123;<span class="hljs-string">&quot;start&quot;</span>: start_idx, <span class="hljs-string">&quot;score&quot;</span>: score&#125;<br><br>    segmentation = best_segmentations[-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">if</span> segmentation[<span class="hljs-string">&quot;score&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-comment"># We did not find a tokenization of the word -&gt; unknown</span><br>        <span class="hljs-keyword">return</span> [<span class="hljs-string">&quot;&lt;unk&gt;&quot;</span>], <span class="hljs-literal">None</span><br><br>    score = segmentation[<span class="hljs-string">&quot;score&quot;</span>]<br>    start = segmentation[<span class="hljs-string">&quot;start&quot;</span>]<br>    end = <span class="hljs-built_in">len</span>(word)<br>    tokens = []<br>    <span class="hljs-keyword">while</span> start != <span class="hljs-number">0</span>:<br>        tokens.insert(<span class="hljs-number">0</span>, word[start:end])<br>        next_start = best_segmentations[start][<span class="hljs-string">&quot;start&quot;</span>]<br>        end = start<br>        start = next_start<br>    tokens.insert(<span class="hljs-number">0</span>, word[start:end])<br>    <span class="hljs-keyword">return</span> tokens, score<br><span class="hljs-comment"># 但是为什么是最后的一个?</span><br></code></pre></td></tr></table></figure>

<h2 id="MAIN-NLP-TASKS"><a href="#MAIN-NLP-TASKS" class="headerlink" title="MAIN NLP TASKS"></a>MAIN NLP TASKS</h2><h3 id="Token-classification"><a href="#Token-classification" class="headerlink" title="Token classification"></a>Token classification</h3><h4 id="preparing-the-data"><a href="#preparing-the-data" class="headerlink" title="preparing the data"></a>preparing the data</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br>raw_datasets = load_dataset(<span class="hljs-string">&quot;conll2003&quot;</span>)<br><br><span class="hljs-comment"># 数据形式</span><br><br>DatasetDict(&#123;<br>    train: Dataset(&#123;<br>        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],<br>        num_rows: <span class="hljs-number">14041</span><br>    &#125;)<br>    validation: Dataset(&#123;<br>        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],<br>        num_rows: <span class="hljs-number">3250</span><br>    &#125;)<br>    test: Dataset(&#123;<br>        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],<br>        num_rows: <span class="hljs-number">3453</span><br>    &#125;)<br>&#125;)<br><span class="hljs-comment">#the last column is called tokens, but it contains words in the sense that these are pre-tokenized inputs that still need to go through the tokenizer for subword tokenization</span><br><br><span class="hljs-comment"># 数据形式</span><br>ner_feature = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].features[<span class="hljs-string">&quot;ner_tags&quot;</span>]<br><br><span class="hljs-type">Sequence</span>(feature=ClassLabel(num_classes=<span class="hljs-number">9</span>, names=[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>, <span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;I-ORG&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;I-LOC&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>), length=-<span class="hljs-number">1</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)<br><br><span class="hljs-comment"># 表示这里的训练队列的类型</span><br></code></pre></td></tr></table></figure>
<p>解构数据表示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>words = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;tokens&quot;</span>]<br>labels = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]<br>line1 = <span class="hljs-string">&quot;&quot;</span><br>line2 = <span class="hljs-string">&quot;&quot;</span><br><span class="hljs-keyword">for</span> word, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(words, labels):<span class="hljs-comment">#不仅取出了两个列表中的元素,同时把这两个对应的数组压缩成元组</span><br>    full_label = label_names[label]<br>    max_length = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">len</span>(word), <span class="hljs-built_in">len</span>(full_label))<br>    line1 += word + <span class="hljs-string">&quot; &quot;</span> * (max_length - <span class="hljs-built_in">len</span>(word) + <span class="hljs-number">1</span>)<br>    line2 += full_label + <span class="hljs-string">&quot; &quot;</span> * (max_length - <span class="hljs-built_in">len</span>(full_label) + <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<h4 id="数据加工"><a href="#数据加工" class="headerlink" title="数据加工"></a>数据加工</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>model_checkpoint = <span class="hljs-string">&quot;bert-base-cased&quot;</span><br>tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)<br><br>inputs = tokenizer(raw_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;tokens&quot;</span>],is_split_into_words = <span class="hljs-literal">True</span>)<br><br>inputs.word_ids()<span class="hljs-comment">#可以正确的对齐每一个tokens的单词的位置</span><br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#这个函数相当于分裂同时打上标签</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">align_labels_with_tokens</span>(<span class="hljs-params">labels,word_ids</span>):<br>    <span class="hljs-comment">#labels是来自于ner_tags</span><br>    new_labels = []<br>    current_word = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">for</span> word_id <span class="hljs-keyword">in</span> word_ids:<br>        <span class="hljs-keyword">if</span> word_id != current_word:<span class="hljs-comment">#区分是否是一个新的单词</span><br>            current_word = word_id<br>            label = -<span class="hljs-number">100</span> <span class="hljs-keyword">if</span> word_id <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> labels[word_id]<br>            new_labels.append(label)<span class="hljs-comment">#放入新的label</span><br>        <span class="hljs-keyword">elif</span> word_id = <span class="hljs-literal">None</span>:<br>            new_labels.append(-<span class="hljs-number">100</span>)<br>        <span class="hljs-keyword">else</span>:<br>            label = labels[word_id]<span class="hljs-comment">#是在当前的labels中</span><br>            <span class="hljs-keyword">if</span> label % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>:<br>                label += <span class="hljs-number">1</span> <span class="hljs-comment">#相当于把B中的值转换为I,如果是同一个单词的情况下</span><br>            new_labels.append(label)<br>    <span class="hljs-keyword">return</span> new_labels<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_and_align_labels</span>(<span class="hljs-params">examples</span>):<br>    tokenized_inputs = tokenizer(examples[<span class="hljs-string">&quot;tokens&quot;</span>],truncation = <span class="hljs-literal">True</span>, is_split_into_words =<span class="hljs-literal">True</span>)<br>    all_labels = example[<span class="hljs-string">&quot;ner_tags&quot;</span>]<br>    new_labels = []<br>    <span class="hljs-keyword">for</span> i,labels <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(all_labels):<br>        word_ids = tokenized_inputs.word_ids(i)<br>        new_labels.append(align_labels_with_tokens(labels,word_ids))<br>    <br>    tokenized_input[<span class="hljs-string">&quot;labels&quot;</span>] = new_labels<br>    <span class="hljs-keyword">return</span> tokenized_inputs<br><br><span class="hljs-comment">#这里基本相当于是在下面进行了调用,但是这里仍然没有完成把所有的对齐附带上padding</span><br><br><span class="hljs-comment">#以下完成数据集的训练</span><br>tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(<br>    tokenize_and_align_labels,<span class="hljs-comment">#这里的原理应该相当于直接把这个raw数据集传入进去,然后直接依照相关的函数进行输出</span><br>    batched = <span class="hljs-literal">True</span>,<br>    remove_columns = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].column_names,<span class="hljs-comment">#这里相当于把训练后的这一列删除掉</span><br>)<br><br></code></pre></td></tr></table></figure>

<h4 id="Fine-tuning-the-modle-with-trainer-API"><a href="#Fine-tuning-the-modle-with-trainer-API" class="headerlink" title="Fine-tuning the modle with trainer API"></a>Fine-tuning the modle with trainer API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForTokenClassification<br>data_collator = DataClollatorForTokenClassification(tokenizer = tokenizer)<br><span class="hljs-comment">#这里没有对齐的值默认打上了-100的标签</span><br></code></pre></td></tr></table></figure>

<h4 id="Metrics-度量指标"><a href="#Metrics-度量指标" class="headerlink" title="Metrics 度量指标"></a>Metrics 度量指标</h4><p>利用seqeval进行度量该指标</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> evalutate<br>metric = evaluate.load(<span class="hljs-string">&quot;seqeval&quot;</span>)<br><br>labels = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]<br>labels = [label_names[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> labels]<br><span class="hljs-comment">#这里相当于把原先的偏移寻址转换成了正常的可读入字符串的形式</span><br>predictions = labels.copy()<br>predictions[<span class="hljs-number">2</span>] = <span class="hljs-string">&quot;0&quot;</span><br>metric.compute(predictions= [predictions],reference = [labels])<br></code></pre></td></tr></table></figure>

<p>计算度量函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrcis</span>(<span class="hljs-params">eval_preds</span>):<br>    logis,labels = eval_preds<br>    predictions = np.argmax(logits,axis =-<span class="hljs-number">1</span>)<span class="hljs-comment">#true 是真的值,prediction是一个以训练结果导出来的值</span><br>    true_labels = [[label_namse[l] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> label <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels] <span class="hljs-comment"># 啥?</span><br>    true_predictions = [ [label_name[p] <span class="hljs-keyword">for</span> (p,l) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction,label) <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>] <span class="hljs-keyword">for</span> prediction,label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions,labels)]<br>    all_metrics = metrci.compute(predictions = ture_predictions, references = true_labels)<br><br></code></pre></td></tr></table></figure>

<h4 id="defining-the-Model"><a href="#defining-the-Model" class="headerlink" title="defining the Model"></a>defining the Model</h4><p>设置一个相反的字典</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">id2label = &#123;i:label <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(label_names)&#125;<br>lable2id = &#123;v,k <span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> id2label.items()&#125;<br></code></pre></td></tr></table></figure>
<p>在传入相关的模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification<br>model = AutoModelForTokenClassification.from_pretrained(<br>    model_checkpoint,<br>    id2label = id2label<br>    label2id = label2id<br>)<br></code></pre></td></tr></table></figure>

<h4 id="Fine-tuning-the-model"><a href="#Fine-tuning-the-model" class="headerlink" title="Fine-tuning the model"></a>Fine-tuning the model</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login<br>notebook_login()<br><span class="hljs-comment">#调用训练参数</span><br><span class="hljs-keyword">from</span> transformes <span class="hljs-keyword">import</span> TrainingArguments<br>args = TrainingArguments(<br>    <span class="hljs-string">&quot;bert-finetune-ner&quot;</span>,<br>    evaluation_strategy = <span class="hljs-string">&quot;epoch&quot;</span>,<br>    save_strategy = <span class="hljs-string">&quot;epoch&quot;</span>,<br>    learning_rate = <span class="hljs-number">2e05</span>,<br>    num_train_epochs= <span class="hljs-number">3</span><br>    weight_decay= <span class="hljs-number">0.01</span>.<br>    push_to_hub = <span class="hljs-literal">True</span>,<br>)<br><span class="hljs-comment">#构建一个trainer</span><br><span class="hljs-keyword">from</span>  transformers <span class="hljs-keyword">import</span> Trainer<br><br>trainer = Trainer(<br>    model = model,<br>    args =args,<br>    train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],<br>    eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],<br>    data_collator = data_collator,<br>    compyte_metrics= compute_metrics,<br>    tokenizer = tokenizer,<br>)<br>trainer.train()<br>trainer.push_to_hub(commit_message= <span class="hljs-string">&quot;Training complete&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>以上的模型在每一次训练的时候,都会上传到hub中</p>
<h4 id="传统的训练流程举例"><a href="#传统的训练流程举例" class="headerlink" title="传统的训练流程举例"></a>传统的训练流程举例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>train_dataloader = DataLoader(<br>    tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],<br>    shuffle = <span class="hljs-literal">True</span>,<br>    collate_fn = data_collator,<br>    batch_size = <span class="hljs-number">8</span>,<br><br>)<br>eval_dataloader = DataLoader(<br>    tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],<br>    collate_fn= data_collator,<br>    batch_size = <span class="hljs-number">8</span><br>)<br><br><span class="hljs-comment">#构建模型</span><br><br>model = AutoModelForTokenXlassification.from_pretrained(<br>    model_checkpoint,<br>    id2label = id2label,<br>    label2id  = label2id,<br>)<br><br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW<br>optimizer = AdamW(model.parameters(),lr= <span class="hljs-number">2e-5</span>)<br><br><span class="hljs-comment">#加速器模块</span><br><br><span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator<br>accelerator = Accelerator()<br>modle,optimizer,train_dataloader,eval_dataloader = accelerator.prepare(<br>    modle,optimizer,train_dataloader,eval_dataloader<br>)<br><br><span class="hljs-comment">#???</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler<br>num_train_epochs = <span class="hljs-number">3</span><br>num_update_steps_per_epoch = <span class="hljs-built_in">len</span>(train_dataloader)<br>num_training_steps = num_train_epochs * num_update_steps_per_epoch <span class="hljs-comment">#全部训练完的epoch</span><br>lr_scheduler = get_scheduler(<br>    <span class="hljs-string">&quot;linear&quot;</span>,<br>    optimizer = optimizer.<br>    num_warmup_steps = <span class="hljs-number">0</span>,<br>    num_training_steps = num_training_steps<br>)<br><br></code></pre></td></tr></table></figure>

<h4 id="上传到仓库"><a href="#上传到仓库" class="headerlink" title="上传到仓库"></a>上传到仓库</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository,get_full_repo_name<br>model_name = <span class="hljs-string">&quot;bert-finetune-ner-accelerate&quot;</span><br>repo_name = get_full_repo_name(model_name)<span class="hljs-comment">#加上原来的地址.</span><br><br></code></pre></td></tr></table></figure>

<h4 id="Train-loop"><a href="#Train-loop" class="headerlink" title="Train loop"></a>Train loop</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">postprocess</span>(<span class="hljs-params">predictions,labels</span>):<br>    predictions = predictions.detach().cpu().clone().numpy()<br>    labels = labels.detach().cpu().clone().numpy()<br>    <span class="hljs-comment">#从GPU中拷贝数据并转换为numpy数据</span><br><br>    true_labels = [ [label_names[l] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> label <span class="hljs-keyword">if</span> l != <span class="hljs-number">100</span>] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels]<br>    true_predictions = [ [label_names[p] <span class="hljs-keyword">for</span> (p,l) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction,label) <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>]<br>    <span class="hljs-keyword">for</span> prediction , label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, labels)]<br>    <span class="hljs-keyword">return</span> true_labels,true_predictions<br><br><span class="hljs-comment">#训练中</span><br><span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> torch<br>progress_bar = tqdm((<span class="hljs-built_in">range</span>(num_training_steps)))<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_train_epochs):<br>    model.train()<br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:<br>        outputs = model(**batch)<br>        loss = outputs.loss<br>        accelerator.backward(loss)<br>        optimizer.step()<br>        lr_scheduler.step()<br>        optimizer.zero_grad()<br>        progress_bar.update(<span class="hljs-number">1</span>)<br>    <br>    model.<span class="hljs-built_in">eval</span>()<br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> eval_dataloader:<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            outputs = model(**batch)<br>        <br>        predictions = outputs/logits.argmax(dim=-<span class="hljs-number">1</span>)<br>        labels = batch[<span class="hljs-string">&quot;labels&quot;</span>]<br></code></pre></td></tr></table></figure>

<p>部分跳过🤣👉🏻🤡</p>
<h3 id="Fine-tuning-a-masked-language-model"><a href="#Fine-tuning-a-masked-language-model" class="headerlink" title="Fine-tuning a masked language model"></a>Fine-tuning a masked language model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMaskedLM<br>model_checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased&quot;</span><br>model = AutoModelForMaskedLM.from_pretrained(model_Checkpoint)<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br>tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)<br><br><span class="hljs-keyword">import</span> torch<br>inputs = tokenizer(text,return_tensors= <span class="hljs-string">&quot;pt&quot;</span>)<span class="hljs-comment">#按照pytorch张量输出</span><br>token_logits = modle(**inputs).logits<br>mask_token_index = torch.where(inputs[input_ids]== tokenizer.mask_token_id)[<span class="hljs-number">1</span>]<br>mask_token_logits = token_logits[<span class="hljs-number">0</span>,mask_token_index,:]<br>top_5_token = torch.topk(mask_token_logits,<span class="hljs-number">5</span>,dim = <span class="hljs-number">1</span>).indices[<span class="hljs-number">0</span>],tolist()<br><br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>imdb_dataset = load_dataset(<span class="hljs-string">&quot;imdb&quot;</span>)<br>sample = imdb_dataset[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>))<br><span class="hljs-comment">#注意可以通过数据集的特定部分的.shuffle来选择打乱数据集</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):<br>    result = tokenizer(examples[<span class="hljs-string">&quot;text&quot;</span>])<br>    <span class="hljs-keyword">if</span> tokenizer.is_fast:<br>        result[<span class="hljs-string">&quot;word_ids&quot;</span>] = [result.word_ids(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(result[<span class="hljs-string">&quot;input_ids&quot;</span>]))] <span class="hljs-comment">#word_ids相当于分词器映射到了第几个单词上面 这里相当于对于不同的句子组建立了不同的值</span><br>    <span class="hljs-keyword">return</span> result<br><br>tokenizer.model_max_length <span class="hljs-comment"># 分词器最大的文本容纳量</span><br><br><span class="hljs-comment">#连锁</span><br>tokenized_samples = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][:<span class="hljs-number">3</span>]<br><span class="hljs-keyword">for</span> idx,sample <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tokenized_samples[<span class="hljs-string">&quot;input_ids&quot;</span>]):<br>    <span class="hljs-built_in">print</span>(f <span class="hljs-string">&quot;&gt;&gt;&#123;ids&#125;&quot;</span>)<br><br><br>concatenated_examples = &#123;<br>    <span class="hljs-comment">#以下相当于把多个不同的列表合成为一个共同的列表</span><br>    k:<span class="hljs-built_in">sum</span>(tokenized_samples[k],[]) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> examples.keys()<span class="hljs-comment">#生成字典的键的值</span><br>&#125;<span class="hljs-comment"># k是一系列的键</span><br>total_length = <span class="hljs-built_in">len</span>(concatenated_examples[<span class="hljs-string">&quot;input_ids&quot;</span>]) <span class="hljs-comment">#951</span><br><br>Chunk = &#123;<br>    k:[t[i:i+chunk_size] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,total_length,chunk_size)]<br>    <span class="hljs-keyword">for</span> k ,t <span class="hljs-keyword">in</span> concatenated_exampls.items() <span class="hljs-comment">#相当于元素的整合再按照chunk_size的切割</span><br>&#125;<br><br><br><br></code></pre></td></tr></table></figure>
<p><strong>同时对于最后一个chunk出现的不均匀的情况,采用直接填充,或者直接丢弃的方法</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">group_texts</span>(<span class="hljs-params">examples</span>):<br>    concatenated_examples = &#123;k:<span class="hljs-built_in">sum</span>(examples[k],[]) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> examples.keys()&#125;<br>    total_length = <span class="hljs-built_in">len</span>(concatenated_examples[<span class="hljs-built_in">list</span>(examples.keys())[<span class="hljs-number">0</span>]])<br>    total_length = (total_length // chunk_size) *chunk_size<br><br>    result = &#123;<br>        k:[t[i:i+chunk_size]<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,total_legth,chunk_size)] <span class="hljs-keyword">for</span> k,t inconcatenated_examples.items()<br>    &#125;<br><br>    result[<span class="hljs-string">&quot;labels&quot;</span>]= result[<span class="hljs-string">&quot;input_ids&quot;</span>].copy()<br>    <span class="hljs-keyword">return</span> result<br><br>lm_datasets = tokenzied_datasets.<span class="hljs-built_in">map</span>(group_texts,batched = <span class="hljs-literal">True</span>)    <br><br></code></pre></td></tr></table></figure>

<h4 id="Fine-tuning-DistilBERt-with-the-Trainer-API"><a href="#Fine-tuning-DistilBERt-with-the-Trainer-API" class="headerlink" title="Fine-tuning DistilBERt with the Trainer API"></a>Fine-tuning DistilBERt with the Trainer API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformer <span class="hljs-keyword">import</span> DataCollatorForlanguageModeling<br>data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer,mlm_probability = <span class="hljs-number">0.15</span> )<br><br>samples = [lm_dataset[<span class="hljs-string">&quot;train&quot;</span>][i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>)]<br><span class="hljs-keyword">for</span> sample <span class="hljs-keyword">in</span> samples:<br>    _ = sample.popp(<span class="hljs-string">&quot;word_ids&quot;</span>) <span class="hljs-comment">#这个会弹出key对应的value 并删除这个键对值</span><br><br><span class="hljs-keyword">import</span> collections<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> default_data_collator<br><br>ww_prolbability = <span class="hljs-number">0.2</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">whole_word_masking_data_collator</span>(<span class="hljs-params">features</span>):<br>    <span class="hljs-comment">#features是最外的字典</span><br>    <span class="hljs-comment">#feature是 键对值</span><br>    <span class="hljs-keyword">for</span> feature <span class="hljs-keyword">in</span> features:<br>        word_ids = feature.pop(<span class="hljs-string">&quot;word_ids&quot;</span>)<br>        mapping = collections.defaultdict(<span class="hljs-built_in">list</span>) <span class="hljs-comment">#mapping内部元素是一种列表</span><br>        current_word_index = -<span class="hljs-number">1</span><br>        current_word = <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">for</span> idx,word_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(word_ids):<br>            <span class="hljs-keyword">if</span> word_id <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                <span class="hljs-keyword">if</span> word_id != current_word:<br>                    current_word = word_id<br>                    <span class="hljs-comment">#单词数量加1</span><br>                    current_word_index += <span class="hljs-number">1</span><br>                mapping[current_word_index].append(idx)<span class="hljs-comment">#在当前单词的位置上映射对应的token的位置</span><br>    <span class="hljs-comment"># 随机的遮蔽相关的字符</span><br>    mask = np.random.binomial(<span class="hljs-number">1</span>,wwm_probability,(<span class="hljs-built_in">len</span>(mapping))) <span class="hljs-comment">#在mapping上的每一个元素都做二项分布,概率有wwm生成,同时生成一个列表 含有1,0等元素 </span><br>    <span class="hljs-comment">#这里满足了一整个单词遮蔽的方式</span><br><br><br>    <span class="hljs-comment">#同时原来的labels和input_ids都是保留一样的值</span><br>    input_ids = feature[<span class="hljs-string">&quot;input_ids&quot;</span>] <br>    labels = feautre[<span class="hljs-string">&quot;labels&quot;</span>]<br>    new_labels = [-<span class="hljs-number">100</span>] *<span class="hljs-built_in">len</span>(labels) <span class="hljs-comment">#创建一个长度为len 每一个元素都是[ -100]的列表 , </span><br>    <span class="hljs-keyword">for</span> word_id <span class="hljs-keyword">in</span> np.where(mask)[<span class="hljs-number">0</span>]: <span class="hljs-comment">#当作布尔行代数来看</span><br>        word_id = word_id.item()<br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> mapping[word_id]:<br>            new_labels[idx] = labels[idx] <span class="hljs-comment">#其他的默认是-100? 这里保留着遮蔽的那些词?</span><br>            input_ids[idx] = tokenizer.mask_token_id <span class="hljs-comment">#这里应该是相当于遮蔽了?</span><br><br>    feature[<span class="hljs-string">&quot;labels&quot;</span>] = new_labels<br><br>    <span class="hljs-keyword">return</span> default_data_collator(features)<br><br>train_size =<span class="hljs-number">10_000</span><br>test_size = <span class="hljs-built_in">int</span>(<span class="hljs-number">0.1</span> * train_size) <span class="hljs-comment">#int() 表示类型转换为整数</span><br><br>downsampled_dataset = lm_datasets[<span class="hljs-string">&quot;train&quot;</span>].train_test_split(<br>    train_size = train_size, test_size=test_size, seed = <span class="hljs-number">42</span><br>)<br><br></code></pre></td></tr></table></figure>

<h4 id="训练数据库"><a href="#训练数据库" class="headerlink" title="训练数据库"></a>训练数据库</h4><p>给trainer定义参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transfromers <span class="hljs-keyword">import</span> TrainingArguments<br><br>batch_size = <span class="hljs-number">64</span><br>logging_steps = <span class="hljs-built_in">len</span>(downsampled_dataset[<span class="hljs-string">&quot;train&quot;</span>]) //batch_size<br>model_name = model_checkpoint.split(<span class="hljs-string">&quot;/&quot;</span>)[-<span class="hljs-number">1</span>] <span class="hljs-comment">#按照/的形式切割,并取出最后一个值</span><br>training_args = TrainingArguments(<br>    output_dir = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;model_name&#125;</span>-finetune-immdb&quot;</span>,<br>    overwrite_output_dir = <span class="hljs-literal">True</span>,<br>    evaluation_strategy = <span class="hljs-string">&quot;epocoh&quot;</span>,<br>    learning_rate = <span class="hljs-number">2e-5</span>,<br>    weight_decay = <span class="hljs-number">0.01</span>,<br>    per_device_train_batch_size = batch_size,<br>    per_device_eval_batch_size = batch_size,<br>    push_to_hub = <span class="hljs-literal">True</span>,<br>    fp16 = <span class="hljs-literal">True</span>,<br>    logging_steps = logging_steps,<br>)<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer<br>trainer = Trainer(<br>    model = model,<br>    args = training_args,<br>    train_dataset = downsampled_dataset[<span class="hljs-string">&quot;train&quot;</span>],<br>    eval_dataselt = downsampled_dataset[<span class="hljs-string">&quot;test&quot;</span>],<br>    data_collator = data_collator,<br>    tokenizer = tokenizer,<br>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">insert_random_mask</span>(<span class="hljs-params">batch</span>):<br>    features = [<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(batch,t)) <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(*batch.values())] <br>    <span class="hljs-comment">#zip(*batch.value())会对一个key的东西压缩成为一个元组通常，它用于将多个列表或序列的元素按照相同索引位置配对在一起。 </span><br>    <span class="hljs-comment">#t相当于是一个元组, 用每一个key和元组中的元素进行配对</span><br>    masked_inputs = data_collator(features)<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;masked_&quot;</span>+k:v.numpy()<span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> masked_inputs.items()&#125;<br>    <span class="hljs-comment">#这个相当于在原字典之前加上“masked_&quot;的前缀</span><br><br>downsampled_dataset = downsampled_dataset.remove_columns([<span class="hljs-string">&quot;word_ids&quot;</span>])<br>eval_dataset = downsampled_dataset[<span class="hljs-string">&quot;test&quot;</span>].<span class="hljs-built_in">map</span>(<br>    insert_random_mask,<br>    batched = <span class="hljs-literal">True</span>,<br>    remove_columns = downsampled_dataset[<span class="hljs-string">&quot;test&quot;</span>].column_names,<br>)<br><br>eval_dataset = eval_dataset.rename_columns(<br>    &#123;<br>        <span class="hljs-string">&quot;masked_input_ids&quot;</span>: <span class="hljs-string">&quot;input_ids&quot;</span>,<br>        <span class="hljs-string">&quot;masked_attention_mask&quot;</span>: <span class="hljs-string">&quot;attention_mask&quot;</span>,<br>        <span class="hljs-string">&quot;masked_labels&quot;</span>: <span class="hljs-string">&quot;labels&quot;</span>,<br>    &#125;<br>)<br><br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> default_data_collator<br><br>batch_size =<span class="hljs-number">64</span><br>train_dataloader = DataLoader(<br>    downsampled_dataset[<span class="hljs-string">&quot;train&quot;</span>],<br>    shuffle = <span class="hljs-literal">True</span>,<br>    batch_size = batch_size,<br>    collate_fn = data_collator<br>)<br><br>eval_dataloader = DataLoader(<br>    eval_dataset,batch_size = batch_size.collate_fn = default_data_collator<br>)<br><br>model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW<br>optimizer = AdamW(model.parameters(),lr= <span class="hljs-number">5e-5</span>)<br><br><span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator<br><br>accelerator = Accelerator()<br>model,optimizer,train_dataloader,eval_dataloader = accelerator.prepare(<br>    model,optimizer,train_dataloader,eval_dataloader<br>)<br><br></code></pre></td></tr></table></figure>

<h3 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h3><h4 id="loaddata"><a href="#loaddata" class="headerlink" title="loaddata"></a>loaddata</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br>raw_datasets = load_dataset(<span class="hljs-string">&quot;kde4&quot;</span>, lang1=<span class="hljs-string">&quot;en&quot;</span>, lang2=<span class="hljs-string">&quot;fr&quot;</span>)<br>split_datasets = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].train_test_split(train_size=<span class="hljs-number">0.9</span>, seed=<span class="hljs-number">20</span>) <span class="hljs-comment">#选择训练集和测试集</span><br><br>split_datasets[<span class="hljs-string">&quot;validation&quot;</span>] = split_datasets.pop(<span class="hljs-string">&quot;test&quot;</span>) <span class="hljs-comment">#重命名</span><br><br>split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>] <span class="hljs-comment">#两种id 和translation-&gt;字典 同时en,fr</span><br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>model_checkpoint = <span class="hljs-string">&quot;Helsinki-NLP/opus-mt-en-fr&quot;</span><br>translator = pipeline(<span class="hljs-string">&quot;translation&quot;</span>, model=model_checkpoint)<br>translator(<span class="hljs-string">&quot;Default to expanded threads&quot;</span>)<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>model_checkpoint = <span class="hljs-string">&quot;Helsinki-NLP/opus-mt-en-fr&quot;</span><br>tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br><br><span class="hljs-comment">#tokenizer完成</span><br><br>en_sentence = split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>][<span class="hljs-string">&quot;en&quot;</span>]<br>fr_sentence = split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>][<span class="hljs-string">&quot;fr&quot;</span>]<br><br>inputs = tokenizer(en_sentence, text_target=fr_sentence)<br><br><span class="hljs-comment">#input结果生成</span><br>&#123;<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">47591</span>, <span class="hljs-number">12</span>, <span class="hljs-number">9842</span>, <span class="hljs-number">19634</span>, <span class="hljs-number">9</span>, <span class="hljs-number">0</span>], <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&#x27;labels&#x27;</span>: [<span class="hljs-number">577</span>, <span class="hljs-number">5891</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3184</span>, <span class="hljs-number">16</span>, <span class="hljs-number">2542</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1710</span>, <span class="hljs-number">0</span>]&#125;<br><span class="hljs-comment">#没有理解错误的情况下:input_ids应该用的是对应的每一个单词在语料库的位置,labels对应的法语的位置 #同时这个注意要指定参数</span><br><span class="hljs-built_in">print</span>(tokenizer.convert_ids_to_tokens(inputs[<span class="hljs-string">&quot;labels&quot;</span>])) <span class="hljs-comment">#这里用的是把id转换成tokens的一种函数才能合理的看出是什么东西</span><br><br>max_length = <span class="hljs-number">128</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):<br>    inputs = [ex[<span class="hljs-string">&quot;en&quot;</span>] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;translation&quot;</span>]]<br>    targets = [ex[<span class="hljs-string">&quot;fr&quot;</span>] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;translation&quot;</span>]]<br>    <span class="hljs-comment">#切割</span><br>    model_inputs = tokenizer(<br>        inputs, text_target=targets, max_length=max_length, truncation=<span class="hljs-literal">True</span><br>    )<br>    <span class="hljs-keyword">return</span> model_inputs<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSeq2SeqLM<br><br>model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForSeq2Seq<br><br>data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)<br><span class="hljs-comment">#the padding value used to pad the labels should be -100 and not the padding token of the tokenizer, to make sure those padded values are ignored in the loss computation. it takes the tokenizer used to preprocess the inputs, but it also takes the model. This is because this data collator will also be responsible for preparing the decoder input IDs, which are shifted versions of the labels with a special token at the beginning. Since this shift is done slightly differently for different architectures, the DataCollatorForSeq2Seq needs to know the model object:</span><br><br><span class="hljs-comment">#for ex</span><br>batch = data_collator([tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)])<br>batch.keys()<br>dict_keys([<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;labels&#x27;</span>, <span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>])<br>batch[<span class="hljs-string">&quot;labels&quot;</span>]<br>batch[<span class="hljs-string">&quot;decoder_input_ids&quot;</span>]  <span class="hljs-comment"># see that they are shifted versions of the labels:</span><br><br></code></pre></td></tr></table></figure>

<h4 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> evaluate<br>metric = evaluate.load(<span class="hljs-string">&quot;sacrebleu&quot;</span>)<br>predictions = [<br>    <span class="hljs-string">&quot;This plugin lets you translate web pages between several languages automatically.&quot;</span><br>]<br>references = [<br>    [<br>        <span class="hljs-string">&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span><br>    ]<br>]<br><span class="hljs-comment"># the predictions should be a list of sentences, but the references should be a list of lists of sentences.</span><br><br>metric.compute(predictions=predictions, references=references)<span class="hljs-comment">#调用函数评判翻译结果的好坏</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_preds</span>):<br>    preds, labels = eval_preds<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(preds,<span class="hljs-built_in">tuple</span>):<span class="hljs-comment">#检查对象类型是不是元组 //一种相关的函数</span><br>        preds = preds[<span class="hljs-number">0</span>]<br>    <br>    decoded_preds = tokenizer.batch_decode(preds,skip_special_toknes = <span class="hljs-literal">True</span>) <span class="hljs-comment">#这里应该是已经完成了替换,所以不需要在这里进行更改</span><br>    labes = np.where(labels != -<span class="hljs-number">100</span>,labels,tokenizer.pad_token_id) <span class="hljs-comment">#分别代表了检索的值,在哪检索,不符合的值替换成什么</span><br>    decoded_labels = tokenizer.batch_decode(labels,skip_special_tokens =<span class="hljs-literal">True</span>)<br><br>    decoded_preds = [pred.strip() <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> decoded_preds] <span class="hljs-comment">#去除字符串两侧的空白字符（包括空格、制表符、换行符等</span><br>    decoded_labels = [[label.strip()] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> decoded_labels]<br><br>    result = metric.compute(predictions=decoded_preds, references=decoded_labels) <span class="hljs-comment">#计算出结果</span><br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;bleu&quot;</span>: result[<span class="hljs-string">&quot;score&quot;</span>]&#125;<br></code></pre></td></tr></table></figure>
<p>评估函数</p>
<h4 id="Fine-tuning-the-model-1"><a href="#Fine-tuning-the-model-1" class="headerlink" title="Fine-tuning the model"></a>Fine-tuning the model</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainingArguments<br><br>args = Seq2SeqTrainingArguments(<br>    <span class="hljs-string">f&quot;marian-finetuned-kde4-en-to-fr&quot;</span>,<br>    evaluation_strategy=<span class="hljs-string">&quot;no&quot;</span>,<br>    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>    learning_rate=<span class="hljs-number">2e-5</span>,<br>    per_device_train_batch_size=<span class="hljs-number">32</span>,<br>    per_device_eval_batch_size=<span class="hljs-number">64</span>,<br>    weight_decay=<span class="hljs-number">0.01</span>,<br>    save_total_limit=<span class="hljs-number">3</span>,<br>    num_train_epochs=<span class="hljs-number">3</span>,<br>    predict_with_generate=<span class="hljs-literal">True</span>,<br>    fp16=<span class="hljs-literal">True</span>,<br>    push_to_hub=<span class="hljs-literal">True</span>,<br>)<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainingArguments<br><br>args = Seq2SeqTrainingArguments(<br>    <span class="hljs-string">f&quot;marian-finetuned-kde4-en-to-fr&quot;</span>,<br>    evaluation_strategy=<span class="hljs-string">&quot;no&quot;</span>,<br>    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>    learning_rate=<span class="hljs-number">2e-5</span>,<br>    per_device_train_batch_size=<span class="hljs-number">32</span>,<br>    per_device_eval_batch_size=<span class="hljs-number">64</span>,<br>    weight_decay=<span class="hljs-number">0.01</span>,<br>    save_total_limit=<span class="hljs-number">3</span>,<br>    num_train_epochs=<span class="hljs-number">3</span>,<br>    predict_with_generate=<span class="hljs-literal">True</span>,<br>    fp16=<span class="hljs-literal">True</span>,<span class="hljs-comment">#在GPU上加速训练</span><br>    push_to_hub=<span class="hljs-literal">True</span>,<br>)<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainer<br><br>trainer = Seq2SeqTrainer(<br>    model,<br>    args,<br>    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],<br>    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],<br>    data_collator=data_collator,<br>    tokenizer=tokenizer,<br>    compute_metrics=compute_metrics,<br>)<br></code></pre></td></tr></table></figure>

<h3 id="summation"><a href="#summation" class="headerlink" title="summation"></a>summation</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">english_dataset.set_format(<span class="hljs-string">&quot;pandas&quot;</span>)<span class="hljs-comment">#转换数据类型</span><br>english_df = english_dataset[<span class="hljs-string">&quot;train&quot;</span>][:]<br><span class="hljs-comment"># Show counts for top 20 products</span><br>english_df[<span class="hljs-string">&quot;product_category&quot;</span>].value_counts()[:<span class="hljs-number">20</span>]<span class="hljs-comment">#统计出现次数最多的两个</span><br><br><span class="hljs-comment">#数据过滤</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">filter_books</span>(<span class="hljs-params">example</span>):<br>    <span class="hljs-keyword">return</span> (<br>        example[<span class="hljs-string">&quot;product_category&quot;</span>] == <span class="hljs-string">&quot;book&quot;</span><br>        <span class="hljs-keyword">or</span> example[<span class="hljs-string">&quot;product_category&quot;</span>] == <span class="hljs-string">&quot;digital_ebook_purchase&quot;</span><br>    )<br><br>english_dataset.reset_format() <span class="hljs-comment">#重新设置数据的格式</span><br>spanish_books = spanish_dataset.<span class="hljs-built_in">filter</span>(filter_books) <span class="hljs-comment">#应该是利用数据的格式,按照返回值来过滤数据</span><br>english_books = english_dataset.<span class="hljs-built_in">filter</span>(filter_books)<br><br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> concatenate_datasets, DatasetDict<br><br>books_dataset = DatasetDict()<br><br><span class="hljs-keyword">for</span> split <span class="hljs-keyword">in</span> english_books.keys():<br>    books_dataset[split] = concatenate_datasets(<br>        [english_books[split], spanish_books[split]]<br>    ) <span class="hljs-comment">#这里是取出相关的标签 然后创建一致的量.</span><br>    books_dataset[split] = books_dataset[split].shuffle(seed=<span class="hljs-number">42</span>)<br><br><span class="hljs-comment"># Peek at a few examples</span><br>show_samples(books_dataset) <span class="hljs-comment">#books混入两种不同语言的数据集</span><br><br></code></pre></td></tr></table></figure>

<h4 id="查看内容"><a href="#查看内容" class="headerlink" title="查看内容"></a>查看内容</h4><p>对于总结来说,过滤掉减短的总结是一件很重要的事情,否则会引起这种短总结的bias</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python">books_dataset = books_dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x[<span class="hljs-string">&quot;review_title&quot;</span>].split()) &gt; <span class="hljs-number">2</span>)<span class="hljs-comment">#按照里面值为1的方式进行过滤</span><br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>model_checkpoint = <span class="hljs-string">&quot;google/mt5-small&quot;</span><br>tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)<br><br><span class="hljs-comment">#输出结果</span><br>&#123;<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">336</span>, <span class="hljs-number">259</span>, <span class="hljs-number">28387</span>, <span class="hljs-number">11807</span>, <span class="hljs-number">287</span>, <span class="hljs-number">62893</span>, <span class="hljs-number">295</span>, <span class="hljs-number">12507</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]&#125;<br><br>tokenizer.convert_ids_to_tokens(inputs.input_ids) <span class="hljs-comment">#分词转换的语句</span><br>[<span class="hljs-string">&#x27;▁I&#x27;</span>, <span class="hljs-string">&#x27;▁&#x27;</span>, <span class="hljs-string">&#x27;loved&#x27;</span>, <span class="hljs-string">&#x27;▁reading&#x27;</span>, <span class="hljs-string">&#x27;▁the&#x27;</span>, <span class="hljs-string">&#x27;▁Hung&#x27;</span>, <span class="hljs-string">&#x27;er&#x27;</span>, <span class="hljs-string">&#x27;▁Games&#x27;</span>, <span class="hljs-string">&#x27;&lt;/s&gt;&#x27;</span>]<br><br>max_input_length = <span class="hljs-number">512</span><br>max_target_length = <span class="hljs-number">30</span><br><br><span class="hljs-comment">#这里没有看懂....</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):<br>    model_inputs = tokenizer(<br>        examples[<span class="hljs-string">&quot;review_body&quot;</span>],<br>        max_length=max_input_length,<br>        truncation=<span class="hljs-literal">True</span>,<br>    )<br>    labels = tokenizer(<br>        examples[<span class="hljs-string">&quot;review_title&quot;</span>], max_length=max_target_length, truncation=<span class="hljs-literal">True</span><br>    )<br>    model_inputs[<span class="hljs-string">&quot;labels&quot;</span>] = labels[<span class="hljs-string">&quot;input_ids&quot;</span>]<br>    <span class="hljs-keyword">return</span> model_inputs<br><br></code></pre></td></tr></table></figure>

<h4 id="create-a-strong-yet-simple-baseline"><a href="#create-a-strong-yet-simple-baseline" class="headerlink" title="create a strong, yet simple baseline!"></a>create a strong, yet simple baseline!</h4><p>A common baseline for text summarization is to simply take the first three sentences of an article, often called the lead-3 baseline.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> nltk<br><br>nltk.download(<span class="hljs-string">&quot;punkt&quot;</span>)<br><br><span class="hljs-keyword">from</span> nltk.tokenize <span class="hljs-keyword">import</span> sent_tokenize<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">three_sentence_summary</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;\n&quot;</span>.join(sent_tokenize(text)[:<span class="hljs-number">3</span>])<br><br><br><span class="hljs-built_in">print</span>(three_sentence_summary(books_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;review_body&quot;</span>]))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_baseline</span>(<span class="hljs-params">dataset, metric</span>):<br>    summaries = [three_sentence_summary(text) <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> dataset[<span class="hljs-string">&quot;review_body&quot;</span>]]<br>    <span class="hljs-keyword">return</span> metric.compute(predictions=summaries, references=dataset[<span class="hljs-string">&quot;review_title&quot;</span>])<br><br><span class="hljs-comment">#相当于用文本的前三句话作为评判的标准</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>score = evaluate_baseline(books_dataset[<span class="hljs-string">&quot;validation&quot;</span>], rouge_score)<br>rouge_names = [<span class="hljs-string">&quot;rouge1&quot;</span>, <span class="hljs-string">&quot;rouge2&quot;</span>, <span class="hljs-string">&quot;rougeL&quot;</span>, <span class="hljs-string">&quot;rougeLsum&quot;</span>]<br>rouge_dict = <span class="hljs-built_in">dict</span>((rn, <span class="hljs-built_in">round</span>(score[rn].mid.fmeasure * <span class="hljs-number">100</span>, <span class="hljs-number">2</span>)) <span class="hljs-keyword">for</span> rn <span class="hljs-keyword">in</span> rouge_names)<br>rouge_dict<br></code></pre></td></tr></table></figure>

<h2 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a>LangChain</h2><h3 id="chain"><a href="#chain" class="headerlink" title="chain"></a>chain</h3><p>起到了串联不同的agent的作用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Chain</span>(BaseModel, ABC):<br>    <span class="hljs-string">&quot;&quot;&quot;Base interface that all chains should implement.&quot;&quot;&quot;</span><br><br>    memory: BaseMemory<br>    callbacks: Callbacks<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        inputs: <span class="hljs-type">Any</span>,</span><br><span class="hljs-params">        return_only_outputs: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">        callbacks: Callbacks = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Any</span>]:<br>        ...<br><br><span class="hljs-comment">#use it</span><br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><br>llm = OpenAI(temperature=<span class="hljs-number">0.9</span>)<br>prompt = PromptTemplate(<span class="hljs-comment">#这里应该是创建一个prompt的模版</span><br>    input_variables=[<span class="hljs-string">&quot;product&quot;</span>],<br>    template=<span class="hljs-string">&quot;What is a good name for a company that makes &#123;product&#125;?&quot;</span>,<br>)<br><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> LLMChain<br>chain = LLMChain(llm=llm, prompt=prompt)<span class="hljs-comment">#传入两个参数</span><br><br><span class="hljs-comment"># Run the chain only specifying the input variable.</span><br><span class="hljs-built_in">print</span>(chain.run(<span class="hljs-string">&quot;colorful socks&quot;</span>))<br><br><br><span class="hljs-keyword">from</span> langchain.chat_models <span class="hljs-keyword">import</span> ChatOpenAI<br><span class="hljs-keyword">from</span> langchain.prompts.chat <span class="hljs-keyword">import</span> (<br>    ChatPromptTemplate,<br>    HumanMessagePromptTemplate,<br>)<br>human_message_prompt = HumanMessagePromptTemplate(<br>        prompt=PromptTemplate(<br>            template=<span class="hljs-string">&quot;What is a good name for a company that makes &#123;product&#125;?&quot;</span>,<br>            input_variables=[<span class="hljs-string">&quot;product&quot;</span>],<br>        )<br>    )<br>chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])<br>chat = ChatOpenAI(temperature=<span class="hljs-number">0.9</span>)<br>chain = LLMChain(llm=chat, prompt=chat_prompt_template)<br><span class="hljs-built_in">print</span>(chain.run(<span class="hljs-string">&quot;colorful socks&quot;</span>))<br><br><span class="hljs-comment"># call chain</span><br>chat = ChatOpenAI(temperature=<span class="hljs-number">0</span>)<br>prompt_template = <span class="hljs-string">&quot;Tell me a &#123;adjective&#125; joke&quot;</span><br>llm_chain = LLMChain(llm=chat, prompt=PromptTemplate.from_template(prompt_template))<br><br>llm_chain(inputs=&#123;<span class="hljs-string">&quot;adjective&quot;</span>: <span class="hljs-string">&quot;corny&quot;</span>&#125;)<span class="hljs-comment">#生成后填入input</span><br>llm_chain(<span class="hljs-string">&quot;colorful socks&quot;</span>)<br><br><span class="hljs-comment"># 同时也可以选择apply的方式,通过填入一个列表,里面分别是这些字典</span><br><br>input_list = [<br>    &#123;<span class="hljs-string">&quot;product&quot;</span>: <span class="hljs-string">&quot;socks&quot;</span>&#125;,<br>    &#123;<span class="hljs-string">&quot;product&quot;</span>: <span class="hljs-string">&quot;computer&quot;</span>&#125;,<br>    &#123;<span class="hljs-string">&quot;product&quot;</span>: <span class="hljs-string">&quot;shoes&quot;</span>&#125;<br>]<br><br>llm_chain.apply(input_list)<br>llm_chain.generate(input_list)<span class="hljs-comment">#相似的功能,但是内容类型不同</span><br>llm_chain(<span class="hljs-string">&quot;corny&quot;</span>, return_only_outputs=<span class="hljs-literal">True</span>)<span class="hljs-comment">#取消</span><br>llm_chain.run(&#123;<span class="hljs-string">&quot;adjective&quot;</span>: <span class="hljs-string">&quot;corny&quot;</span>&#125;)<span class="hljs-comment">#等价于填入这个运行,run里面必须填入字典</span><br>llm_chain.predict(product=<span class="hljs-string">&quot;colorful socks&quot;</span>)<span class="hljs-comment">#这里必须填入关键词进行完成,如下</span><br><br>template = <span class="hljs-string">&quot;&quot;&quot;Tell me a &#123;adjective&#125; joke about &#123;subject&#125;.&quot;&quot;&quot;</span><br>prompt = PromptTemplate(template=template, input_variables=[<span class="hljs-string">&quot;adjective&quot;</span>, <span class="hljs-string">&quot;subject&quot;</span>])<br>llm_chain = LLMChain(prompt=prompt, llm=OpenAI(temperature=<span class="hljs-number">0</span>))<br><br>llm_chain.predict(adjective=<span class="hljs-string">&quot;sad&quot;</span>, subject=<span class="hljs-string">&quot;ducks&quot;</span>)<br><br><span class="hljs-comment"># 语法分析parsing the outputs</span><br><br><span class="hljs-comment">#必须带上parsing的信号</span><br><span class="hljs-keyword">from</span> langchain.output_parsers <span class="hljs-keyword">import</span> CommaSeparatedListOutputParser<br><br>output_parser = CommaSeparatedListOutputParser()<br>template = <span class="hljs-string">&quot;&quot;&quot;List all the colors in a rainbow&quot;&quot;&quot;</span><br>prompt = PromptTemplate(template=template, input_variables=[], output_parser=output_parser)<br>llm_chain = LLMChain(prompt=prompt, llm=llm)<br><br>llm_chain.predict()<br>llm_chain.predict_and_parse()<br><br><br></code></pre></td></tr></table></figure>

<h3 id="modules"><a href="#modules" class="headerlink" title="modules"></a>modules</h3><h4 id="prompts"><a href="#prompts" class="headerlink" title="prompts"></a>prompts</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> PromptTemplate<br>prompt_template = PromptTemplate.from_template(<br>    <span class="hljs-string">&quot;Tell me a &#123;adjective&#125; joke about &#123;content&#125;.&quot;</span><br>)<span class="hljs-comment">#引号加入抽象内容 format可以放入实体</span><br>prompt_template.<span class="hljs-built_in">format</span>(adjective=<span class="hljs-string">&quot;funny&quot;</span>, content=<span class="hljs-string">&quot;chickens&quot;</span>)<br><br>invalid_prompt = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;adjective&quot;</span>],<span class="hljs-comment">#可以从这里买你的字典内容进行比较</span><br>    template=<span class="hljs-string">&quot;Tell me a &#123;adjective&#125; joke about &#123;content&#125;.&quot;</span><br>)<br><br><span class="hljs-comment">#chat prompt template</span><br><br><br>template = ChatPromptTemplate.from_messages([<br>    (<span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;You are a helpful AI bot. Your name is &#123;name&#125;.&quot;</span>),<br>    (<span class="hljs-string">&quot;human&quot;</span>, <span class="hljs-string">&quot;Hello, how are you doing?&quot;</span>),<br>    (<span class="hljs-string">&quot;ai&quot;</span>, <span class="hljs-string">&quot;I&#x27;m doing well, thanks!&quot;</span>),<br>    (<span class="hljs-string">&quot;human&quot;</span>, <span class="hljs-string">&quot;&#123;user_input&#125;&quot;</span>),<span class="hljs-comment">#多轮交流?</span><br>])<br><br>messages = template.format_messages(<br>    name=<span class="hljs-string">&quot;Bob&quot;</span>,<br>    user_input=<span class="hljs-string">&quot;What is your name?&quot;</span><span class="hljs-comment">#.format_messages可以用来补充信息</span><br>)<br><br><span class="hljs-comment"># few-shot prompt templates</span><br>examples = [<br>  &#123;<br>    <span class="hljs-string">&quot;question&quot;</span>: <span class="hljs-string">&quot;Who lived longer, Muhammad Ali or Alan Turing?&quot;</span>,<br>    <span class="hljs-string">&quot;answer&quot;</span>: <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Are follow up questions needed here: Yes.</span><br><span class="hljs-string">Follow up: How old was Muhammad Ali when he died?</span><br><span class="hljs-string">Intermediate answer: Muhammad Ali was 74 years old when he died.</span><br><span class="hljs-string">Follow up: How old was Alan Turing when he died?</span><br><span class="hljs-string">Intermediate answer: Alan Turing was 41 years old when he died.</span><br><span class="hljs-string">So the final answer is: Muhammad Ali</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>  &#125;] <span class="hljs-comment">#examples表现形式为列表中嵌入相关的字典</span><br>example_prompt = PromptTemplate(input_variables=[<span class="hljs-string">&quot;question&quot;</span>, <span class="hljs-string">&quot;answer&quot;</span>], template=<span class="hljs-string">&quot;Question: &#123;question&#125;\n&#123;answer&#125;&quot;</span>)<br><br><span class="hljs-built_in">print</span>(example_prompt.<span class="hljs-built_in">format</span>(**examples[<span class="hljs-number">0</span>]))<span class="hljs-comment">## **在python中传递了字典中的健对值</span><br><br>prompt = FewShotPromptTemplate(<br>    examples=examples, <br>    example_prompt=example_prompt, <br>    suffix=<span class="hljs-string">&quot;Question: &#123;input&#125;&quot;</span>, <span class="hljs-comment">#添加一个后缀</span><br>    input_variables=[<span class="hljs-string">&quot;input&quot;</span>],<span class="hljs-comment">#加入一个input作为一个输出变量,放在后面用来填入</span><br>)<br><br><span class="hljs-built_in">print</span>(prompt.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">input</span>=<span class="hljs-string">&quot;Who was the father of Mary Ball Washington?&quot;</span>))<span class="hljs-comment">#同时format是直接把这个字符串用来返回</span><br><br><span class="hljs-comment"># 通过exampleselector完成相关的操作</span><br><span class="hljs-keyword">from</span> langchain.prompts.example_selector <span class="hljs-keyword">import</span> SemanticSimilarityExampleSelector<br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> Chroma<br><span class="hljs-keyword">from</span> langchain.embeddings <span class="hljs-keyword">import</span> OpenAIEmbeddings<br>example_selector = SemanticSimilarityExampleSelector.from_examples(<br>    <span class="hljs-comment"># This is the list of examples available to select from.</span><br>    examples,<br>    <span class="hljs-comment"># This is the embedding class used to produce embeddings which are used to measure semantic similarity.</span><br>    OpenAIEmbeddings(),<br>    <span class="hljs-comment"># This is the VectorStore class that is used to store the embeddings and do a similarity search over.</span><br>    Chroma,<br>    <span class="hljs-comment"># This is the number of examples to produce.</span><br>    k=<span class="hljs-number">1</span><br>)<br><br><span class="hljs-comment"># Few-shot examples for chat models - API</span><br>langchain.prompts.few_shot.FewShotChatMessagePromptTemplate 类<br>examples = [<br>    &#123;<span class="hljs-string">&quot;input&quot;</span>: <span class="hljs-string">&quot;2+2&quot;</span>, <span class="hljs-string">&quot;output&quot;</span>: <span class="hljs-string">&quot;4&quot;</span>&#125;,<br>    &#123;<span class="hljs-string">&quot;input&quot;</span>: <span class="hljs-string">&quot;2+3&quot;</span>, <span class="hljs-string">&quot;output&quot;</span>: <span class="hljs-string">&quot;5&quot;</span>&#125;,<span class="hljs-comment">#相当于两个</span><br>]<br>example_prompt = ChatPromptTemplate.from_messages(<br>    [(<span class="hljs-string">&#x27;human&#x27;</span>, <span class="hljs-string">&#x27;&#123;input&#125;&#x27;</span>), (<span class="hljs-string">&#x27;ai&#x27;</span>, <span class="hljs-string">&#x27;&#123;output&#125;&#x27;</span>)]<br>)<br>few_shot_prompt = FewShotChatMessagePromptTemplate(<br>    examples=examples,<br>    <span class="hljs-comment"># This is a prompt template used to format each individual example.</span><br>    example_prompt=example_prompt,<br>)<br>final_prompt = ChatPromptTemplate.from_messages(<br>    [<br>        (<span class="hljs-string">&#x27;system&#x27;</span>, <span class="hljs-string">&#x27;You are a helpful AI Assistant&#x27;</span>),<br>        few_shot_prompt,<br>        (<span class="hljs-string">&#x27;human&#x27;</span>, <span class="hljs-string">&#x27;&#123;input&#125;&#x27;</span>),<br>    ]<br>)<br><br><span class="hljs-comment">#root chain</span><br><br><br></code></pre></td></tr></table></figure>
<h3 id="memory"><a href="#memory" class="headerlink" title="memory"></a>memory</h3><h4 id="store"><a href="#store" class="headerlink" title="store"></a>store</h4><p>呃呃,感觉这个单元有点像存在第三方库里面?</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#通过chatmessagehistorty类来完成相关操作</span><br><span class="hljs-keyword">from</span> langchain.memory <span class="hljs-keyword">import</span> ChatMessageHistory<br>history = ChatMessageHistory()<br>history.add_user_message(<span class="hljs-string">&quot;HI&quot;</span>)<br>history.add_ai_message(<span class="hljs-string">&quot;what&#x27;s up?&quot;</span>)<br>history.messages<br>    [HumanMessage(content=<span class="hljs-string">&#x27;hi!&#x27;</span>, additional_kwargs=&#123;&#125;),<br>     AIMessage(content=<span class="hljs-string">&#x27;whats up?&#x27;</span>, additional_kwargs=&#123;&#125;)]<br><br><span class="hljs-comment">#for start</span><br><span class="hljs-keyword">from</span> langchain.memory <span class="hljs-keyword">import</span> ConversationBufferjMemory<br>memory = ConversationBufferMemory()<br>memory = ConversationBufferMemory(memory_key=<span class="hljs-string">&quot;chat_history&quot;</span>)<span class="hljs-comment">#把history的键值更改</span><br>memory.chat_memory.add_user_message(<span class="hljs-string">&quot;hi!&quot;</span>)<br>memory.chat_memory.add_ai_message(<span class="hljs-string">&quot;what&#x27;s up?&quot;</span>)<br>memory.load_memory_variables(&#123;&#125;)<span class="hljs-comment">#同时可以发现里面放入的是字典同时含有history以及AI: 可以使用</span><br><br>memory = ConversationBufferMemory(return_messages=<span class="hljs-literal">True</span>)<br>memory.chat_memory.add_user_message(<span class="hljs-string">&quot;hi!&quot;</span>)<br>memory.chat_memory.add_ai_message(<span class="hljs-string">&quot;what&#x27;s up?&quot;</span>)<br><span class="hljs-comment">#return list of memory</span><br><span class="hljs-comment">#可以通过input_key以及output_key实现参数相关的方案</span><br><br><span class="hljs-comment"># end to end</span><br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> LLMChain<br><span class="hljs-keyword">from</span> langchain.memory <span class="hljs-keyword">import</span> ConversationBufferMemory<br><br><br>llm = OpenAI(temperature=<span class="hljs-number">0</span>)<br><span class="hljs-comment"># Notice that &quot;chat_history&quot; is present in the prompt template</span><br>template = <span class="hljs-string">&quot;&quot;&quot;You are a nice chatbot having a conversation with a human.</span><br><span class="hljs-string"></span><br><span class="hljs-string">Previous conversation:</span><br><span class="hljs-string">&#123;chat_history&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">New human question: &#123;question&#125;</span><br><span class="hljs-string">Response:&quot;&quot;&quot;</span><br>prompt = PromptTemplate.from_template(template)<br><span class="hljs-comment"># Notice that we need to align the `memory_key`</span><br>memory = ConversationBufferMemory(memory_key=<span class="hljs-string">&quot;chat_history&quot;</span>)<br>conversation = LLMChain(<br>    llm=llm,<br>    prompt=prompt,<br>    verbose=<span class="hljs-literal">True</span>,<br>    memory=memory<br>)<br><span class="hljs-comment"># Notice that we just pass in the `question` variables - `chat_history` gets populated by memory</span><br>conversation(&#123;<span class="hljs-string">&quot;question&quot;</span>: <span class="hljs-string">&quot;hi&quot;</span>&#125;)<br><br><span class="hljs-comment"># Memory in LLMChain</span><br><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> LLMChain<br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> langchain.memory <span class="hljs-keyword">import</span> ConversationBufferMemory<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><br>template = <span class="hljs-string">&quot;&quot;&quot;You are a chatbot having a conversation with a human.</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;chat_history&#125;</span><br><span class="hljs-string">Human: &#123;human_input&#125;</span><br><span class="hljs-string">Chatbot:&quot;&quot;&quot;</span><br><br>prompt = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;chat_history&quot;</span>, <span class="hljs-string">&quot;human_input&quot;</span>], template=template<br>)<br><span class="hljs-comment">#这个应该代表的是可以在里面输入变量,同时通过指明input_variables为外部变量,可以在之后添加进去</span><br>memory = ConversationBufferMemory(memory_key=<span class="hljs-string">&quot;chat_history&quot;</span>)<br>llm = OpenAI()<br>llm_chain = LLMChain(<br>    llm=llm,<br>    prompt=prompt,<br>    verbose=<span class="hljs-literal">True</span>,<br>    memory=memory,<br>)<br><span class="hljs-comment">#langchain提供了memort接口,应该可以自动链接prompt里的数据以及memory里的数据且标签为chat_history</span><br>llm_chain.predict(human_input=<span class="hljs-string">&quot;Hi there my friend&quot;</span>) <span class="hljs-comment"># 这里通过字符串的方式进行预测</span><br><br><br><span class="hljs-comment"># 增加记忆LLM</span><br><span class="hljs-keyword">from</span> langchain.chat_models <span class="hljs-keyword">import</span> ChatOpenAI<br><span class="hljs-keyword">from</span> langchain.schema <span class="hljs-keyword">import</span> SystemMessage<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder<br><br>prompt = ChatPromptTemplate.from_messages([<span class="hljs-comment"># 组合数据的形式</span><br>    SystemMessage(content=<span class="hljs-string">&quot;You are a chatbot having a conversation with a human.&quot;</span>), <span class="hljs-comment"># The persistent system prompt</span><br>    MessagesPlaceholder(variable_name=<span class="hljs-string">&quot;chat_history&quot;</span>), <span class="hljs-comment"># Where the memory will be stored.记忆存储的key</span><br>    HumanMessagePromptTemplate.from_template(<span class="hljs-string">&quot;&#123;human_input&#125;&quot;</span>), <span class="hljs-comment"># Where the human input will injected</span><br>])<br>    <br>memory = ConversationBufferMemory(memory_key=<span class="hljs-string">&quot;chat_history&quot;</span>, return_messages=<span class="hljs-literal">True</span>)<br><br><br><span class="hljs-comment"># Memory in the Multi-Input Chain</span><br><span class="hljs-keyword">from</span> langchain.embeddings.openai <span class="hljs-keyword">import</span> OpenAIEmbeddings<br><span class="hljs-keyword">from</span> langchain.embeddings.cohere <span class="hljs-keyword">import</span> CohereEmbeddings<br><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> CharacterTextSplitter<br><span class="hljs-keyword">from</span> langchain.vectorstores.elastic_vector_search <span class="hljs-keyword">import</span> ElasticVectorSearch<br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> Chroma<br><span class="hljs-keyword">from</span> langchain.docstore.document <span class="hljs-keyword">import</span> Document<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../../state_of_the_union.txt&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    state_of_the_union = f.read()<br>text_splitter = CharacterTextSplitter(chunk_size=<span class="hljs-number">1000</span>, chunk_overlap=<span class="hljs-number">0</span>)<br>texts = text_splitter.split_text(state_of_the_union)<br><br>embeddings = OpenAIEmbeddings()<br>docsearch = Chroma.from_texts(<br>    texts, embeddings, metadatas=[&#123;<span class="hljs-string">&quot;source&quot;</span>: i&#125; <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(texts))]<br>)<span class="hljs-comment"># 按照source texts每一个单元都作为嵌入数据处理</span><br>query = <span class="hljs-string">&quot;What did the president say about Justice Breyer&quot;</span><br>docs = docsearch.similarity_search(query) <span class="hljs-comment"># 数据库可以直接使用其处理 .similarity_search()检索</span><br><br><span class="hljs-keyword">from</span> langchain.chains.question_answering <span class="hljs-keyword">import</span> load_qa_chain<br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><span class="hljs-keyword">from</span> langchain.memory <span class="hljs-keyword">import</span> ConversationBufferMemory<br><br>template = <span class="hljs-string">&quot;&quot;&quot;You are a chatbot having a conversation with a human.</span><br><span class="hljs-string"></span><br><span class="hljs-string">Given the following extracted parts of a long document and a question, create a final answer.</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;context&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;chat_history&#125;</span><br><span class="hljs-string">Human: &#123;human_input&#125;</span><br><span class="hljs-string">Chatbot:&quot;&quot;&quot;</span><br><br>prompt = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;chat_history&quot;</span>, <span class="hljs-string">&quot;human_input&quot;</span>, <span class="hljs-string">&quot;context&quot;</span>], template=template<br>)<br>memory = ConversationBufferMemory(memory_key=<span class="hljs-string">&quot;chat_history&quot;</span>, input_key=<span class="hljs-string">&quot;human_input&quot;</span>)<span class="hljs-comment">#</span><br>chain = load_qa_chain(<br>    OpenAI(temperature=<span class="hljs-number">0</span>), chain_type=<span class="hljs-string">&quot;stuff&quot;</span>, memory=memory, prompt=prompt<br>)<br><span class="hljs-comment"># memory in agent</span><br><br>search = GoogleSearchAPIWrapper()<br>tools = [<br>    Tool(<span class="hljs-comment">#? </span><br>        name=<span class="hljs-string">&quot;Search&quot;</span>,<span class="hljs-comment">#ming ming</span><br>        func=search.run,<span class="hljs-comment">#函数功能</span><br>        description=<span class="hljs-string">&quot;useful for when you need to answer questions about current events&quot;</span>,<br>    )<br>]<span class="hljs-comment">#可以使用的功能</span><br><br><br>prefix = <span class="hljs-string">&quot;&quot;&quot;Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:&quot;&quot;&quot;</span><br>suffix = <span class="hljs-string">&quot;&quot;&quot;Begin!&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;chat_history&#125;</span><br><span class="hljs-string">Question: &#123;input&#125;</span><br><span class="hljs-string">&#123;agent_scratchpad&#125;&quot;&quot;&quot;</span><br><span class="hljs-comment"># </span><br>prompt = ZeroShotAgent.create_prompt(<br>    tools,<br>    prefix=prefix,<br>    suffix=suffix,<br>    input_variables=[<span class="hljs-string">&quot;input&quot;</span>, <span class="hljs-string">&quot;chat_history&quot;</span>, <span class="hljs-string">&quot;agent_scratchpad&quot;</span>],<br>)<span class="hljs-comment"># ? 可以直接嵌入前缀以及后缀吗</span><br><br>memory = ConversationBufferMemory(memory_key=<span class="hljs-string">&quot;chat_history&quot;</span>)<span class="hljs-comment">#按照之前的</span><br><br>llm_chain = LLMChain(llm=OpenAI(temperature=<span class="hljs-number">0</span>), prompt=prompt)<br>agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=<span class="hljs-literal">True</span>)<span class="hljs-comment">#代理人, 工具</span><br>agent_chain = AgentExecutor.from_agent_and_tools(<br>    agent=agent, tools=tools, verbose=<span class="hljs-literal">True</span>, memory=memory<br>)<span class="hljs-comment">#memory 重新嵌入agent_chain </span><br><br><br><br><br></code></pre></td></tr></table></figure>

<h3 id="retrieve-检索器"><a href="#retrieve-检索器" class="headerlink" title="retrieve 检索器"></a>retrieve 检索器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># quick start!</span><br><br><br><span class="hljs-comment">#document loader - ex for csv-&gt;以逗号作为分隔的文件</span><br><span class="hljs-keyword">from</span> langchain.document_loaders.csv_loader <span class="hljs-keyword">import</span> CSVLoader<br>loader = CSVLoader(file_path = <span class="hljs-string">&#x27;./example_data/mllb_teams_2012.csv&#x27;</span>)<br>data = loader.load()<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;../../state_of_the_union.txt&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    state_of_the_union = f.read()<br><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> RecursiveCharacterTextSplitter<br>text_splitter = RecursiveCharacterTextSplitter(<br>    <span class="hljs-comment"># Set a really small chunk size, just to show.</span><br>    chunk_size = <span class="hljs-number">100</span>,<span class="hljs-comment">#最长数量</span><br>    chunk_overlap  = <span class="hljs-number">20</span>,<span class="hljs-comment">#重叠数量</span><br>    length_function = <span class="hljs-built_in">len</span>,<br>    add_start_index = <span class="hljs-literal">True</span>,<span class="hljs-comment">#切割后的开始字符在原来的数组中的位置</span><br>)<br><br><span class="hljs-comment">#---以上略去了一些其他的切割方式</span><br><br><span class="hljs-comment">#Lost in the middle: The problem with long contexts:When models must access relevant information in the middle of long contexts, they tend to ignore the provided documents</span><br><span class="hljs-comment">#采用重新打乱的方式完成(检索之后)</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> chromadb<br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> Chroma<br><span class="hljs-keyword">from</span> langchain.embeddings <span class="hljs-keyword">import</span> HuggingFaceEmbeddings<br><span class="hljs-keyword">from</span> langchain.document_transformers <span class="hljs-keyword">import</span> (<br>    LongContextReorder,<br>)<br><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> StuffDocumentsChain, LLMChain<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><br><span class="hljs-comment"># Get embeddings.</span><br>embeddings = HuggingFaceEmbeddings(model_name=<span class="hljs-string">&quot;all-MiniLM-L6-v2&quot;</span>)<br><br>texts = [<br>    <span class="hljs-string">&quot;Basquetball is a great sport.&quot;</span>,<br>    <span class="hljs-string">&quot;Fly me to the moon is one of my favourite songs.&quot;</span>,<br>    <span class="hljs-string">&quot;The Celtics are my favourite team.&quot;</span>,<br>    <span class="hljs-string">&quot;This is a document about the Boston Celtics&quot;</span>,<br>    <span class="hljs-string">&quot;I simply love going to the movies&quot;</span>,<br>    <span class="hljs-string">&quot;The Boston Celtics won the game by 20 points&quot;</span>,<br>    <span class="hljs-string">&quot;This is just a random text.&quot;</span>,<br>    <span class="hljs-string">&quot;Elden Ring is one of the best games in the last 15 years.&quot;</span>,<br>    <span class="hljs-string">&quot;L. Kornet is one of the best Celtics players.&quot;</span>,<br>    <span class="hljs-string">&quot;Larry Bird was an iconic NBA player.&quot;</span>,<br>]<br><br><span class="hljs-comment"># Create a retriever</span><br>retriever = Chroma.from_texts(texts, embedding=embeddings).as_retriever(<br>    search_kwargs=&#123;<span class="hljs-string">&quot;k&quot;</span>: <span class="hljs-number">10</span>&#125;<br>)<br>query = <span class="hljs-string">&quot;What can you tell me about the Celtics?&quot;</span><br><br><span class="hljs-comment"># Get relevant documents ordered by relevance score</span><br>docs = retriever.get_relevant_documents(query)<br>docs<br><span class="hljs-comment">#这个b东西穿模了吧</span><br><br><span class="hljs-comment">#embedding</span><br><span class="hljs-keyword">from</span> langchain.embeddings <span class="hljs-keyword">import</span> OpenAIEmbeddings<br><br>embeddings_model = OpenAIEmbeddings()<span class="hljs-comment">#直接设置</span><br>embeddings = embeddings_model.embed_documents(<br>    [<br>        <span class="hljs-string">&quot;Hi there!&quot;</span>,<br>        <span class="hljs-string">&quot;Oh, hello!&quot;</span>,<br>        <span class="hljs-string">&quot;What&#x27;s your name?&quot;</span>,<br>        <span class="hljs-string">&quot;My friends call me World&quot;</span>,<br>        <span class="hljs-string">&quot;Hello World!&quot;</span><br>    ]<br>)<span class="hljs-comment">#分解的时候支持列表里的多个字符串的形式</span><br><span class="hljs-built_in">len</span>(embeddings), <span class="hljs-built_in">len</span>(embeddings[<span class="hljs-number">0</span>])<span class="hljs-comment">#表示有多少行的变量长度</span><br><br>embedded_query = embeddings_model.embed_query(<span class="hljs-string">&quot;What was the name mentioned in the conversation?&quot;</span>)<br>embedded_query[:<span class="hljs-number">5</span>]<span class="hljs-comment">#询问以及其他的含有不同的表征形式</span><br><br><span class="hljs-comment">#支持caching技术</span><br><span class="hljs-comment">#TODO</span><br><span class="hljs-comment">#Vector stores </span><br><span class="hljs-comment">#存储embedding向量同时之后用于查询的方式</span><br><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> TextLoader<br><span class="hljs-keyword">from</span> langchain.embeddings.openai <span class="hljs-keyword">import</span> OpenAIEmbeddings<br><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> CharacterTextSplitter<br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> FAISS<br><br><span class="hljs-comment"># Load the document, split it into chunks, embed each chunk and load it into the vector store.</span><br>raw_documents = TextLoader(<span class="hljs-string">&#x27;../../../state_of_the_union.txt&#x27;</span>).load()<br>text_splitter = CharacterTextSplitter(chunk_size=<span class="hljs-number">1000</span>, chunk_overlap=<span class="hljs-number">0</span>)<br>documents = text_splitter.split_documents(raw_documents)<span class="hljs-comment">#已经完成相关的切割了</span><br>db = FAISS.from_documents(documents, OpenAIEmbeddings())<br><span class="hljs-comment">#相似性的查询</span><br>query = <span class="hljs-string">&quot;What did the president say about Ketanji Brown Jackson&quot;</span><br>docs = db.similarity_search(query)<br><span class="hljs-built_in">print</span>(docs[<span class="hljs-number">0</span>].page_content)<br><span class="hljs-comment">#vector查询</span><br>embedding_vector = OpenAIEmbeddings().embed_query(query)<br>docs = db.similarity_search_by_vector(embedding_vector)<br><span class="hljs-built_in">print</span>(docs[<span class="hljs-number">0</span>].page_content)<br><span class="hljs-comment">#结果一致</span><br><br><span class="hljs-comment">#retrieve QUICK START</span><br><span class="hljs-keyword">from</span> abc <span class="hljs-keyword">import</span> ABC, abstractmethod<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Any</span>, <span class="hljs-type">List</span><br><span class="hljs-keyword">from</span> langchain.schema <span class="hljs-keyword">import</span> Document<br><span class="hljs-keyword">from</span> langchain.callbacks.manager <span class="hljs-keyword">import</span> Callbacks<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BaseRetriever</span>(<span class="hljs-title class_ inherited__">ABC</span>):<br>    ...<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_relevant_documents</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self, query: <span class="hljs-built_in">str</span>, *, callbacks: Callbacks = <span class="hljs-literal">None</span>, **kwargs: <span class="hljs-type">Any</span></span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-type">List</span>[Document]:<br>        <span class="hljs-string">&quot;&quot;&quot;Retrieve documents relevant to a query.</span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            query: string to find relevant documents for</span><br><span class="hljs-string">            callbacks: Callback manager or list of callbacks</span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            List of relevant documents</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        ...<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">aget_relevant_documents</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self, query: <span class="hljs-built_in">str</span>, *, callbacks: Callbacks = <span class="hljs-literal">None</span>, **kwargs: <span class="hljs-type">Any</span></span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-type">List</span>[Document]:<br>        <span class="hljs-string">&quot;&quot;&quot;Asynchronously get documents relevant to a query.</span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            query: string to find relevant documents for</span><br><span class="hljs-string">            callbacks: Callback manager or list of callbacks</span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            List of relevant documents</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        ...<br><br><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> RetrievalQA<br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> TextLoader<br>loader = TextLoader(<span class="hljs-string">&#x27;../state_of_the_union.txt&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf8&#x27;</span>)<br><span class="hljs-keyword">from</span> langchain.indexes <span class="hljs-keyword">import</span> VectorstoreIndexCreator<br>index = VectorstoreIndexCreator().from_loaders([loader])<span class="hljs-comment">#</span><br>query = <span class="hljs-string">&quot;What did the president say about Ketanji Brown Jackson&quot;</span><br>index.query_with_sources(query)<span class="hljs-comment">#返回相关的字符串</span><br>query = <span class="hljs-string">&quot;What did the president say about Ketanji Brown Jackson&quot;</span><br>index.query_with_sources(query)<span class="hljs-comment">#字典 含有详细的相关的文本</span><br>index.query(<span class="hljs-string">&quot;Summarize the general content of this document.&quot;</span>, retriever_kwargs=&#123;<span class="hljs-string">&quot;search_kwargs&quot;</span>: &#123;<span class="hljs-string">&quot;filter&quot;</span>: &#123;<span class="hljs-string">&quot;source&quot;</span>: <span class="hljs-string">&quot;../state_of_the_union.txt&quot;</span>&#125;&#125;&#125;)<span class="hljs-comment">#同时可以选择过滤的方式</span><br><br><br><span class="hljs-comment">#muliquery use</span><br><br><br><span class="hljs-comment"># Build a sample vectorDB</span><br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> Chroma<br><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> WebBaseLoader<br><span class="hljs-keyword">from</span> langchain.embeddings.openai <span class="hljs-keyword">import</span> OpenAIEmbeddings<br><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> RecursiveCharacterTextSplitter<br><br><span class="hljs-comment"># Load blog post</span><br>loader = WebBaseLoader(<span class="hljs-string">&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;</span>)<br>data = loader.load()<br><br><span class="hljs-comment"># Split</span><br>text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class="hljs-number">500</span>, chunk_overlap=<span class="hljs-number">0</span>)<br>splits = text_splitter.split_documents(data)<br><br><span class="hljs-comment"># VectorDB</span><br>embedding = OpenAIEmbeddings()<br>vectordb = Chroma.from_documents(documents=splits, embedding=embedding)<br><span class="hljs-comment">#chroma表示split用embedding处理后存入数据库</span><br><span class="hljs-keyword">from</span> langchain.chat_models <span class="hljs-keyword">import</span> ChatOpenAI<br><span class="hljs-keyword">from</span> langchain.retrievers.multi_query <span class="hljs-keyword">import</span> MultiQueryRetriever<br><br>question = <span class="hljs-string">&quot;What are the approaches to Task Decomposition?&quot;</span><br>llm = ChatOpenAI(temperature=<span class="hljs-number">0</span>)<br>retriever_from_llm = MultiQueryRetriever.from_llm(<br>    retriever=vectordb.as_retriever(), llm=llm<br>)<br>unique_docs = retriever_from_llm.get_relevant_documents(query=question)<span class="hljs-comment">#表示依据询问,连续产生相关的疑问来进行检索</span><br><span class="hljs-built_in">len</span>(unique_docs)<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> LLMChain<br><span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel, Field<span class="hljs-comment">#数据验证库 可以定义不同名字的类</span><br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><span class="hljs-keyword">from</span> langchain.output_parsers <span class="hljs-keyword">import</span> PydanticOutputParser<br><br><br><span class="hljs-comment"># Output parser will split the LLM result into a list of queries</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LineList</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    <span class="hljs-comment"># &quot;lines&quot; is the key (attribute name) of the parsed output</span><br>    lines: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>] = Field(description=<span class="hljs-string">&quot;Lines of text&quot;</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LineListOutputParser</span>(<span class="hljs-title class_ inherited__">PydanticOutputParser</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__(pydantic_object=LineList)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">parse</span>(<span class="hljs-params">self, text: <span class="hljs-built_in">str</span></span>) -&gt; LineList:<br>        lines = text.strip().split(<span class="hljs-string">&quot;\n&quot;</span>)<br>        <span class="hljs-keyword">return</span> LineList(lines=lines)<br><br><br>output_parser = LineListOutputParser()<br><br>QUERY_PROMPT = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;question&quot;</span>],<br>    template=<span class="hljs-string">&quot;&quot;&quot;You are an AI language model assistant. Your task is to generate five </span><br><span class="hljs-string">    different versions of the given user question to retrieve relevant documents from a vector </span><br><span class="hljs-string">    database. By generating multiple perspectives on the user question, your goal is to help</span><br><span class="hljs-string">    the user overcome some of the limitations of the distance-based similarity search. </span><br><span class="hljs-string">    Provide these alternative questions seperated by newlines.</span><br><span class="hljs-string">    Original question: &#123;question&#125;&quot;&quot;&quot;</span>,<br>)<br>llm = ChatOpenAI(temperature=<span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># Chain</span><br>llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT, output_parser=output_parser)<br><br><span class="hljs-comment"># Other inputs</span><br>question = <span class="hljs-string">&quot;What are the approaches to Task Decomposition?&quot;</span><br><br><span class="hljs-comment"># 按时间检索完成</span><br>scoring = semantic_similarity + (<span class="hljs-number">1.0</span> - decay_rate) ^ hours_passed<br><span class="hljs-comment">#每一次access都需要更新自己的记忆</span><br><span class="hljs-keyword">import</span> faiss<br><br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime, timedelta<br><span class="hljs-keyword">from</span> langchain.docstore <span class="hljs-keyword">import</span> InMemoryDocstore<br><span class="hljs-keyword">from</span> langchain.embeddings <span class="hljs-keyword">import</span> OpenAIEmbeddings<br><span class="hljs-keyword">from</span> langchain.retrievers <span class="hljs-keyword">import</span> TimeWeightedVectorStoreRetriever<br><span class="hljs-keyword">from</span> langchain.schema <span class="hljs-keyword">import</span> Document<br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> FAISS<br><br><span class="hljs-comment"># Define your embedding model</span><br>embeddings_model = OpenAIEmbeddings()<br><span class="hljs-comment"># Initialize the vectorstore as empty</span><br>embedding_size = <span class="hljs-number">1536</span><br>index = faiss.IndexFlatL2(embedding_size)<br>vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore(&#123;&#125;), &#123;&#125;)<span class="hljs-comment">#vectorstore 用于描述存入的方式</span><br>retriever = TimeWeightedVectorStoreRetriever(vectorstore=vectorstore, decay_rate=<span class="hljs-number">.0000000000000000000000001</span>, k=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>



                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/NLP-hug/" class="print-no-link">#NLP_hug</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>NLP&amp;&amp;LLM</div>
      <div>http://example.com/2023/08/20/NLP/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>NGC6302</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2023年8月20日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/08/26/nlp-paper/" title="nlp_paper">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">nlp_paper</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/07/26/c-learn/" title="c++_learn">
                        <span class="hidden-mobile">c++_learn</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
