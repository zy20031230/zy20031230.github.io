

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="NGC6302">
  <meta name="keywords" content="">
  
    <meta name="description" content="BASEå‚è€ƒé“¾æ¥ NLP_course unigram tokenization12345678910111213141516171819202122232425262728293031323334353637383940def encode_word(word, model):    best_segmentations &#x3D; [&amp;#123;&quot;start&quot;: 0, &quot;">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP&amp;&amp;LLM">
<meta property="og:url" content="http://example.com/2023/08/20/NLP/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="BASEå‚è€ƒé“¾æ¥ NLP_course unigram tokenization12345678910111213141516171819202122232425262728293031323334353637383940def encode_word(word, model):    best_segmentations &#x3D; [&amp;#123;&quot;start&quot;: 0, &quot;">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-08-20T13:39:49.000Z">
<meta property="article:modified_time" content="2023-09-15T06:41:55.171Z">
<meta property="article:author" content="NGC6302">
<meta property="article:tag" content="NLP_hug">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>NLP&amp;&amp;LLM - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.5-a","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>é¦–é¡µ</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>å½’æ¡£</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>åˆ†ç±»</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>æ ‡ç­¾</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>å…³äº</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="NLP&amp;&amp;LLM"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-08-20 21:39" pubdate>
          2023å¹´8æœˆ20æ—¥ æ™šä¸Š
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          43k å­—
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          362 åˆ†é’Ÿ
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">NLP&amp;&amp;LLM</h1>
            
            
              <div class="markdown-body">
                
                <h2 id="BASE"><a href="#BASE" class="headerlink" title="BASE"></a>BASE</h2><p>å‚è€ƒé“¾æ¥ <a target="_blank" rel="noopener" href="https://huggingface.co/learn/nlp-course/">NLP_course</a></p>
<h3 id="unigram-tokenization"><a href="#unigram-tokenization" class="headerlink" title="unigram tokenization"></a>unigram tokenization</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">encode_word</span>(<span class="hljs-params">word, model</span>):<br>    best_segmentations = [&#123;<span class="hljs-string">&quot;start&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-number">1</span>&#125;] + [<br>        &#123;<span class="hljs-string">&quot;start&quot;</span>: <span class="hljs-literal">None</span>, <span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-literal">None</span>&#125; <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(word))<br>    ]<br>    <span class="hljs-comment">#è‡³å°‘æ¯ä¸€ç§å­—é•¿éƒ½æœ‰ç•™ä¸‹æ¥å¯¹åº”çš„ä¸€ä¸ªå€¼.åŒæ—¶åœ¨ä½æ¬¡ä¸Šå¯¹åº”END,é‡Œé¢çš„startå¯¹åº”äº†åœ¨è¿™ä¸ªENDä¸­,åœ¨å“ªé‡Œæœ‰æœ€å¥½çš„åˆ†è¯çš„æ–¹æ³•.</span><br>    <span class="hljs-keyword">for</span> start_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(word)):<br>        <span class="hljs-comment"># This should be properly filled by the previous steps of the loop</span><br>        best_score_at_start = best_segmentations[start_idx][<span class="hljs-string">&quot;score&quot;</span>]<br>        <span class="hljs-keyword">for</span> end_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(start_idx + <span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(word) + <span class="hljs-number">1</span>):<br>            token = word[start_idx:end_idx] <span class="hljs-comment"># tokeæˆªå–äº†ä¸€ç»„å€¼,ä¹‹åé€šè¿‡æŸ¥è¡¨è¿›è¡Œæ¯”è¾ƒ</span><br>            <span class="hljs-keyword">if</span> token <span class="hljs-keyword">in</span> model <span class="hljs-keyword">and</span> best_score_at_start <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                score = model[token] + best_score_at_start<br>                <span class="hljs-comment"># If we have found a better segmentation ending at end_idx, we update</span><br>                <span class="hljs-keyword">if</span> (<br>                    best_segmentations[end_idx][<span class="hljs-string">&quot;score&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span><br>                    <span class="hljs-keyword">or</span> best_segmentations[end_idx][<span class="hljs-string">&quot;score&quot;</span>] &gt; score<br>                ):<br>                <span class="hljs-comment">#è¿™é‡Œå–çš„æ˜¯-logç›¸å½“äºæ˜¯ä¸€ä¸ªé€’å‡çš„å‡½æ•°,å¦‚æœé¢‘ç‡é«˜,åè€Œå¾—åˆ°çš„å€¼è¶Šä½,æ‰€ä»¥è¿™é‡Œé€‰æ‹©é«˜é¢‘ç‡çš„ç•™ä¸‹,</span><br>                <span class="hljs-comment">#å…³äºç»§æ‰¿å‰é¢çš„å€¼,è¿™é‡Œçš„å«ä¹‰æŒ‡çš„æ˜¯:start endéƒ½å«æœ‰ä¸€å®šçš„å€¼,startçš„åˆ†è¯+æ–°å¢çš„è¯å—é¢‘ç‡å¤Ÿé«˜çš„æƒ…å†µæ‰æ›´æ–°ENDçš„æ¨¡å—</span><br>                <span class="hljs-comment">#ä¸‹é¢å¯¹åº”äº†ä¸¤ç§æƒ…å†µ,ä¸€ç§æ˜¯åç»­æ²¡æœ‰end_idxç›´æ¥æ‰“ä¸Šæ ‡ç­¾ å¦ä¸€ç§æ˜¯åœ¨å½“å‰çš„start + å¢çš„ æ¯”åç»­çš„ä½åˆ™æ›´æ”¹??</span><br>                    best_segmentations[end_idx] = &#123;<span class="hljs-string">&quot;start&quot;</span>: start_idx, <span class="hljs-string">&quot;score&quot;</span>: score&#125;<br><br>    segmentation = best_segmentations[-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">if</span> segmentation[<span class="hljs-string">&quot;score&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-comment"># We did not find a tokenization of the word -&gt; unknown</span><br>        <span class="hljs-keyword">return</span> [<span class="hljs-string">&quot;&lt;unk&gt;&quot;</span>], <span class="hljs-literal">None</span><br><br>    score = segmentation[<span class="hljs-string">&quot;score&quot;</span>]<br>    start = segmentation[<span class="hljs-string">&quot;start&quot;</span>]<br>    end = <span class="hljs-built_in">len</span>(word)<br>    tokens = []<br>    <span class="hljs-keyword">while</span> start != <span class="hljs-number">0</span>:<br>        tokens.insert(<span class="hljs-number">0</span>, word[start:end])<br>        next_start = best_segmentations[start][<span class="hljs-string">&quot;start&quot;</span>]<br>        end = start<br>        start = next_start<br>    tokens.insert(<span class="hljs-number">0</span>, word[start:end])<br>    <span class="hljs-keyword">return</span> tokens, score<br><span class="hljs-comment"># ä½†æ˜¯ä¸ºä»€ä¹ˆæ˜¯æœ€åçš„ä¸€ä¸ª?</span><br></code></pre></td></tr></table></figure>

<h2 id="MAIN-NLP-TASKS"><a href="#MAIN-NLP-TASKS" class="headerlink" title="MAIN NLP TASKS"></a>MAIN NLP TASKS</h2><h3 id="Token-classification"><a href="#Token-classification" class="headerlink" title="Token classification"></a>Token classification</h3><h4 id="preparing-the-data"><a href="#preparing-the-data" class="headerlink" title="preparing the data"></a>preparing the data</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br>raw_datasets = load_dataset(<span class="hljs-string">&quot;conll2003&quot;</span>)<br><br><span class="hljs-comment"># æ•°æ®å½¢å¼</span><br><br>DatasetDict(&#123;<br>    train: Dataset(&#123;<br>        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],<br>        num_rows: <span class="hljs-number">14041</span><br>    &#125;)<br>    validation: Dataset(&#123;<br>        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],<br>        num_rows: <span class="hljs-number">3250</span><br>    &#125;)<br>    test: Dataset(&#123;<br>        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],<br>        num_rows: <span class="hljs-number">3453</span><br>    &#125;)<br>&#125;)<br><span class="hljs-comment">#the last column is called tokens, but it contains words in the sense that these are pre-tokenized inputs that still need to go through the tokenizer for subword tokenization</span><br><br><span class="hljs-comment"># æ•°æ®å½¢å¼</span><br>ner_feature = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].features[<span class="hljs-string">&quot;ner_tags&quot;</span>]<br><br><span class="hljs-type">Sequence</span>(feature=ClassLabel(num_classes=<span class="hljs-number">9</span>, names=[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>, <span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;I-ORG&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;I-LOC&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>), length=-<span class="hljs-number">1</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)<br><br><span class="hljs-comment"># è¡¨ç¤ºè¿™é‡Œçš„è®­ç»ƒé˜Ÿåˆ—çš„ç±»å‹</span><br></code></pre></td></tr></table></figure>
<p>è§£æ„æ•°æ®è¡¨ç¤º</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>words = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;tokens&quot;</span>]<br>labels = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]<br>line1 = <span class="hljs-string">&quot;&quot;</span><br>line2 = <span class="hljs-string">&quot;&quot;</span><br><span class="hljs-keyword">for</span> word, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(words, labels):<span class="hljs-comment">#ä¸ä»…å–å‡ºäº†ä¸¤ä¸ªåˆ—è¡¨ä¸­çš„å…ƒç´ ,åŒæ—¶æŠŠè¿™ä¸¤ä¸ªå¯¹åº”çš„æ•°ç»„å‹ç¼©æˆå…ƒç»„</span><br>    full_label = label_names[label]<br>    max_length = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">len</span>(word), <span class="hljs-built_in">len</span>(full_label))<br>    line1 += word + <span class="hljs-string">&quot; &quot;</span> * (max_length - <span class="hljs-built_in">len</span>(word) + <span class="hljs-number">1</span>)<br>    line2 += full_label + <span class="hljs-string">&quot; &quot;</span> * (max_length - <span class="hljs-built_in">len</span>(full_label) + <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<h4 id="æ•°æ®åŠ å·¥"><a href="#æ•°æ®åŠ å·¥" class="headerlink" title="æ•°æ®åŠ å·¥"></a>æ•°æ®åŠ å·¥</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>model_checkpoint = <span class="hljs-string">&quot;bert-base-cased&quot;</span><br>tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)<br><br>inputs = tokenizer(raw_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;tokens&quot;</span>],is_split_into_words = <span class="hljs-literal">True</span>)<br><br>inputs.word_ids()<span class="hljs-comment">#å¯ä»¥æ­£ç¡®çš„å¯¹é½æ¯ä¸€ä¸ªtokensçš„å•è¯çš„ä½ç½®</span><br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#è¿™ä¸ªå‡½æ•°ç›¸å½“äºåˆ†è£‚åŒæ—¶æ‰“ä¸Šæ ‡ç­¾</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">align_labels_with_tokens</span>(<span class="hljs-params">labels,word_ids</span>):<br>    <span class="hljs-comment">#labelsæ˜¯æ¥è‡ªäºner_tags</span><br>    new_labels = []<br>    current_word = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">for</span> word_id <span class="hljs-keyword">in</span> word_ids:<br>        <span class="hljs-keyword">if</span> word_id != current_word:<span class="hljs-comment">#åŒºåˆ†æ˜¯å¦æ˜¯ä¸€ä¸ªæ–°çš„å•è¯</span><br>            current_word = word_id<br>            label = -<span class="hljs-number">100</span> <span class="hljs-keyword">if</span> word_id <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> labels[word_id]<br>            new_labels.append(label)<span class="hljs-comment">#æ”¾å…¥æ–°çš„label</span><br>        <span class="hljs-keyword">elif</span> word_id = <span class="hljs-literal">None</span>:<br>            new_labels.append(-<span class="hljs-number">100</span>)<br>        <span class="hljs-keyword">else</span>:<br>            label = labels[word_id]<span class="hljs-comment">#æ˜¯åœ¨å½“å‰çš„labelsä¸­</span><br>            <span class="hljs-keyword">if</span> label % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>:<br>                label += <span class="hljs-number">1</span> <span class="hljs-comment">#ç›¸å½“äºæŠŠBä¸­çš„å€¼è½¬æ¢ä¸ºI,å¦‚æœæ˜¯åŒä¸€ä¸ªå•è¯çš„æƒ…å†µä¸‹</span><br>            new_labels.append(label)<br>    <span class="hljs-keyword">return</span> new_labels<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_and_align_labels</span>(<span class="hljs-params">examples</span>):<br>    tokenized_inputs = tokenizer(examples[<span class="hljs-string">&quot;tokens&quot;</span>],truncation = <span class="hljs-literal">True</span>, is_split_into_words =<span class="hljs-literal">True</span>)<br>    all_labels = example[<span class="hljs-string">&quot;ner_tags&quot;</span>]<br>    new_labels = []<br>    <span class="hljs-keyword">for</span> i,labels <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(all_labels):<br>        word_ids = tokenized_inputs.word_ids(i)<br>        new_labels.append(align_labels_with_tokens(labels,word_ids))<br>    <br>    tokenized_input[<span class="hljs-string">&quot;labels&quot;</span>] = new_labels<br>    <span class="hljs-keyword">return</span> tokenized_inputs<br><br><span class="hljs-comment">#è¿™é‡ŒåŸºæœ¬ç›¸å½“äºæ˜¯åœ¨ä¸‹é¢è¿›è¡Œäº†è°ƒç”¨,ä½†æ˜¯è¿™é‡Œä»ç„¶æ²¡æœ‰å®ŒæˆæŠŠæ‰€æœ‰çš„å¯¹é½é™„å¸¦ä¸Špadding</span><br><br><span class="hljs-comment">#ä»¥ä¸‹å®Œæˆæ•°æ®é›†çš„è®­ç»ƒ</span><br>tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(<br>    tokenize_and_align_labels,<span class="hljs-comment">#è¿™é‡Œçš„åŸç†åº”è¯¥ç›¸å½“äºç›´æ¥æŠŠè¿™ä¸ªrawæ•°æ®é›†ä¼ å…¥è¿›å»,ç„¶åç›´æ¥ä¾ç…§ç›¸å…³çš„å‡½æ•°è¿›è¡Œè¾“å‡º</span><br>    batched = <span class="hljs-literal">True</span>,<br>    remove_columns = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].column_names,<span class="hljs-comment">#è¿™é‡Œç›¸å½“äºæŠŠè®­ç»ƒåçš„è¿™ä¸€åˆ—åˆ é™¤æ‰</span><br>)<br><br></code></pre></td></tr></table></figure>

<h4 id="Fine-tuning-the-modle-with-trainer-API"><a href="#Fine-tuning-the-modle-with-trainer-API" class="headerlink" title="Fine-tuning the modle with trainer API"></a>Fine-tuning the modle with trainer API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForTokenClassification<br>data_collator = DataClollatorForTokenClassification(tokenizer = tokenizer)<br><span class="hljs-comment">#è¿™é‡Œæ²¡æœ‰å¯¹é½çš„å€¼é»˜è®¤æ‰“ä¸Šäº†-100çš„æ ‡ç­¾</span><br></code></pre></td></tr></table></figure>

<h4 id="Metrics-åº¦é‡æŒ‡æ ‡"><a href="#Metrics-åº¦é‡æŒ‡æ ‡" class="headerlink" title="Metrics åº¦é‡æŒ‡æ ‡"></a>Metrics åº¦é‡æŒ‡æ ‡</h4><p>åˆ©ç”¨seqevalè¿›è¡Œåº¦é‡è¯¥æŒ‡æ ‡</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> evalutate<br>metric = evaluate.load(<span class="hljs-string">&quot;seqeval&quot;</span>)<br><br>labels = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]<br>labels = [label_names[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> labels]<br><span class="hljs-comment">#è¿™é‡Œç›¸å½“äºæŠŠåŸå…ˆçš„åç§»å¯»å€è½¬æ¢æˆäº†æ­£å¸¸çš„å¯è¯»å…¥å­—ç¬¦ä¸²çš„å½¢å¼</span><br>predictions = labels.copy()<br>predictions[<span class="hljs-number">2</span>] = <span class="hljs-string">&quot;0&quot;</span><br>metric.compute(predictions= [predictions],reference = [labels])<br></code></pre></td></tr></table></figure>

<p>è®¡ç®—åº¦é‡å‡½æ•°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrcis</span>(<span class="hljs-params">eval_preds</span>):<br>    logis,labels = eval_preds<br>    predictions = np.argmax(logits,axis =-<span class="hljs-number">1</span>)<span class="hljs-comment">#true æ˜¯çœŸçš„å€¼,predictionæ˜¯ä¸€ä¸ªä»¥è®­ç»ƒç»“æœå¯¼å‡ºæ¥çš„å€¼</span><br>    true_labels = [[label_namse[l] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> label <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels] <span class="hljs-comment"># å•¥?</span><br>    true_predictions = [ [label_name[p] <span class="hljs-keyword">for</span> (p,l) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction,label) <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>] <span class="hljs-keyword">for</span> prediction,label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions,labels)]<br>    all_metrics = metrci.compute(predictions = ture_predictions, references = true_labels)<br><br></code></pre></td></tr></table></figure>

<h4 id="defining-the-Model"><a href="#defining-the-Model" class="headerlink" title="defining the Model"></a>defining the Model</h4><p>è®¾ç½®ä¸€ä¸ªç›¸åçš„å­—å…¸</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">id2label = &#123;i:label <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(label_names)&#125;<br>lable2id = &#123;v,k <span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> id2label.items()&#125;<br></code></pre></td></tr></table></figure>
<p>åœ¨ä¼ å…¥ç›¸å…³çš„æ¨¡å‹</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification<br>model = AutoModelForTokenClassification.from_pretrained(<br>    model_checkpoint,<br>    id2label = id2label<br>    label2id = label2id<br>)<br></code></pre></td></tr></table></figure>

<h4 id="Fine-tuning-the-model"><a href="#Fine-tuning-the-model" class="headerlink" title="Fine-tuning the model"></a>Fine-tuning the model</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login<br>notebook_login()<br><span class="hljs-comment">#è°ƒç”¨è®­ç»ƒå‚æ•°</span><br><span class="hljs-keyword">from</span> transformes <span class="hljs-keyword">import</span> TrainingArguments<br>args = TrainingArguments(<br>    <span class="hljs-string">&quot;bert-finetune-ner&quot;</span>,<br>    evaluation_strategy = <span class="hljs-string">&quot;epoch&quot;</span>,<br>    save_strategy = <span class="hljs-string">&quot;epoch&quot;</span>,<br>    learning_rate = <span class="hljs-number">2e05</span>,<br>    num_train_epochs= <span class="hljs-number">3</span><br>    weight_decay= <span class="hljs-number">0.01</span>.<br>    push_to_hub = <span class="hljs-literal">True</span>,<br>)<br><span class="hljs-comment">#æ„å»ºä¸€ä¸ªtrainer</span><br><span class="hljs-keyword">from</span>  transformers <span class="hljs-keyword">import</span> Trainer<br><br>trainer = Trainer(<br>    model = model,<br>    args =args,<br>    train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],<br>    eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],<br>    data_collator = data_collator,<br>    compyte_metrics= compute_metrics,<br>    tokenizer = tokenizer,<br>)<br>trainer.train()<br>trainer.push_to_hub(commit_message= <span class="hljs-string">&quot;Training complete&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>ä»¥ä¸Šçš„æ¨¡å‹åœ¨æ¯ä¸€æ¬¡è®­ç»ƒçš„æ—¶å€™,éƒ½ä¼šä¸Šä¼ åˆ°hubä¸­</p>
<h4 id="ä¼ ç»Ÿçš„è®­ç»ƒæµç¨‹ä¸¾ä¾‹"><a href="#ä¼ ç»Ÿçš„è®­ç»ƒæµç¨‹ä¸¾ä¾‹" class="headerlink" title="ä¼ ç»Ÿçš„è®­ç»ƒæµç¨‹ä¸¾ä¾‹"></a>ä¼ ç»Ÿçš„è®­ç»ƒæµç¨‹ä¸¾ä¾‹</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>train_dataloader = DataLoader(<br>    tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],<br>    shuffle = <span class="hljs-literal">True</span>,<br>    collate_fn = data_collator,<br>    batch_size = <span class="hljs-number">8</span>,<br><br>)<br>eval_dataloader = DataLoader(<br>    tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],<br>    collate_fn= data_collator,<br>    batch_size = <span class="hljs-number">8</span><br>)<br><br><span class="hljs-comment">#æ„å»ºæ¨¡å‹</span><br><br>model = AutoModelForTokenXlassification.from_pretrained(<br>    model_checkpoint,<br>    id2label = id2label,<br>    label2id  = label2id,<br>)<br><br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW<br>optimizer = AdamW(model.parameters(),lr= <span class="hljs-number">2e-5</span>)<br><br><span class="hljs-comment">#åŠ é€Ÿå™¨æ¨¡å—</span><br><br><span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator<br>accelerator = Accelerator()<br>modle,optimizer,train_dataloader,eval_dataloader = accelerator.prepare(<br>    modle,optimizer,train_dataloader,eval_dataloader<br>)<br><br><span class="hljs-comment">#???</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler<br>num_train_epochs = <span class="hljs-number">3</span><br>num_update_steps_per_epoch = <span class="hljs-built_in">len</span>(train_dataloader)<br>num_training_steps = num_train_epochs * num_update_steps_per_epoch <span class="hljs-comment">#å…¨éƒ¨è®­ç»ƒå®Œçš„epoch</span><br>lr_scheduler = get_scheduler(<br>    <span class="hljs-string">&quot;linear&quot;</span>,<br>    optimizer = optimizer.<br>    num_warmup_steps = <span class="hljs-number">0</span>,<br>    num_training_steps = num_training_steps<br>)<br><br></code></pre></td></tr></table></figure>

<h4 id="ä¸Šä¼ åˆ°ä»“åº“"><a href="#ä¸Šä¼ åˆ°ä»“åº“" class="headerlink" title="ä¸Šä¼ åˆ°ä»“åº“"></a>ä¸Šä¼ åˆ°ä»“åº“</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository,get_full_repo_name<br>model_name = <span class="hljs-string">&quot;bert-finetune-ner-accelerate&quot;</span><br>repo_name = get_full_repo_name(model_name)<span class="hljs-comment">#åŠ ä¸ŠåŸæ¥çš„åœ°å€.</span><br><br></code></pre></td></tr></table></figure>

<h4 id="Train-loop"><a href="#Train-loop" class="headerlink" title="Train loop"></a>Train loop</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">postprocess</span>(<span class="hljs-params">predictions,labels</span>):<br>    predictions = predictions.detach().cpu().clone().numpy()<br>    labels = labels.detach().cpu().clone().numpy()<br>    <span class="hljs-comment">#ä»GPUä¸­æ‹·è´æ•°æ®å¹¶è½¬æ¢ä¸ºnumpyæ•°æ®</span><br><br>    true_labels = [ [label_names[l] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> label <span class="hljs-keyword">if</span> l != <span class="hljs-number">100</span>] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels]<br>    true_predictions = [ [label_names[p] <span class="hljs-keyword">for</span> (p,l) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction,label) <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>]<br>    <span class="hljs-keyword">for</span> prediction , label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, labels)]<br>    <span class="hljs-keyword">return</span> true_labels,true_predictions<br><br><span class="hljs-comment">#è®­ç»ƒä¸­</span><br><span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> torch<br>progress_bar = tqdm((<span class="hljs-built_in">range</span>(num_training_steps)))<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_train_epochs):<br>    model.train()<br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:<br>        outputs = model(**batch)<br>        loss = outputs.loss<br>        accelerator.backward(loss)<br>        optimizer.step()<br>        lr_scheduler.step()<br>        optimizer.zero_grad()<br>        progress_bar.update(<span class="hljs-number">1</span>)<br>    <br>    model.<span class="hljs-built_in">eval</span>()<br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> eval_dataloader:<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            outputs = model(**batch)<br>        <br>        predictions = outputs/logits.argmax(dim=-<span class="hljs-number">1</span>)<br>        labels = batch[<span class="hljs-string">&quot;labels&quot;</span>]<br></code></pre></td></tr></table></figure>

<p>éƒ¨åˆ†è·³è¿‡ğŸ¤£ğŸ‘‰ğŸ»ğŸ¤¡</p>
<h3 id="Fine-tuning-a-masked-language-model"><a href="#Fine-tuning-a-masked-language-model" class="headerlink" title="Fine-tuning a masked language model"></a>Fine-tuning a masked language model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMaskedLM<br>model_checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased&quot;</span><br>model = AutoModelForMaskedLM.from_pretrained(model_Checkpoint)<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br>tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)<br><br><span class="hljs-keyword">import</span> torch<br>inputs = tokenizer(text,return_tensors= <span class="hljs-string">&quot;pt&quot;</span>)<span class="hljs-comment">#æŒ‰ç…§pytorchå¼ é‡è¾“å‡º</span><br>token_logits = modle(**inputs).logits<br>mask_token_index = torch.where(inputs[input_ids]== tokenizer.mask_token_id)[<span class="hljs-number">1</span>]<br>mask_token_logits = token_logits[<span class="hljs-number">0</span>,mask_token_index,:]<br>top_5_token = torch.topk(mask_token_logits,<span class="hljs-number">5</span>,dim = <span class="hljs-number">1</span>).indices[<span class="hljs-number">0</span>],tolist()<br><br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>imdb_dataset = load_dataset(<span class="hljs-string">&quot;imdb&quot;</span>)<br>sample = imdb_dataset[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>))<br><span class="hljs-comment">#æ³¨æ„å¯ä»¥é€šè¿‡æ•°æ®é›†çš„ç‰¹å®šéƒ¨åˆ†çš„.shuffleæ¥é€‰æ‹©æ‰“ä¹±æ•°æ®é›†</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):<br>    result = tokenizer(examples[<span class="hljs-string">&quot;text&quot;</span>])<br>    <span class="hljs-keyword">if</span> tokenizer.is_fast:<br>        result[<span class="hljs-string">&quot;word_ids&quot;</span>] = [result.word_ids(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(result[<span class="hljs-string">&quot;input_ids&quot;</span>]))] <span class="hljs-comment">#word_idsç›¸å½“äºåˆ†è¯å™¨æ˜ å°„åˆ°äº†ç¬¬å‡ ä¸ªå•è¯ä¸Šé¢ è¿™é‡Œç›¸å½“äºå¯¹äºä¸åŒçš„å¥å­ç»„å»ºç«‹äº†ä¸åŒçš„å€¼</span><br>    <span class="hljs-keyword">return</span> result<br><br>tokenizer.model_max_length <span class="hljs-comment"># åˆ†è¯å™¨æœ€å¤§çš„æ–‡æœ¬å®¹çº³é‡</span><br><br><span class="hljs-comment">#è¿é”</span><br>tokenized_samples = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][:<span class="hljs-number">3</span>]<br><span class="hljs-keyword">for</span> idx,sample <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tokenized_samples[<span class="hljs-string">&quot;input_ids&quot;</span>]):<br>    <span class="hljs-built_in">print</span>(f <span class="hljs-string">&quot;&gt;&gt;&#123;ids&#125;&quot;</span>)<br><br><br>concatenated_examples = &#123;<br>    <span class="hljs-comment">#ä»¥ä¸‹ç›¸å½“äºæŠŠå¤šä¸ªä¸åŒçš„åˆ—è¡¨åˆæˆä¸ºä¸€ä¸ªå…±åŒçš„åˆ—è¡¨</span><br>    k:<span class="hljs-built_in">sum</span>(tokenized_samples[k],[]) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> examples.keys()<span class="hljs-comment">#ç”Ÿæˆå­—å…¸çš„é”®çš„å€¼</span><br>&#125;<span class="hljs-comment"># kæ˜¯ä¸€ç³»åˆ—çš„é”®</span><br>total_length = <span class="hljs-built_in">len</span>(concatenated_examples[<span class="hljs-string">&quot;input_ids&quot;</span>]) <span class="hljs-comment">#951</span><br><br>Chunk = &#123;<br>    k:[t[i:i+chunk_size] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,total_length,chunk_size)]<br>    <span class="hljs-keyword">for</span> k ,t <span class="hljs-keyword">in</span> concatenated_exampls.items() <span class="hljs-comment">#ç›¸å½“äºå…ƒç´ çš„æ•´åˆå†æŒ‰ç…§chunk_sizeçš„åˆ‡å‰²</span><br>&#125;<br><br><br><br></code></pre></td></tr></table></figure>
<p><strong>åŒæ—¶å¯¹äºæœ€åä¸€ä¸ªchunkå‡ºç°çš„ä¸å‡åŒ€çš„æƒ…å†µ,é‡‡ç”¨ç›´æ¥å¡«å……,æˆ–è€…ç›´æ¥ä¸¢å¼ƒçš„æ–¹æ³•</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">group_texts</span>(<span class="hljs-params">examples</span>):<br>    concatenated_examples = &#123;k:<span class="hljs-built_in">sum</span>(examples[k],[]) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> examples.keys()&#125;<br>    total_length = <span class="hljs-built_in">len</span>(concatenated_examples[<span class="hljs-built_in">list</span>(examples.keys())[<span class="hljs-number">0</span>]])<br>    total_length = (total_length // chunk_size) *chunk_size<br><br>    result = &#123;<br>        k:[t[i:i+chunk_size]<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,total_legth,chunk_size)] <span class="hljs-keyword">for</span> k,t inconcatenated_examples.items()<br>    &#125;<br><br>    result[<span class="hljs-string">&quot;labels&quot;</span>]= result[<span class="hljs-string">&quot;input_ids&quot;</span>].copy()<br>    <span class="hljs-keyword">return</span> result<br><br>lm_datasets = tokenzied_datasets.<span class="hljs-built_in">map</span>(group_texts,batched = <span class="hljs-literal">True</span>)    <br><br></code></pre></td></tr></table></figure>

<h4 id="Fine-tuning-DistilBERt-with-the-Trainer-API"><a href="#Fine-tuning-DistilBERt-with-the-Trainer-API" class="headerlink" title="Fine-tuning DistilBERt with the Trainer API"></a>Fine-tuning DistilBERt with the Trainer API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformer <span class="hljs-keyword">import</span> DataCollatorForlanguageModeling<br>data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer,mlm_probability = <span class="hljs-number">0.15</span> )<br><br>samples = [lm_dataset[<span class="hljs-string">&quot;train&quot;</span>][i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>)]<br><span class="hljs-keyword">for</span> sample <span class="hljs-keyword">in</span> samples:<br>    _ = sample.popp(<span class="hljs-string">&quot;word_ids&quot;</span>) <span class="hljs-comment">#è¿™ä¸ªä¼šå¼¹å‡ºkeyå¯¹åº”çš„value å¹¶åˆ é™¤è¿™ä¸ªé”®å¯¹å€¼</span><br><br><span class="hljs-keyword">import</span> collections<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> default_data_collator<br><br>ww_prolbability = <span class="hljs-number">0.2</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">whole_word_masking_data_collator</span>(<span class="hljs-params">features</span>):<br>    <span class="hljs-comment">#featuresæ˜¯æœ€å¤–çš„å­—å…¸</span><br>    <span class="hljs-comment">#featureæ˜¯ é”®å¯¹å€¼</span><br>    <span class="hljs-keyword">for</span> feature <span class="hljs-keyword">in</span> features:<br>        word_ids = feature.pop(<span class="hljs-string">&quot;word_ids&quot;</span>)<br>        mapping = collections.defaultdict(<span class="hljs-built_in">list</span>) <span class="hljs-comment">#mappingå†…éƒ¨å…ƒç´ æ˜¯ä¸€ç§åˆ—è¡¨</span><br>        current_word_index = -<span class="hljs-number">1</span><br>        current_word = <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">for</span> idx,word_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(word_ids):<br>            <span class="hljs-keyword">if</span> word_id <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                <span class="hljs-keyword">if</span> word_id != current_word:<br>                    current_word = word_id<br>                    <span class="hljs-comment">#å•è¯æ•°é‡åŠ 1</span><br>                    current_word_index += <span class="hljs-number">1</span><br>                mapping[current_word_index].append(idx)<span class="hljs-comment">#åœ¨å½“å‰å•è¯çš„ä½ç½®ä¸Šæ˜ å°„å¯¹åº”çš„tokençš„ä½ç½®</span><br>    <span class="hljs-comment"># éšæœºçš„é®è”½ç›¸å…³çš„å­—ç¬¦</span><br>    mask = np.random.binomial(<span class="hljs-number">1</span>,wwm_probability,(<span class="hljs-built_in">len</span>(mapping))) <span class="hljs-comment">#åœ¨mappingä¸Šçš„æ¯ä¸€ä¸ªå…ƒç´ éƒ½åšäºŒé¡¹åˆ†å¸ƒ,æ¦‚ç‡æœ‰wwmç”Ÿæˆ,åŒæ—¶ç”Ÿæˆä¸€ä¸ªåˆ—è¡¨ å«æœ‰1,0ç­‰å…ƒç´  </span><br>    <span class="hljs-comment">#è¿™é‡Œæ»¡è¶³äº†ä¸€æ•´ä¸ªå•è¯é®è”½çš„æ–¹å¼</span><br><br><br>    <span class="hljs-comment">#åŒæ—¶åŸæ¥çš„labelså’Œinput_idséƒ½æ˜¯ä¿ç•™ä¸€æ ·çš„å€¼</span><br>    input_ids = feature[<span class="hljs-string">&quot;input_ids&quot;</span>] <br>    labels = feautre[<span class="hljs-string">&quot;labels&quot;</span>]<br>    new_labels = [-<span class="hljs-number">100</span>] *<span class="hljs-built_in">len</span>(labels) <span class="hljs-comment">#åˆ›å»ºä¸€ä¸ªé•¿åº¦ä¸ºlen æ¯ä¸€ä¸ªå…ƒç´ éƒ½æ˜¯[ -100]çš„åˆ—è¡¨ , </span><br>    <span class="hljs-keyword">for</span> word_id <span class="hljs-keyword">in</span> np.where(mask)[<span class="hljs-number">0</span>]: <span class="hljs-comment">#å½“ä½œå¸ƒå°”è¡Œä»£æ•°æ¥çœ‹</span><br>        word_id = word_id.item()<br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> mapping[word_id]:<br>            new_labels[idx] = labels[idx] <span class="hljs-comment">#å…¶ä»–çš„é»˜è®¤æ˜¯-100? è¿™é‡Œä¿ç•™ç€é®è”½çš„é‚£äº›è¯?</span><br>            input_ids[idx] = tokenizer.mask_token_id <span class="hljs-comment">#è¿™é‡Œåº”è¯¥æ˜¯ç›¸å½“äºé®è”½äº†?</span><br><br>    feature[<span class="hljs-string">&quot;labels&quot;</span>] = new_labels<br><br>    <span class="hljs-keyword">return</span> default_data_collator(features)<br><br>train_size =<span class="hljs-number">10_000</span><br>test_size = <span class="hljs-built_in">int</span>(<span class="hljs-number">0.1</span> * train_size) <span class="hljs-comment">#int() è¡¨ç¤ºç±»å‹è½¬æ¢ä¸ºæ•´æ•°</span><br><br>downsampled_dataset = lm_datasets[<span class="hljs-string">&quot;train&quot;</span>].train_test_split(<br>    train_size = train_size, test_size=test_size, seed = <span class="hljs-number">42</span><br>)<br><br></code></pre></td></tr></table></figure>

<h4 id="è®­ç»ƒæ•°æ®åº“"><a href="#è®­ç»ƒæ•°æ®åº“" class="headerlink" title="è®­ç»ƒæ•°æ®åº“"></a>è®­ç»ƒæ•°æ®åº“</h4><p>ç»™trainerå®šä¹‰å‚æ•°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transfromers <span class="hljs-keyword">import</span> TrainingArguments<br><br>batch_size = <span class="hljs-number">64</span><br>logging_steps = <span class="hljs-built_in">len</span>(downsampled_dataset[<span class="hljs-string">&quot;train&quot;</span>]) //batch_size<br>model_name = model_checkpoint.split(<span class="hljs-string">&quot;/&quot;</span>)[-<span class="hljs-number">1</span>] <span class="hljs-comment">#æŒ‰ç…§/çš„å½¢å¼åˆ‡å‰²,å¹¶å–å‡ºæœ€åä¸€ä¸ªå€¼</span><br>training_args = TrainingArguments(<br>    output_dir = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;model_name&#125;</span>-finetune-immdb&quot;</span>,<br>    overwrite_output_dir = <span class="hljs-literal">True</span>,<br>    evaluation_strategy = <span class="hljs-string">&quot;epocoh&quot;</span>,<br>    learning_rate = <span class="hljs-number">2e-5</span>,<br>    weight_decay = <span class="hljs-number">0.01</span>,<br>    per_device_train_batch_size = batch_size,<br>    per_device_eval_batch_size = batch_size,<br>    push_to_hub = <span class="hljs-literal">True</span>,<br>    fp16 = <span class="hljs-literal">True</span>,<br>    logging_steps = logging_steps,<br>)<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer<br>trainer = Trainer(<br>    model = model,<br>    args = training_args,<br>    train_dataset = downsampled_dataset[<span class="hljs-string">&quot;train&quot;</span>],<br>    eval_dataselt = downsampled_dataset[<span class="hljs-string">&quot;test&quot;</span>],<br>    data_collator = data_collator,<br>    tokenizer = tokenizer,<br>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">insert_random_mask</span>(<span class="hljs-params">batch</span>):<br>    features = [<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(batch,t)) <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(*batch.values())] <br>    <span class="hljs-comment">#zip(*batch.value())ä¼šå¯¹ä¸€ä¸ªkeyçš„ä¸œè¥¿å‹ç¼©æˆä¸ºä¸€ä¸ªå…ƒç»„é€šå¸¸ï¼Œå®ƒç”¨äºå°†å¤šä¸ªåˆ—è¡¨æˆ–åºåˆ—çš„å…ƒç´ æŒ‰ç…§ç›¸åŒç´¢å¼•ä½ç½®é…å¯¹åœ¨ä¸€èµ·ã€‚ </span><br>    <span class="hljs-comment">#tç›¸å½“äºæ˜¯ä¸€ä¸ªå…ƒç»„, ç”¨æ¯ä¸€ä¸ªkeyå’Œå…ƒç»„ä¸­çš„å…ƒç´ è¿›è¡Œé…å¯¹</span><br>    masked_inputs = data_collator(features)<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;masked_&quot;</span>+k:v.numpy()<span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> masked_inputs.items()&#125;<br>    <span class="hljs-comment">#è¿™ä¸ªç›¸å½“äºåœ¨åŸå­—å…¸ä¹‹å‰åŠ ä¸Šâ€œmasked_&quot;çš„å‰ç¼€</span><br><br>downsampled_dataset = downsampled_dataset.remove_columns([<span class="hljs-string">&quot;word_ids&quot;</span>])<br>eval_dataset = downsampled_dataset[<span class="hljs-string">&quot;test&quot;</span>].<span class="hljs-built_in">map</span>(<br>    insert_random_mask,<br>    batched = <span class="hljs-literal">True</span>,<br>    remove_columns = downsampled_dataset[<span class="hljs-string">&quot;test&quot;</span>].column_names,<br>)<br><br>eval_dataset = eval_dataset.rename_columns(<br>    &#123;<br>        <span class="hljs-string">&quot;masked_input_ids&quot;</span>: <span class="hljs-string">&quot;input_ids&quot;</span>,<br>        <span class="hljs-string">&quot;masked_attention_mask&quot;</span>: <span class="hljs-string">&quot;attention_mask&quot;</span>,<br>        <span class="hljs-string">&quot;masked_labels&quot;</span>: <span class="hljs-string">&quot;labels&quot;</span>,<br>    &#125;<br>)<br><br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> default_data_collator<br><br>batch_size =<span class="hljs-number">64</span><br>train_dataloader = DataLoader(<br>    downsampled_dataset[<span class="hljs-string">&quot;train&quot;</span>],<br>    shuffle = <span class="hljs-literal">True</span>,<br>    batch_size = batch_size,<br>    collate_fn = data_collator<br>)<br><br>eval_dataloader = DataLoader(<br>    eval_dataset,batch_size = batch_size.collate_fn = default_data_collator<br>)<br><br>model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW<br>optimizer = AdamW(model.parameters(),lr= <span class="hljs-number">5e-5</span>)<br><br><span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator<br><br>accelerator = Accelerator()<br>model,optimizer,train_dataloader,eval_dataloader = accelerator.prepare(<br>    model,optimizer,train_dataloader,eval_dataloader<br>)<br><br></code></pre></td></tr></table></figure>

<h3 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h3><h4 id="loaddata"><a href="#loaddata" class="headerlink" title="loaddata"></a>loaddata</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br>raw_datasets = load_dataset(<span class="hljs-string">&quot;kde4&quot;</span>, lang1=<span class="hljs-string">&quot;en&quot;</span>, lang2=<span class="hljs-string">&quot;fr&quot;</span>)<br>split_datasets = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].train_test_split(train_size=<span class="hljs-number">0.9</span>, seed=<span class="hljs-number">20</span>) <span class="hljs-comment">#é€‰æ‹©è®­ç»ƒé›†å’Œæµ‹è¯•é›†</span><br><br>split_datasets[<span class="hljs-string">&quot;validation&quot;</span>] = split_datasets.pop(<span class="hljs-string">&quot;test&quot;</span>) <span class="hljs-comment">#é‡å‘½å</span><br><br>split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>] <span class="hljs-comment">#ä¸¤ç§id å’Œtranslation-&gt;å­—å…¸ åŒæ—¶en,fr</span><br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>model_checkpoint = <span class="hljs-string">&quot;Helsinki-NLP/opus-mt-en-fr&quot;</span><br>translator = pipeline(<span class="hljs-string">&quot;translation&quot;</span>, model=model_checkpoint)<br>translator(<span class="hljs-string">&quot;Default to expanded threads&quot;</span>)<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>model_checkpoint = <span class="hljs-string">&quot;Helsinki-NLP/opus-mt-en-fr&quot;</span><br>tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br><br><span class="hljs-comment">#tokenizerå®Œæˆ</span><br><br>en_sentence = split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>][<span class="hljs-string">&quot;en&quot;</span>]<br>fr_sentence = split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>][<span class="hljs-string">&quot;fr&quot;</span>]<br><br>inputs = tokenizer(en_sentence, text_target=fr_sentence)<br><br><span class="hljs-comment">#inputç»“æœç”Ÿæˆ</span><br>&#123;<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">47591</span>, <span class="hljs-number">12</span>, <span class="hljs-number">9842</span>, <span class="hljs-number">19634</span>, <span class="hljs-number">9</span>, <span class="hljs-number">0</span>], <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&#x27;labels&#x27;</span>: [<span class="hljs-number">577</span>, <span class="hljs-number">5891</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3184</span>, <span class="hljs-number">16</span>, <span class="hljs-number">2542</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1710</span>, <span class="hljs-number">0</span>]&#125;<br><span class="hljs-comment">#æ²¡æœ‰ç†è§£é”™è¯¯çš„æƒ…å†µä¸‹:input_idsåº”è¯¥ç”¨çš„æ˜¯å¯¹åº”çš„æ¯ä¸€ä¸ªå•è¯åœ¨è¯­æ–™åº“çš„ä½ç½®,labelså¯¹åº”çš„æ³•è¯­çš„ä½ç½® #åŒæ—¶è¿™ä¸ªæ³¨æ„è¦æŒ‡å®šå‚æ•°</span><br><span class="hljs-built_in">print</span>(tokenizer.convert_ids_to_tokens(inputs[<span class="hljs-string">&quot;labels&quot;</span>])) <span class="hljs-comment">#è¿™é‡Œç”¨çš„æ˜¯æŠŠidè½¬æ¢æˆtokensçš„ä¸€ç§å‡½æ•°æ‰èƒ½åˆç†çš„çœ‹å‡ºæ˜¯ä»€ä¹ˆä¸œè¥¿</span><br><br>max_length = <span class="hljs-number">128</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):<br>    inputs = [ex[<span class="hljs-string">&quot;en&quot;</span>] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;translation&quot;</span>]]<br>    targets = [ex[<span class="hljs-string">&quot;fr&quot;</span>] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;translation&quot;</span>]]<br>    <span class="hljs-comment">#åˆ‡å‰²</span><br>    model_inputs = tokenizer(<br>        inputs, text_target=targets, max_length=max_length, truncation=<span class="hljs-literal">True</span><br>    )<br>    <span class="hljs-keyword">return</span> model_inputs<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSeq2SeqLM<br><br>model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForSeq2Seq<br><br>data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)<br><span class="hljs-comment">#the padding value used to pad the labels should be -100 and not the padding token of the tokenizer, to make sure those padded values are ignored in the loss computation. it takes the tokenizer used to preprocess the inputs, but it also takes the model. This is because this data collator will also be responsible for preparing the decoder input IDs, which are shifted versions of the labels with a special token at the beginning. Since this shift is done slightly differently for different architectures, the DataCollatorForSeq2Seq needs to know the model object:</span><br><br><span class="hljs-comment">#for ex</span><br>batch = data_collator([tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)])<br>batch.keys()<br>dict_keys([<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;labels&#x27;</span>, <span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>])<br>batch[<span class="hljs-string">&quot;labels&quot;</span>]<br>batch[<span class="hljs-string">&quot;decoder_input_ids&quot;</span>]  <span class="hljs-comment"># see that they are shifted versions of the labels:</span><br><br></code></pre></td></tr></table></figure>

<h4 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> evaluate<br>metric = evaluate.load(<span class="hljs-string">&quot;sacrebleu&quot;</span>)<br>predictions = [<br>    <span class="hljs-string">&quot;This plugin lets you translate web pages between several languages automatically.&quot;</span><br>]<br>references = [<br>    [<br>        <span class="hljs-string">&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span><br>    ]<br>]<br><span class="hljs-comment"># the predictions should be a list of sentences, but the references should be a list of lists of sentences.</span><br><br>metric.compute(predictions=predictions, references=references)<span class="hljs-comment">#è°ƒç”¨å‡½æ•°è¯„åˆ¤ç¿»è¯‘ç»“æœçš„å¥½å</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_preds</span>):<br>    preds, labels = eval_preds<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(preds,<span class="hljs-built_in">tuple</span>):<span class="hljs-comment">#æ£€æŸ¥å¯¹è±¡ç±»å‹æ˜¯ä¸æ˜¯å…ƒç»„ //ä¸€ç§ç›¸å…³çš„å‡½æ•°</span><br>        preds = preds[<span class="hljs-number">0</span>]<br>    <br>    decoded_preds = tokenizer.batch_decode(preds,skip_special_toknes = <span class="hljs-literal">True</span>) <span class="hljs-comment">#è¿™é‡Œåº”è¯¥æ˜¯å·²ç»å®Œæˆäº†æ›¿æ¢,æ‰€ä»¥ä¸éœ€è¦åœ¨è¿™é‡Œè¿›è¡Œæ›´æ”¹</span><br>    labes = np.where(labels != -<span class="hljs-number">100</span>,labels,tokenizer.pad_token_id) <span class="hljs-comment">#åˆ†åˆ«ä»£è¡¨äº†æ£€ç´¢çš„å€¼,åœ¨å“ªæ£€ç´¢,ä¸ç¬¦åˆçš„å€¼æ›¿æ¢æˆä»€ä¹ˆ</span><br>    decoded_labels = tokenizer.batch_decode(labels,skip_special_tokens =<span class="hljs-literal">True</span>)<br><br>    decoded_preds = [pred.strip() <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> decoded_preds] <span class="hljs-comment">#å»é™¤å­—ç¬¦ä¸²ä¸¤ä¾§çš„ç©ºç™½å­—ç¬¦ï¼ˆåŒ…æ‹¬ç©ºæ ¼ã€åˆ¶è¡¨ç¬¦ã€æ¢è¡Œç¬¦ç­‰</span><br>    decoded_labels = [[label.strip()] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> decoded_labels]<br><br>    result = metric.compute(predictions=decoded_preds, references=decoded_labels) <span class="hljs-comment">#è®¡ç®—å‡ºç»“æœ</span><br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;bleu&quot;</span>: result[<span class="hljs-string">&quot;score&quot;</span>]&#125;<br></code></pre></td></tr></table></figure>
<p>è¯„ä¼°å‡½æ•°</p>
<h4 id="Fine-tuning-the-model-1"><a href="#Fine-tuning-the-model-1" class="headerlink" title="Fine-tuning the model"></a>Fine-tuning the model</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainingArguments<br><br>args = Seq2SeqTrainingArguments(<br>    <span class="hljs-string">f&quot;marian-finetuned-kde4-en-to-fr&quot;</span>,<br>    evaluation_strategy=<span class="hljs-string">&quot;no&quot;</span>,<br>    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>    learning_rate=<span class="hljs-number">2e-5</span>,<br>    per_device_train_batch_size=<span class="hljs-number">32</span>,<br>    per_device_eval_batch_size=<span class="hljs-number">64</span>,<br>    weight_decay=<span class="hljs-number">0.01</span>,<br>    save_total_limit=<span class="hljs-number">3</span>,<br>    num_train_epochs=<span class="hljs-number">3</span>,<br>    predict_with_generate=<span class="hljs-literal">True</span>,<br>    fp16=<span class="hljs-literal">True</span>,<br>    push_to_hub=<span class="hljs-literal">True</span>,<br>)<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainingArguments<br><br>args = Seq2SeqTrainingArguments(<br>    <span class="hljs-string">f&quot;marian-finetuned-kde4-en-to-fr&quot;</span>,<br>    evaluation_strategy=<span class="hljs-string">&quot;no&quot;</span>,<br>    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>    learning_rate=<span class="hljs-number">2e-5</span>,<br>    per_device_train_batch_size=<span class="hljs-number">32</span>,<br>    per_device_eval_batch_size=<span class="hljs-number">64</span>,<br>    weight_decay=<span class="hljs-number">0.01</span>,<br>    save_total_limit=<span class="hljs-number">3</span>,<br>    num_train_epochs=<span class="hljs-number">3</span>,<br>    predict_with_generate=<span class="hljs-literal">True</span>,<br>    fp16=<span class="hljs-literal">True</span>,<span class="hljs-comment">#åœ¨GPUä¸ŠåŠ é€Ÿè®­ç»ƒ</span><br>    push_to_hub=<span class="hljs-literal">True</span>,<br>)<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainer<br><br>trainer = Seq2SeqTrainer(<br>    model,<br>    args,<br>    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],<br>    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],<br>    data_collator=data_collator,<br>    tokenizer=tokenizer,<br>    compute_metrics=compute_metrics,<br>)<br></code></pre></td></tr></table></figure>

<h3 id="summation"><a href="#summation" class="headerlink" title="summation"></a>summation</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">english_dataset.set_format(<span class="hljs-string">&quot;pandas&quot;</span>)<span class="hljs-comment">#è½¬æ¢æ•°æ®ç±»å‹</span><br>english_df = english_dataset[<span class="hljs-string">&quot;train&quot;</span>][:]<br><span class="hljs-comment"># Show counts for top 20 products</span><br>english_df[<span class="hljs-string">&quot;product_category&quot;</span>].value_counts()[:<span class="hljs-number">20</span>]<span class="hljs-comment">#ç»Ÿè®¡å‡ºç°æ¬¡æ•°æœ€å¤šçš„ä¸¤ä¸ª</span><br><br><span class="hljs-comment">#æ•°æ®è¿‡æ»¤</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">filter_books</span>(<span class="hljs-params">example</span>):<br>    <span class="hljs-keyword">return</span> (<br>        example[<span class="hljs-string">&quot;product_category&quot;</span>] == <span class="hljs-string">&quot;book&quot;</span><br>        <span class="hljs-keyword">or</span> example[<span class="hljs-string">&quot;product_category&quot;</span>] == <span class="hljs-string">&quot;digital_ebook_purchase&quot;</span><br>    )<br><br>english_dataset.reset_format() <span class="hljs-comment">#é‡æ–°è®¾ç½®æ•°æ®çš„æ ¼å¼</span><br>spanish_books = spanish_dataset.<span class="hljs-built_in">filter</span>(filter_books) <span class="hljs-comment">#åº”è¯¥æ˜¯åˆ©ç”¨æ•°æ®çš„æ ¼å¼,æŒ‰ç…§è¿”å›å€¼æ¥è¿‡æ»¤æ•°æ®</span><br>english_books = english_dataset.<span class="hljs-built_in">filter</span>(filter_books)<br><br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> concatenate_datasets, DatasetDict<br><br>books_dataset = DatasetDict()<br><br><span class="hljs-keyword">for</span> split <span class="hljs-keyword">in</span> english_books.keys():<br>    books_dataset[split] = concatenate_datasets(<br>        [english_books[split], spanish_books[split]]<br>    ) <span class="hljs-comment">#è¿™é‡Œæ˜¯å–å‡ºç›¸å…³çš„æ ‡ç­¾ ç„¶ååˆ›å»ºä¸€è‡´çš„é‡.</span><br>    books_dataset[split] = books_dataset[split].shuffle(seed=<span class="hljs-number">42</span>)<br><br><span class="hljs-comment"># Peek at a few examples</span><br>show_samples(books_dataset) <span class="hljs-comment">#booksæ··å…¥ä¸¤ç§ä¸åŒè¯­è¨€çš„æ•°æ®é›†</span><br><br></code></pre></td></tr></table></figure>

<h4 id="æŸ¥çœ‹å†…å®¹"><a href="#æŸ¥çœ‹å†…å®¹" class="headerlink" title="æŸ¥çœ‹å†…å®¹"></a>æŸ¥çœ‹å†…å®¹</h4><p>å¯¹äºæ€»ç»“æ¥è¯´,è¿‡æ»¤æ‰å‡çŸ­çš„æ€»ç»“æ˜¯ä¸€ä»¶å¾ˆé‡è¦çš„äº‹æƒ…,å¦åˆ™ä¼šå¼•èµ·è¿™ç§çŸ­æ€»ç»“çš„bias</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python">books_dataset = books_dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x[<span class="hljs-string">&quot;review_title&quot;</span>].split()) &gt; <span class="hljs-number">2</span>)<span class="hljs-comment">#æŒ‰ç…§é‡Œé¢å€¼ä¸º1çš„æ–¹å¼è¿›è¡Œè¿‡æ»¤</span><br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>model_checkpoint = <span class="hljs-string">&quot;google/mt5-small&quot;</span><br>tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)<br><br><span class="hljs-comment">#è¾“å‡ºç»“æœ</span><br>&#123;<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">336</span>, <span class="hljs-number">259</span>, <span class="hljs-number">28387</span>, <span class="hljs-number">11807</span>, <span class="hljs-number">287</span>, <span class="hljs-number">62893</span>, <span class="hljs-number">295</span>, <span class="hljs-number">12507</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]&#125;<br><br>tokenizer.convert_ids_to_tokens(inputs.input_ids) <span class="hljs-comment">#åˆ†è¯è½¬æ¢çš„è¯­å¥</span><br>[<span class="hljs-string">&#x27;â–I&#x27;</span>, <span class="hljs-string">&#x27;â–&#x27;</span>, <span class="hljs-string">&#x27;loved&#x27;</span>, <span class="hljs-string">&#x27;â–reading&#x27;</span>, <span class="hljs-string">&#x27;â–the&#x27;</span>, <span class="hljs-string">&#x27;â–Hung&#x27;</span>, <span class="hljs-string">&#x27;er&#x27;</span>, <span class="hljs-string">&#x27;â–Games&#x27;</span>, <span class="hljs-string">&#x27;&lt;/s&gt;&#x27;</span>]<br><br>max_input_length = <span class="hljs-number">512</span><br>max_target_length = <span class="hljs-number">30</span><br><br><span class="hljs-comment">#è¿™é‡Œæ²¡æœ‰çœ‹æ‡‚....</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):<br>    model_inputs = tokenizer(<br>        examples[<span class="hljs-string">&quot;review_body&quot;</span>],<br>        max_length=max_input_length,<br>        truncation=<span class="hljs-literal">True</span>,<br>    )<br>    labels = tokenizer(<br>        examples[<span class="hljs-string">&quot;review_title&quot;</span>], max_length=max_target_length, truncation=<span class="hljs-literal">True</span><br>    )<br>    model_inputs[<span class="hljs-string">&quot;labels&quot;</span>] = labels[<span class="hljs-string">&quot;input_ids&quot;</span>]<br>    <span class="hljs-keyword">return</span> model_inputs<br><br></code></pre></td></tr></table></figure>

<h4 id="create-a-strong-yet-simple-baseline"><a href="#create-a-strong-yet-simple-baseline" class="headerlink" title="create a strong, yet simple baseline!"></a>create a strong, yet simple baseline!</h4><p>A common baseline for text summarization is to simply take the first three sentences of an article, often called the lead-3 baseline.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> nltk<br><br>nltk.download(<span class="hljs-string">&quot;punkt&quot;</span>)<br><br><span class="hljs-keyword">from</span> nltk.tokenize <span class="hljs-keyword">import</span> sent_tokenize<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">three_sentence_summary</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;\n&quot;</span>.join(sent_tokenize(text)[:<span class="hljs-number">3</span>])<br><br><br><span class="hljs-built_in">print</span>(three_sentence_summary(books_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;review_body&quot;</span>]))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_baseline</span>(<span class="hljs-params">dataset, metric</span>):<br>    summaries = [three_sentence_summary(text) <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> dataset[<span class="hljs-string">&quot;review_body&quot;</span>]]<br>    <span class="hljs-keyword">return</span> metric.compute(predictions=summaries, references=dataset[<span class="hljs-string">&quot;review_title&quot;</span>])<br><br><span class="hljs-comment">#ç›¸å½“äºç”¨æ–‡æœ¬çš„å‰ä¸‰å¥è¯ä½œä¸ºè¯„åˆ¤çš„æ ‡å‡†</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>score = evaluate_baseline(books_dataset[<span class="hljs-string">&quot;validation&quot;</span>], rouge_score)<br>rouge_names = [<span class="hljs-string">&quot;rouge1&quot;</span>, <span class="hljs-string">&quot;rouge2&quot;</span>, <span class="hljs-string">&quot;rougeL&quot;</span>, <span class="hljs-string">&quot;rougeLsum&quot;</span>]<br>rouge_dict = <span class="hljs-built_in">dict</span>((rn, <span class="hljs-built_in">round</span>(score[rn].mid.fmeasure * <span class="hljs-number">100</span>, <span class="hljs-number">2</span>)) <span class="hljs-keyword">for</span> rn <span class="hljs-keyword">in</span> rouge_names)<br>rouge_dict<br></code></pre></td></tr></table></figure>

<h2 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a>LangChain</h2><h3 id="chain"><a href="#chain" class="headerlink" title="chain"></a>chain</h3><p>èµ·åˆ°äº†ä¸²è”ä¸åŒçš„agentçš„ä½œç”¨</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Chain</span>(BaseModel, ABC):<br>    <span class="hljs-string">&quot;&quot;&quot;Base interface that all chains should implement.&quot;&quot;&quot;</span><br><br>    memory: BaseMemory<br>    callbacks: Callbacks<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        inputs: <span class="hljs-type">Any</span>,</span><br><span class="hljs-params">        return_only_outputs: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,</span><br><span class="hljs-params">        callbacks: Callbacks = <span class="hljs-literal">None</span>,</span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Any</span>]:<br>        ...<br><br><span class="hljs-comment">#use it</span><br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><br>llm = OpenAI(temperature=<span class="hljs-number">0.9</span>)<br>prompt = PromptTemplate(<span class="hljs-comment">#è¿™é‡Œåº”è¯¥æ˜¯åˆ›å»ºä¸€ä¸ªpromptçš„æ¨¡ç‰ˆ</span><br>    input_variables=[<span class="hljs-string">&quot;product&quot;</span>],<br>    template=<span class="hljs-string">&quot;What is a good name for a company that makes &#123;product&#125;?&quot;</span>,<br>)<br><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> LLMChain<br>chain = LLMChain(llm=llm, prompt=prompt)<span class="hljs-comment">#ä¼ å…¥ä¸¤ä¸ªå‚æ•°</span><br><br><span class="hljs-comment"># Run the chain only specifying the input variable.</span><br><span class="hljs-built_in">print</span>(chain.run(<span class="hljs-string">&quot;colorful socks&quot;</span>))<br><br><br><span class="hljs-keyword">from</span> langchain.chat_models <span class="hljs-keyword">import</span> ChatOpenAI<br><span class="hljs-keyword">from</span> langchain.prompts.chat <span class="hljs-keyword">import</span> (<br>    ChatPromptTemplate,<br>    HumanMessagePromptTemplate,<br>)<br>human_message_prompt = HumanMessagePromptTemplate(<br>        prompt=PromptTemplate(<br>            template=<span class="hljs-string">&quot;What is a good name for a company that makes &#123;product&#125;?&quot;</span>,<br>            input_variables=[<span class="hljs-string">&quot;product&quot;</span>],<br>        )<br>    )<br>chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])<br>chat = ChatOpenAI(temperature=<span class="hljs-number">0.9</span>)<br>chain = LLMChain(llm=chat, prompt=chat_prompt_template)<br><span class="hljs-built_in">print</span>(chain.run(<span class="hljs-string">&quot;colorful socks&quot;</span>))<br><br><span class="hljs-comment"># call chain</span><br>chat = ChatOpenAI(temperature=<span class="hljs-number">0</span>)<br>prompt_template = <span class="hljs-string">&quot;Tell me a &#123;adjective&#125; joke&quot;</span><br>llm_chain = LLMChain(llm=chat, prompt=PromptTemplate.from_template(prompt_template))<br><br>llm_chain(inputs=&#123;<span class="hljs-string">&quot;adjective&quot;</span>: <span class="hljs-string">&quot;corny&quot;</span>&#125;)<span class="hljs-comment">#ç”Ÿæˆåå¡«å…¥input</span><br>llm_chain(<span class="hljs-string">&quot;colorful socks&quot;</span>)<br><br><span class="hljs-comment"># åŒæ—¶ä¹Ÿå¯ä»¥é€‰æ‹©applyçš„æ–¹å¼,é€šè¿‡å¡«å…¥ä¸€ä¸ªåˆ—è¡¨,é‡Œé¢åˆ†åˆ«æ˜¯è¿™äº›å­—å…¸</span><br><br>input_list = [<br>    &#123;<span class="hljs-string">&quot;product&quot;</span>: <span class="hljs-string">&quot;socks&quot;</span>&#125;,<br>    &#123;<span class="hljs-string">&quot;product&quot;</span>: <span class="hljs-string">&quot;computer&quot;</span>&#125;,<br>    &#123;<span class="hljs-string">&quot;product&quot;</span>: <span class="hljs-string">&quot;shoes&quot;</span>&#125;<br>]<br><br>llm_chain.apply(input_list)<br>llm_chain.generate(input_list)<span class="hljs-comment">#ç›¸ä¼¼çš„åŠŸèƒ½,ä½†æ˜¯å†…å®¹ç±»å‹ä¸åŒ</span><br>llm_chain(<span class="hljs-string">&quot;corny&quot;</span>, return_only_outputs=<span class="hljs-literal">True</span>)<span class="hljs-comment">#å–æ¶ˆ</span><br>llm_chain.run(&#123;<span class="hljs-string">&quot;adjective&quot;</span>: <span class="hljs-string">&quot;corny&quot;</span>&#125;)<span class="hljs-comment">#ç­‰ä»·äºå¡«å…¥è¿™ä¸ªè¿è¡Œ,runé‡Œé¢å¿…é¡»å¡«å…¥å­—å…¸</span><br>llm_chain.predict(product=<span class="hljs-string">&quot;colorful socks&quot;</span>)<span class="hljs-comment">#è¿™é‡Œå¿…é¡»å¡«å…¥å…³é”®è¯è¿›è¡Œå®Œæˆ,å¦‚ä¸‹</span><br><br>template = <span class="hljs-string">&quot;&quot;&quot;Tell me a &#123;adjective&#125; joke about &#123;subject&#125;.&quot;&quot;&quot;</span><br>prompt = PromptTemplate(template=template, input_variables=[<span class="hljs-string">&quot;adjective&quot;</span>, <span class="hljs-string">&quot;subject&quot;</span>])<br>llm_chain = LLMChain(prompt=prompt, llm=OpenAI(temperature=<span class="hljs-number">0</span>))<br><br>llm_chain.predict(adjective=<span class="hljs-string">&quot;sad&quot;</span>, subject=<span class="hljs-string">&quot;ducks&quot;</span>)<br><br><span class="hljs-comment"># è¯­æ³•åˆ†æparsing the outputs</span><br><br><span class="hljs-comment">#å¿…é¡»å¸¦ä¸Šparsingçš„ä¿¡å·</span><br><span class="hljs-keyword">from</span> langchain.output_parsers <span class="hljs-keyword">import</span> CommaSeparatedListOutputParser<br><br>output_parser = CommaSeparatedListOutputParser()<br>template = <span class="hljs-string">&quot;&quot;&quot;List all the colors in a rainbow&quot;&quot;&quot;</span><br>prompt = PromptTemplate(template=template, input_variables=[], output_parser=output_parser)<br>llm_chain = LLMChain(prompt=prompt, llm=llm)<br><br>llm_chain.predict()<br>llm_chain.predict_and_parse()<br><br><br></code></pre></td></tr></table></figure>

<h3 id="modules"><a href="#modules" class="headerlink" title="modules"></a>modules</h3><h4 id="prompts"><a href="#prompts" class="headerlink" title="prompts"></a>prompts</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> PromptTemplate<br>prompt_template = PromptTemplate.from_template(<br>    <span class="hljs-string">&quot;Tell me a &#123;adjective&#125; joke about &#123;content&#125;.&quot;</span><br>)<span class="hljs-comment">#å¼•å·åŠ å…¥æŠ½è±¡å†…å®¹ formatå¯ä»¥æ”¾å…¥å®ä½“</span><br>prompt_template.<span class="hljs-built_in">format</span>(adjective=<span class="hljs-string">&quot;funny&quot;</span>, content=<span class="hljs-string">&quot;chickens&quot;</span>)<br><br>invalid_prompt = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;adjective&quot;</span>],<span class="hljs-comment">#å¯ä»¥ä»è¿™é‡Œä¹°ä½ çš„å­—å…¸å†…å®¹è¿›è¡Œæ¯”è¾ƒ</span><br>    template=<span class="hljs-string">&quot;Tell me a &#123;adjective&#125; joke about &#123;content&#125;.&quot;</span><br>)<br><br><span class="hljs-comment">#chat prompt template</span><br><br><br>template = ChatPromptTemplate.from_messages([<br>    (<span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;You are a helpful AI bot. Your name is &#123;name&#125;.&quot;</span>),<br>    (<span class="hljs-string">&quot;human&quot;</span>, <span class="hljs-string">&quot;Hello, how are you doing?&quot;</span>),<br>    (<span class="hljs-string">&quot;ai&quot;</span>, <span class="hljs-string">&quot;I&#x27;m doing well, thanks!&quot;</span>),<br>    (<span class="hljs-string">&quot;human&quot;</span>, <span class="hljs-string">&quot;&#123;user_input&#125;&quot;</span>),<span class="hljs-comment">#å¤šè½®äº¤æµ?</span><br>])<br><br>messages = template.format_messages(<br>    name=<span class="hljs-string">&quot;Bob&quot;</span>,<br>    user_input=<span class="hljs-string">&quot;What is your name?&quot;</span><span class="hljs-comment">#.format_messageså¯ä»¥ç”¨æ¥è¡¥å……ä¿¡æ¯</span><br>)<br><br><span class="hljs-comment"># few-shot prompt templates</span><br>examples = [<br>  &#123;<br>    <span class="hljs-string">&quot;question&quot;</span>: <span class="hljs-string">&quot;Who lived longer, Muhammad Ali or Alan Turing?&quot;</span>,<br>    <span class="hljs-string">&quot;answer&quot;</span>: <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Are follow up questions needed here: Yes.</span><br><span class="hljs-string">Follow up: How old was Muhammad Ali when he died?</span><br><span class="hljs-string">Intermediate answer: Muhammad Ali was 74 years old when he died.</span><br><span class="hljs-string">Follow up: How old was Alan Turing when he died?</span><br><span class="hljs-string">Intermediate answer: Alan Turing was 41 years old when he died.</span><br><span class="hljs-string">So the final answer is: Muhammad Ali</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>  &#125;] <span class="hljs-comment">#examplesè¡¨ç°å½¢å¼ä¸ºåˆ—è¡¨ä¸­åµŒå…¥ç›¸å…³çš„å­—å…¸</span><br>example_prompt = PromptTemplate(input_variables=[<span class="hljs-string">&quot;question&quot;</span>, <span class="hljs-string">&quot;answer&quot;</span>], template=<span class="hljs-string">&quot;Question: &#123;question&#125;\n&#123;answer&#125;&quot;</span>)<br><br><span class="hljs-built_in">print</span>(example_prompt.<span class="hljs-built_in">format</span>(**examples[<span class="hljs-number">0</span>]))<span class="hljs-comment">## **åœ¨pythonä¸­ä¼ é€’äº†å­—å…¸ä¸­çš„å¥å¯¹å€¼</span><br><br>prompt = FewShotPromptTemplate(<br>    examples=examples, <br>    example_prompt=example_prompt, <br>    suffix=<span class="hljs-string">&quot;Question: &#123;input&#125;&quot;</span>, <span class="hljs-comment">#æ·»åŠ ä¸€ä¸ªåç¼€</span><br>    input_variables=[<span class="hljs-string">&quot;input&quot;</span>],<span class="hljs-comment">#åŠ å…¥ä¸€ä¸ªinputä½œä¸ºä¸€ä¸ªè¾“å‡ºå˜é‡,æ”¾åœ¨åé¢ç”¨æ¥å¡«å…¥</span><br>)<br><br><span class="hljs-built_in">print</span>(prompt.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">input</span>=<span class="hljs-string">&quot;Who was the father of Mary Ball Washington?&quot;</span>))<span class="hljs-comment">#åŒæ—¶formatæ˜¯ç›´æ¥æŠŠè¿™ä¸ªå­—ç¬¦ä¸²ç”¨æ¥è¿”å›</span><br><br><span class="hljs-comment"># é€šè¿‡exampleselectorå®Œæˆç›¸å…³çš„æ“ä½œ</span><br><span class="hljs-keyword">from</span> langchain.prompts.example_selector <span class="hljs-keyword">import</span> SemanticSimilarityExampleSelector<br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> Chroma<br><span class="hljs-keyword">from</span> langchain.embeddings <span class="hljs-keyword">import</span> OpenAIEmbeddings<br>example_selector = SemanticSimilarityExampleSelector.from_examples(<br>    <span class="hljs-comment"># This is the list of examples available to select from.</span><br>    examples,<br>    <span class="hljs-comment"># This is the embedding class used to produce embeddings which are used to measure semantic similarity.</span><br>    OpenAIEmbeddings(),<br>    <span class="hljs-comment"># This is the VectorStore class that is used to store the embeddings and do a similarity search over.</span><br>    Chroma,<br>    <span class="hljs-comment"># This is the number of examples to produce.</span><br>    k=<span class="hljs-number">1</span><br>)<br><br><span class="hljs-comment"># Few-shot examples for chat models - API</span><br>langchain.prompts.few_shot.FewShotChatMessagePromptTemplate ç±»<br>examples = [<br>    &#123;<span class="hljs-string">&quot;input&quot;</span>: <span class="hljs-string">&quot;2+2&quot;</span>, <span class="hljs-string">&quot;output&quot;</span>: <span class="hljs-string">&quot;4&quot;</span>&#125;,<br>    &#123;<span class="hljs-string">&quot;input&quot;</span>: <span class="hljs-string">&quot;2+3&quot;</span>, <span class="hljs-string">&quot;output&quot;</span>: <span class="hljs-string">&quot;5&quot;</span>&#125;,<span class="hljs-comment">#ç›¸å½“äºä¸¤ä¸ª</span><br>]<br>example_prompt = ChatPromptTemplate.from_messages(<br>    [(<span class="hljs-string">&#x27;human&#x27;</span>, <span class="hljs-string">&#x27;&#123;input&#125;&#x27;</span>), (<span class="hljs-string">&#x27;ai&#x27;</span>, <span class="hljs-string">&#x27;&#123;output&#125;&#x27;</span>)]<br>)<br>few_shot_prompt = FewShotChatMessagePromptTemplate(<br>    examples=examples,<br>    <span class="hljs-comment"># This is a prompt template used to format each individual example.</span><br>    example_prompt=example_prompt,<br>)<br>final_prompt = ChatPromptTemplate.from_messages(<br>    [<br>        (<span class="hljs-string">&#x27;system&#x27;</span>, <span class="hljs-string">&#x27;You are a helpful AI Assistant&#x27;</span>),<br>        few_shot_prompt,<br>        (<span class="hljs-string">&#x27;human&#x27;</span>, <span class="hljs-string">&#x27;&#123;input&#125;&#x27;</span>),<br>    ]<br>)<br><br><span class="hljs-comment">#root chain</span><br><br><br></code></pre></td></tr></table></figure>
<h3 id="memory"><a href="#memory" class="headerlink" title="memory"></a>memory</h3><h4 id="store"><a href="#store" class="headerlink" title="store"></a>store</h4><p>å‘ƒå‘ƒ,æ„Ÿè§‰è¿™ä¸ªå•å…ƒæœ‰ç‚¹åƒå­˜åœ¨ç¬¬ä¸‰æ–¹åº“é‡Œé¢?</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#é€šè¿‡chatmessagehistortyç±»æ¥å®Œæˆç›¸å…³æ“ä½œ</span><br><span class="hljs-keyword">from</span> langchain.memory <span class="hljs-keyword">import</span> ChatMessageHistory<br>history = ChatMessageHistory()<br>history.add_user_message(<span class="hljs-string">&quot;HI&quot;</span>)<br>history.add_ai_message(<span class="hljs-string">&quot;what&#x27;s up?&quot;</span>)<br>history.messages<br>    [HumanMessage(content=<span class="hljs-string">&#x27;hi!&#x27;</span>, additional_kwargs=&#123;&#125;),<br>     AIMessage(content=<span class="hljs-string">&#x27;whats up?&#x27;</span>, additional_kwargs=&#123;&#125;)]<br><br><span class="hljs-comment">#for start</span><br><span class="hljs-keyword">from</span> langchain.memory <span class="hljs-keyword">import</span> ConversationBufferjMemory<br>memory = ConversationBufferMemory()<br>memory = ConversationBufferMemory(memory_key=<span class="hljs-string">&quot;chat_history&quot;</span>)<span class="hljs-comment">#æŠŠhistoryçš„é”®å€¼æ›´æ”¹</span><br>memory.chat_memory.add_user_message(<span class="hljs-string">&quot;hi!&quot;</span>)<br>memory.chat_memory.add_ai_message(<span class="hljs-string">&quot;what&#x27;s up?&quot;</span>)<br>memory.load_memory_variables(&#123;&#125;)<span class="hljs-comment">#åŒæ—¶å¯ä»¥å‘ç°é‡Œé¢æ”¾å…¥çš„æ˜¯å­—å…¸åŒæ—¶å«æœ‰historyä»¥åŠAI: å¯ä»¥ä½¿ç”¨</span><br><br>memory = ConversationBufferMemory(return_messages=<span class="hljs-literal">True</span>)<br>memory.chat_memory.add_user_message(<span class="hljs-string">&quot;hi!&quot;</span>)<br>memory.chat_memory.add_ai_message(<span class="hljs-string">&quot;what&#x27;s up?&quot;</span>)<br><span class="hljs-comment">#return list of memory</span><br><span class="hljs-comment">#å¯ä»¥é€šè¿‡input_keyä»¥åŠoutput_keyå®ç°å‚æ•°ç›¸å…³çš„æ–¹æ¡ˆ</span><br><br><span class="hljs-comment"># end to end</span><br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> LLMChain<br><span class="hljs-keyword">from</span> langchain.memory <span class="hljs-keyword">import</span> ConversationBufferMemory<br><br><br>llm = OpenAI(temperature=<span class="hljs-number">0</span>)<br><span class="hljs-comment"># Notice that &quot;chat_history&quot; is present in the prompt template</span><br>template = <span class="hljs-string">&quot;&quot;&quot;You are a nice chatbot having a conversation with a human.</span><br><span class="hljs-string"></span><br><span class="hljs-string">Previous conversation:</span><br><span class="hljs-string">&#123;chat_history&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">New human question: &#123;question&#125;</span><br><span class="hljs-string">Response:&quot;&quot;&quot;</span><br>prompt = PromptTemplate.from_template(template)<br><span class="hljs-comment"># Notice that we need to align the `memory_key`</span><br>memory = ConversationBufferMemory(memory_key=<span class="hljs-string">&quot;chat_history&quot;</span>)<br>conversation = LLMChain(<br>    llm=llm,<br>    prompt=prompt,<br>    verbose=<span class="hljs-literal">True</span>,<br>    memory=memory<br>)<br><span class="hljs-comment"># Notice that we just pass in the `question` variables - `chat_history` gets populated by memory</span><br>conversation(&#123;<span class="hljs-string">&quot;question&quot;</span>: <span class="hljs-string">&quot;hi&quot;</span>&#125;)<br><br><span class="hljs-comment"># Memory in LLMChain</span><br><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> LLMChain<br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> langchain.memory <span class="hljs-keyword">import</span> ConversationBufferMemory<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><br>template = <span class="hljs-string">&quot;&quot;&quot;You are a chatbot having a conversation with a human.</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;chat_history&#125;</span><br><span class="hljs-string">Human: &#123;human_input&#125;</span><br><span class="hljs-string">Chatbot:&quot;&quot;&quot;</span><br><br>prompt = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;chat_history&quot;</span>, <span class="hljs-string">&quot;human_input&quot;</span>], template=template<br>)<br><span class="hljs-comment">#è¿™ä¸ªåº”è¯¥ä»£è¡¨çš„æ˜¯å¯ä»¥åœ¨é‡Œé¢è¾“å…¥å˜é‡,åŒæ—¶é€šè¿‡æŒ‡æ˜input_variablesä¸ºå¤–éƒ¨å˜é‡,å¯ä»¥åœ¨ä¹‹åæ·»åŠ è¿›å»</span><br>memory = ConversationBufferMemory(memory_key=<span class="hljs-string">&quot;chat_history&quot;</span>)<br>llm = OpenAI()<br>llm_chain = LLMChain(<br>    llm=llm,<br>    prompt=prompt,<br>    verbose=<span class="hljs-literal">True</span>,<br>    memory=memory,<br>)<br><span class="hljs-comment">#langchainæä¾›äº†memortæ¥å£,åº”è¯¥å¯ä»¥è‡ªåŠ¨é“¾æ¥prompté‡Œçš„æ•°æ®ä»¥åŠmemoryé‡Œçš„æ•°æ®ä¸”æ ‡ç­¾ä¸ºchat_history</span><br>llm_chain.predict(human_input=<span class="hljs-string">&quot;Hi there my friend&quot;</span>) <span class="hljs-comment"># è¿™é‡Œé€šè¿‡å­—ç¬¦ä¸²çš„æ–¹å¼è¿›è¡Œé¢„æµ‹</span><br><br><br><span class="hljs-comment"># å¢åŠ è®°å¿†LLM</span><br><span class="hljs-keyword">from</span> langchain.chat_models <span class="hljs-keyword">import</span> ChatOpenAI<br><span class="hljs-keyword">from</span> langchain.schema <span class="hljs-keyword">import</span> SystemMessage<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder<br><br>prompt = ChatPromptTemplate.from_messages([<span class="hljs-comment"># ç»„åˆæ•°æ®çš„å½¢å¼</span><br>    SystemMessage(content=<span class="hljs-string">&quot;You are a chatbot having a conversation with a human.&quot;</span>), <span class="hljs-comment"># The persistent system prompt</span><br>    MessagesPlaceholder(variable_name=<span class="hljs-string">&quot;chat_history&quot;</span>), <span class="hljs-comment"># Where the memory will be stored.è®°å¿†å­˜å‚¨çš„key</span><br>    HumanMessagePromptTemplate.from_template(<span class="hljs-string">&quot;&#123;human_input&#125;&quot;</span>), <span class="hljs-comment"># Where the human input will injected</span><br>])<br>    <br>memory = ConversationBufferMemory(memory_key=<span class="hljs-string">&quot;chat_history&quot;</span>, return_messages=<span class="hljs-literal">True</span>)<br><br><br><span class="hljs-comment"># Memory in the Multi-Input Chain</span><br><span class="hljs-keyword">from</span> langchain.embeddings.openai <span class="hljs-keyword">import</span> OpenAIEmbeddings<br><span class="hljs-keyword">from</span> langchain.embeddings.cohere <span class="hljs-keyword">import</span> CohereEmbeddings<br><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> CharacterTextSplitter<br><span class="hljs-keyword">from</span> langchain.vectorstores.elastic_vector_search <span class="hljs-keyword">import</span> ElasticVectorSearch<br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> Chroma<br><span class="hljs-keyword">from</span> langchain.docstore.document <span class="hljs-keyword">import</span> Document<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../../state_of_the_union.txt&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    state_of_the_union = f.read()<br>text_splitter = CharacterTextSplitter(chunk_size=<span class="hljs-number">1000</span>, chunk_overlap=<span class="hljs-number">0</span>)<br>texts = text_splitter.split_text(state_of_the_union)<br><br>embeddings = OpenAIEmbeddings()<br>docsearch = Chroma.from_texts(<br>    texts, embeddings, metadatas=[&#123;<span class="hljs-string">&quot;source&quot;</span>: i&#125; <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(texts))]<br>)<span class="hljs-comment"># æŒ‰ç…§source textsæ¯ä¸€ä¸ªå•å…ƒéƒ½ä½œä¸ºåµŒå…¥æ•°æ®å¤„ç†</span><br>query = <span class="hljs-string">&quot;What did the president say about Justice Breyer&quot;</span><br>docs = docsearch.similarity_search(query) <span class="hljs-comment"># æ•°æ®åº“å¯ä»¥ç›´æ¥ä½¿ç”¨å…¶å¤„ç† .similarity_search()æ£€ç´¢</span><br><br><span class="hljs-keyword">from</span> langchain.chains.question_answering <span class="hljs-keyword">import</span> load_qa_chain<br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><span class="hljs-keyword">from</span> langchain.memory <span class="hljs-keyword">import</span> ConversationBufferMemory<br><br>template = <span class="hljs-string">&quot;&quot;&quot;You are a chatbot having a conversation with a human.</span><br><span class="hljs-string"></span><br><span class="hljs-string">Given the following extracted parts of a long document and a question, create a final answer.</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;context&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;chat_history&#125;</span><br><span class="hljs-string">Human: &#123;human_input&#125;</span><br><span class="hljs-string">Chatbot:&quot;&quot;&quot;</span><br><br>prompt = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;chat_history&quot;</span>, <span class="hljs-string">&quot;human_input&quot;</span>, <span class="hljs-string">&quot;context&quot;</span>], template=template<br>)<br>memory = ConversationBufferMemory(memory_key=<span class="hljs-string">&quot;chat_history&quot;</span>, input_key=<span class="hljs-string">&quot;human_input&quot;</span>)<span class="hljs-comment">#</span><br>chain = load_qa_chain(<br>    OpenAI(temperature=<span class="hljs-number">0</span>), chain_type=<span class="hljs-string">&quot;stuff&quot;</span>, memory=memory, prompt=prompt<br>)<br><span class="hljs-comment"># memory in agent</span><br><br>search = GoogleSearchAPIWrapper()<br>tools = [<br>    Tool(<span class="hljs-comment">#? </span><br>        name=<span class="hljs-string">&quot;Search&quot;</span>,<span class="hljs-comment">#ming ming</span><br>        func=search.run,<span class="hljs-comment">#å‡½æ•°åŠŸèƒ½</span><br>        description=<span class="hljs-string">&quot;useful for when you need to answer questions about current events&quot;</span>,<br>    )<br>]<span class="hljs-comment">#å¯ä»¥ä½¿ç”¨çš„åŠŸèƒ½</span><br><br><br>prefix = <span class="hljs-string">&quot;&quot;&quot;Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:&quot;&quot;&quot;</span><br>suffix = <span class="hljs-string">&quot;&quot;&quot;Begin!&quot;</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;chat_history&#125;</span><br><span class="hljs-string">Question: &#123;input&#125;</span><br><span class="hljs-string">&#123;agent_scratchpad&#125;&quot;&quot;&quot;</span><br><span class="hljs-comment"># </span><br>prompt = ZeroShotAgent.create_prompt(<br>    tools,<br>    prefix=prefix,<br>    suffix=suffix,<br>    input_variables=[<span class="hljs-string">&quot;input&quot;</span>, <span class="hljs-string">&quot;chat_history&quot;</span>, <span class="hljs-string">&quot;agent_scratchpad&quot;</span>],<br>)<span class="hljs-comment"># ? å¯ä»¥ç›´æ¥åµŒå…¥å‰ç¼€ä»¥åŠåç¼€å—</span><br><br>memory = ConversationBufferMemory(memory_key=<span class="hljs-string">&quot;chat_history&quot;</span>)<span class="hljs-comment">#æŒ‰ç…§ä¹‹å‰çš„</span><br><br>llm_chain = LLMChain(llm=OpenAI(temperature=<span class="hljs-number">0</span>), prompt=prompt)<br>agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=<span class="hljs-literal">True</span>)<span class="hljs-comment">#ä»£ç†äºº, å·¥å…·</span><br>agent_chain = AgentExecutor.from_agent_and_tools(<br>    agent=agent, tools=tools, verbose=<span class="hljs-literal">True</span>, memory=memory<br>)<span class="hljs-comment">#memory é‡æ–°åµŒå…¥agent_chain </span><br><br><br><br><br></code></pre></td></tr></table></figure>

<h3 id="retrieve-æ£€ç´¢å™¨"><a href="#retrieve-æ£€ç´¢å™¨" class="headerlink" title="retrieve æ£€ç´¢å™¨"></a>retrieve æ£€ç´¢å™¨</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># quick start!</span><br><br><br><span class="hljs-comment">#document loader - ex for csv-&gt;ä»¥é€—å·ä½œä¸ºåˆ†éš”çš„æ–‡ä»¶</span><br><span class="hljs-keyword">from</span> langchain.document_loaders.csv_loader <span class="hljs-keyword">import</span> CSVLoader<br>loader = CSVLoader(file_path = <span class="hljs-string">&#x27;./example_data/mllb_teams_2012.csv&#x27;</span>)<br>data = loader.load()<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;../../state_of_the_union.txt&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    state_of_the_union = f.read()<br><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> RecursiveCharacterTextSplitter<br>text_splitter = RecursiveCharacterTextSplitter(<br>    <span class="hljs-comment"># Set a really small chunk size, just to show.</span><br>    chunk_size = <span class="hljs-number">100</span>,<span class="hljs-comment">#æœ€é•¿æ•°é‡</span><br>    chunk_overlap  = <span class="hljs-number">20</span>,<span class="hljs-comment">#é‡å æ•°é‡</span><br>    length_function = <span class="hljs-built_in">len</span>,<br>    add_start_index = <span class="hljs-literal">True</span>,<span class="hljs-comment">#åˆ‡å‰²åçš„å¼€å§‹å­—ç¬¦åœ¨åŸæ¥çš„æ•°ç»„ä¸­çš„ä½ç½®</span><br>)<br><br><span class="hljs-comment">#---ä»¥ä¸Šç•¥å»äº†ä¸€äº›å…¶ä»–çš„åˆ‡å‰²æ–¹å¼</span><br><br><span class="hljs-comment">#Lost in the middle: The problem with long contexts:When models must access relevant information in the middle of long contexts, they tend to ignore the provided documents</span><br><span class="hljs-comment">#é‡‡ç”¨é‡æ–°æ‰“ä¹±çš„æ–¹å¼å®Œæˆ(æ£€ç´¢ä¹‹å)</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> chromadb<br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> Chroma<br><span class="hljs-keyword">from</span> langchain.embeddings <span class="hljs-keyword">import</span> HuggingFaceEmbeddings<br><span class="hljs-keyword">from</span> langchain.document_transformers <span class="hljs-keyword">import</span> (<br>    LongContextReorder,<br>)<br><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> StuffDocumentsChain, LLMChain<br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><br><span class="hljs-comment"># Get embeddings.</span><br>embeddings = HuggingFaceEmbeddings(model_name=<span class="hljs-string">&quot;all-MiniLM-L6-v2&quot;</span>)<br><br>texts = [<br>    <span class="hljs-string">&quot;Basquetball is a great sport.&quot;</span>,<br>    <span class="hljs-string">&quot;Fly me to the moon is one of my favourite songs.&quot;</span>,<br>    <span class="hljs-string">&quot;The Celtics are my favourite team.&quot;</span>,<br>    <span class="hljs-string">&quot;This is a document about the Boston Celtics&quot;</span>,<br>    <span class="hljs-string">&quot;I simply love going to the movies&quot;</span>,<br>    <span class="hljs-string">&quot;The Boston Celtics won the game by 20 points&quot;</span>,<br>    <span class="hljs-string">&quot;This is just a random text.&quot;</span>,<br>    <span class="hljs-string">&quot;Elden Ring is one of the best games in the last 15 years.&quot;</span>,<br>    <span class="hljs-string">&quot;L. Kornet is one of the best Celtics players.&quot;</span>,<br>    <span class="hljs-string">&quot;Larry Bird was an iconic NBA player.&quot;</span>,<br>]<br><br><span class="hljs-comment"># Create a retriever</span><br>retriever = Chroma.from_texts(texts, embedding=embeddings).as_retriever(<br>    search_kwargs=&#123;<span class="hljs-string">&quot;k&quot;</span>: <span class="hljs-number">10</span>&#125;<br>)<br>query = <span class="hljs-string">&quot;What can you tell me about the Celtics?&quot;</span><br><br><span class="hljs-comment"># Get relevant documents ordered by relevance score</span><br>docs = retriever.get_relevant_documents(query)<br>docs<br><span class="hljs-comment">#è¿™ä¸ªbä¸œè¥¿ç©¿æ¨¡äº†å§</span><br><br><span class="hljs-comment">#embedding</span><br><span class="hljs-keyword">from</span> langchain.embeddings <span class="hljs-keyword">import</span> OpenAIEmbeddings<br><br>embeddings_model = OpenAIEmbeddings()<span class="hljs-comment">#ç›´æ¥è®¾ç½®</span><br>embeddings = embeddings_model.embed_documents(<br>    [<br>        <span class="hljs-string">&quot;Hi there!&quot;</span>,<br>        <span class="hljs-string">&quot;Oh, hello!&quot;</span>,<br>        <span class="hljs-string">&quot;What&#x27;s your name?&quot;</span>,<br>        <span class="hljs-string">&quot;My friends call me World&quot;</span>,<br>        <span class="hljs-string">&quot;Hello World!&quot;</span><br>    ]<br>)<span class="hljs-comment">#åˆ†è§£çš„æ—¶å€™æ”¯æŒåˆ—è¡¨é‡Œçš„å¤šä¸ªå­—ç¬¦ä¸²çš„å½¢å¼</span><br><span class="hljs-built_in">len</span>(embeddings), <span class="hljs-built_in">len</span>(embeddings[<span class="hljs-number">0</span>])<span class="hljs-comment">#è¡¨ç¤ºæœ‰å¤šå°‘è¡Œçš„å˜é‡é•¿åº¦</span><br><br>embedded_query = embeddings_model.embed_query(<span class="hljs-string">&quot;What was the name mentioned in the conversation?&quot;</span>)<br>embedded_query[:<span class="hljs-number">5</span>]<span class="hljs-comment">#è¯¢é—®ä»¥åŠå…¶ä»–çš„å«æœ‰ä¸åŒçš„è¡¨å¾å½¢å¼</span><br><br><span class="hljs-comment">#æ”¯æŒcachingæŠ€æœ¯</span><br><span class="hljs-comment">#TODO</span><br><span class="hljs-comment">#Vector stores </span><br><span class="hljs-comment">#å­˜å‚¨embeddingå‘é‡åŒæ—¶ä¹‹åç”¨äºæŸ¥è¯¢çš„æ–¹å¼</span><br><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> TextLoader<br><span class="hljs-keyword">from</span> langchain.embeddings.openai <span class="hljs-keyword">import</span> OpenAIEmbeddings<br><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> CharacterTextSplitter<br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> FAISS<br><br><span class="hljs-comment"># Load the document, split it into chunks, embed each chunk and load it into the vector store.</span><br>raw_documents = TextLoader(<span class="hljs-string">&#x27;../../../state_of_the_union.txt&#x27;</span>).load()<br>text_splitter = CharacterTextSplitter(chunk_size=<span class="hljs-number">1000</span>, chunk_overlap=<span class="hljs-number">0</span>)<br>documents = text_splitter.split_documents(raw_documents)<span class="hljs-comment">#å·²ç»å®Œæˆç›¸å…³çš„åˆ‡å‰²äº†</span><br>db = FAISS.from_documents(documents, OpenAIEmbeddings())<br><span class="hljs-comment">#ç›¸ä¼¼æ€§çš„æŸ¥è¯¢</span><br>query = <span class="hljs-string">&quot;What did the president say about Ketanji Brown Jackson&quot;</span><br>docs = db.similarity_search(query)<br><span class="hljs-built_in">print</span>(docs[<span class="hljs-number">0</span>].page_content)<br><span class="hljs-comment">#vectoræŸ¥è¯¢</span><br>embedding_vector = OpenAIEmbeddings().embed_query(query)<br>docs = db.similarity_search_by_vector(embedding_vector)<br><span class="hljs-built_in">print</span>(docs[<span class="hljs-number">0</span>].page_content)<br><span class="hljs-comment">#ç»“æœä¸€è‡´</span><br><br><span class="hljs-comment">#retrieve QUICK START</span><br><span class="hljs-keyword">from</span> abc <span class="hljs-keyword">import</span> ABC, abstractmethod<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Any</span>, <span class="hljs-type">List</span><br><span class="hljs-keyword">from</span> langchain.schema <span class="hljs-keyword">import</span> Document<br><span class="hljs-keyword">from</span> langchain.callbacks.manager <span class="hljs-keyword">import</span> Callbacks<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BaseRetriever</span>(<span class="hljs-title class_ inherited__">ABC</span>):<br>    ...<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_relevant_documents</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self, query: <span class="hljs-built_in">str</span>, *, callbacks: Callbacks = <span class="hljs-literal">None</span>, **kwargs: <span class="hljs-type">Any</span></span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-type">List</span>[Document]:<br>        <span class="hljs-string">&quot;&quot;&quot;Retrieve documents relevant to a query.</span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            query: string to find relevant documents for</span><br><span class="hljs-string">            callbacks: Callback manager or list of callbacks</span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            List of relevant documents</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        ...<br><br>    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">aget_relevant_documents</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self, query: <span class="hljs-built_in">str</span>, *, callbacks: Callbacks = <span class="hljs-literal">None</span>, **kwargs: <span class="hljs-type">Any</span></span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-type">List</span>[Document]:<br>        <span class="hljs-string">&quot;&quot;&quot;Asynchronously get documents relevant to a query.</span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            query: string to find relevant documents for</span><br><span class="hljs-string">            callbacks: Callback manager or list of callbacks</span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            List of relevant documents</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        ...<br><br><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> RetrievalQA<br><span class="hljs-keyword">from</span> langchain.llms <span class="hljs-keyword">import</span> OpenAI<br><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> TextLoader<br>loader = TextLoader(<span class="hljs-string">&#x27;../state_of_the_union.txt&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf8&#x27;</span>)<br><span class="hljs-keyword">from</span> langchain.indexes <span class="hljs-keyword">import</span> VectorstoreIndexCreator<br>index = VectorstoreIndexCreator().from_loaders([loader])<span class="hljs-comment">#</span><br>query = <span class="hljs-string">&quot;What did the president say about Ketanji Brown Jackson&quot;</span><br>index.query_with_sources(query)<span class="hljs-comment">#è¿”å›ç›¸å…³çš„å­—ç¬¦ä¸²</span><br>query = <span class="hljs-string">&quot;What did the president say about Ketanji Brown Jackson&quot;</span><br>index.query_with_sources(query)<span class="hljs-comment">#å­—å…¸ å«æœ‰è¯¦ç»†çš„ç›¸å…³çš„æ–‡æœ¬</span><br>index.query(<span class="hljs-string">&quot;Summarize the general content of this document.&quot;</span>, retriever_kwargs=&#123;<span class="hljs-string">&quot;search_kwargs&quot;</span>: &#123;<span class="hljs-string">&quot;filter&quot;</span>: &#123;<span class="hljs-string">&quot;source&quot;</span>: <span class="hljs-string">&quot;../state_of_the_union.txt&quot;</span>&#125;&#125;&#125;)<span class="hljs-comment">#åŒæ—¶å¯ä»¥é€‰æ‹©è¿‡æ»¤çš„æ–¹å¼</span><br><br><br><span class="hljs-comment">#muliquery use</span><br><br><br><span class="hljs-comment"># Build a sample vectorDB</span><br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> Chroma<br><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> WebBaseLoader<br><span class="hljs-keyword">from</span> langchain.embeddings.openai <span class="hljs-keyword">import</span> OpenAIEmbeddings<br><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> RecursiveCharacterTextSplitter<br><br><span class="hljs-comment"># Load blog post</span><br>loader = WebBaseLoader(<span class="hljs-string">&quot;https://lilianweng.github.io/posts/2023-06-23-agent/&quot;</span>)<br>data = loader.load()<br><br><span class="hljs-comment"># Split</span><br>text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class="hljs-number">500</span>, chunk_overlap=<span class="hljs-number">0</span>)<br>splits = text_splitter.split_documents(data)<br><br><span class="hljs-comment"># VectorDB</span><br>embedding = OpenAIEmbeddings()<br>vectordb = Chroma.from_documents(documents=splits, embedding=embedding)<br><span class="hljs-comment">#chromaè¡¨ç¤ºsplitç”¨embeddingå¤„ç†åå­˜å…¥æ•°æ®åº“</span><br><span class="hljs-keyword">from</span> langchain.chat_models <span class="hljs-keyword">import</span> ChatOpenAI<br><span class="hljs-keyword">from</span> langchain.retrievers.multi_query <span class="hljs-keyword">import</span> MultiQueryRetriever<br><br>question = <span class="hljs-string">&quot;What are the approaches to Task Decomposition?&quot;</span><br>llm = ChatOpenAI(temperature=<span class="hljs-number">0</span>)<br>retriever_from_llm = MultiQueryRetriever.from_llm(<br>    retriever=vectordb.as_retriever(), llm=llm<br>)<br>unique_docs = retriever_from_llm.get_relevant_documents(query=question)<span class="hljs-comment">#è¡¨ç¤ºä¾æ®è¯¢é—®,è¿ç»­äº§ç”Ÿç›¸å…³çš„ç–‘é—®æ¥è¿›è¡Œæ£€ç´¢</span><br><span class="hljs-built_in">len</span>(unique_docs)<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span><br><span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> LLMChain<br><span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel, Field<span class="hljs-comment">#æ•°æ®éªŒè¯åº“ å¯ä»¥å®šä¹‰ä¸åŒåå­—çš„ç±»</span><br><span class="hljs-keyword">from</span> langchain.prompts <span class="hljs-keyword">import</span> PromptTemplate<br><span class="hljs-keyword">from</span> langchain.output_parsers <span class="hljs-keyword">import</span> PydanticOutputParser<br><br><br><span class="hljs-comment"># Output parser will split the LLM result into a list of queries</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LineList</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br>    <span class="hljs-comment"># &quot;lines&quot; is the key (attribute name) of the parsed output</span><br>    lines: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>] = Field(description=<span class="hljs-string">&quot;Lines of text&quot;</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LineListOutputParser</span>(<span class="hljs-title class_ inherited__">PydanticOutputParser</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__(pydantic_object=LineList)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">parse</span>(<span class="hljs-params">self, text: <span class="hljs-built_in">str</span></span>) -&gt; LineList:<br>        lines = text.strip().split(<span class="hljs-string">&quot;\n&quot;</span>)<br>        <span class="hljs-keyword">return</span> LineList(lines=lines)<br><br><br>output_parser = LineListOutputParser()<br><br>QUERY_PROMPT = PromptTemplate(<br>    input_variables=[<span class="hljs-string">&quot;question&quot;</span>],<br>    template=<span class="hljs-string">&quot;&quot;&quot;You are an AI language model assistant. Your task is to generate five </span><br><span class="hljs-string">    different versions of the given user question to retrieve relevant documents from a vector </span><br><span class="hljs-string">    database. By generating multiple perspectives on the user question, your goal is to help</span><br><span class="hljs-string">    the user overcome some of the limitations of the distance-based similarity search. </span><br><span class="hljs-string">    Provide these alternative questions seperated by newlines.</span><br><span class="hljs-string">    Original question: &#123;question&#125;&quot;&quot;&quot;</span>,<br>)<br>llm = ChatOpenAI(temperature=<span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># Chain</span><br>llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT, output_parser=output_parser)<br><br><span class="hljs-comment"># Other inputs</span><br>question = <span class="hljs-string">&quot;What are the approaches to Task Decomposition?&quot;</span><br><br><span class="hljs-comment"># æŒ‰æ—¶é—´æ£€ç´¢å®Œæˆ</span><br>scoring = semantic_similarity + (<span class="hljs-number">1.0</span> - decay_rate) ^ hours_passed<br><span class="hljs-comment">#æ¯ä¸€æ¬¡accesséƒ½éœ€è¦æ›´æ–°è‡ªå·±çš„è®°å¿†</span><br><span class="hljs-keyword">import</span> faiss<br><br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime, timedelta<br><span class="hljs-keyword">from</span> langchain.docstore <span class="hljs-keyword">import</span> InMemoryDocstore<br><span class="hljs-keyword">from</span> langchain.embeddings <span class="hljs-keyword">import</span> OpenAIEmbeddings<br><span class="hljs-keyword">from</span> langchain.retrievers <span class="hljs-keyword">import</span> TimeWeightedVectorStoreRetriever<br><span class="hljs-keyword">from</span> langchain.schema <span class="hljs-keyword">import</span> Document<br><span class="hljs-keyword">from</span> langchain.vectorstores <span class="hljs-keyword">import</span> FAISS<br><br><span class="hljs-comment"># Define your embedding model</span><br>embeddings_model = OpenAIEmbeddings()<br><span class="hljs-comment"># Initialize the vectorstore as empty</span><br>embedding_size = <span class="hljs-number">1536</span><br>index = faiss.IndexFlatL2(embedding_size)<br>vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore(&#123;&#125;), &#123;&#125;)<span class="hljs-comment">#vectorstore ç”¨äºæè¿°å­˜å…¥çš„æ–¹å¼</span><br>retriever = TimeWeightedVectorStoreRetriever(vectorstore=vectorstore, decay_rate=<span class="hljs-number">.0000000000000000000000001</span>, k=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>



                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/NLP-hug/" class="print-no-link">#NLP_hug</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>NLP&amp;&amp;LLM</div>
      <div>http://example.com/2023/08/20/NLP/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>ä½œè€…</div>
          <div>NGC6302</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>å‘å¸ƒäº</div>
          <div>2023å¹´8æœˆ20æ—¥</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>è®¸å¯åè®®</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - ç½²å">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/08/26/nlp-paper/" title="nlp_paper">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">nlp_paper</span>
                        <span class="visible-mobile">ä¸Šä¸€ç¯‡</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/07/26/c-learn/" title="c++_learn">
                        <span class="hidden-mobile">c++_learn</span>
                        <span class="visible-mobile">ä¸‹ä¸€ç¯‡</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>ç›®å½•</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">æœç´¢</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">å…³é”®è¯</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- ä¸»é¢˜çš„å¯åŠ¨é¡¹ï¼Œå°†å®ƒä¿æŒåœ¨æœ€åº•éƒ¨ -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">åšå®¢åœ¨å…è®¸ JavaScript è¿è¡Œçš„ç¯å¢ƒä¸‹æµè§ˆæ•ˆæœæ›´ä½³</div>
  </noscript>
</body>
</html>
