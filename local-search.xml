<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>leetcode</title>
    <link href="/2023/08/26/leetcode/"/>
    <url>/2023/08/26/leetcode/</url>
    
    <content type="html"><![CDATA[<h1 id="算法代码阅读"><a href="#算法代码阅读" class="headerlink" title="算法代码阅读"></a>算法代码阅读</h1><h4 id="两数之和-1"><a href="#两数之和-1" class="headerlink" title="两数之和 -1"></a>两数之和 -1</h4><p>给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target  的那 两个 整数，并返回它们的数组下标。</p><p>你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。</p><p>你可以按任意顺序返回答案。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">twoSum</span>(<span class="hljs-params">self, nums, target</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        :type nums: List[int]</span><br><span class="hljs-string">        :type target: int</span><br><span class="hljs-string">        :rtype: List[int]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span> <span class="hljs-comment">#这里应该是判断用的</span><br>        <span class="hljs-comment"># 遍历列表</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(nums)):<br>            <span class="hljs-comment"># 计算需要找到的下一个目标数字</span><br>            res = target-nums[i]<br>                <span class="hljs-comment"># i个数字的对应的大小放在 i的空间上</span><br>            <span class="hljs-keyword">if</span> res <span class="hljs-keyword">in</span> nums[i+<span class="hljs-number">1</span>:]:<br><br><br>                <span class="hljs-comment"># 若存在，返回答案。这里由于是两数之和，可采用.index()方法</span><br>                <span class="hljs-comment"># 获得目标元素在nums[i+1:]这个子数组中的索引后，还需加上i+1才是该元素在nums中的索引</span><br>                <span class="hljs-keyword">return</span> [i, nums[i+<span class="hljs-number">1</span>:].index(res)+i+<span class="hljs-number">1</span>] <span class="hljs-comment">#index(值用的是直接索引出标签、)</span><br><br><span class="hljs-comment"># 时间复杂读为 n^2</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">twoSum</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:<br>        idx = &#123;&#125;  <span class="hljs-comment"># 创建一个空哈希表（字典）</span><br>        <span class="hljs-keyword">for</span> j, x <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(nums):  <span class="hljs-comment"># x=nums[j]</span><br>            <span class="hljs-keyword">if</span> target - x <span class="hljs-keyword">in</span> idx:  <span class="hljs-comment"># 在左边找 nums[i]，满足 nums[i]+x=target</span><br>                <span class="hljs-keyword">return</span> [idx[target - x], j]  <span class="hljs-comment"># 返回两个数的下标</span><br>            idx[x] = j  <span class="hljs-comment"># 保存 nums[j] 和 j</span><br><br><span class="hljs-comment">#hash表的映射关系, a[i] = x 令 b[x] = i 对于target - x 只要检测后表是不是有这个值即可</span><br><br></code></pre></td></tr></table></figure><h3 id="两数相加-2"><a href="#两数相加-2" class="headerlink" title="两数相加 -2"></a>两数相加 -2</h3><p>给你两个 非空 的链表，表示两个非负的整数。它们每位数字都是按照 逆序 的方式存储的，并且每个节点只能存储 一位 数字。</p><p>请你将两个数相加，并以相同形式返回一个表示和的链表。</p><p>你可以假设除了数字 0 之外，这两个数都不会以 0 开头。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-comment"># l1 和 l2 为当前遍历的节点，carry 为进位</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">addTwoNumbers</span>(<span class="hljs-params">self, l1: <span class="hljs-type">Optional</span>[ListNode], l2: <span class="hljs-type">Optional</span>[ListNode], carry=<span class="hljs-number">0</span></span>) -&gt; <span class="hljs-type">Optional</span>[ListNode]:<span class="hljs-comment">#Optional表示可以是ListNode类型也可以是None类型</span><br>        <span class="hljs-comment">#递归的结束标志</span><br>        <span class="hljs-keyword">if</span> l1 <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> l2 <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:  <span class="hljs-comment"># 递归边界：l1 和 l2 都是空节点</span><br>            <span class="hljs-keyword">return</span> ListNode(carry) <span class="hljs-keyword">if</span> carry <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>  <span class="hljs-comment"># 创建一个节点值为carry的结点</span><br>            <span class="hljs-comment">#进位的标志</span><br>        <span class="hljs-keyword">if</span> l1 <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:  <span class="hljs-comment"># 令l1一直是长的节点</span><br>            l1, l2 = l2, l1  <br><br>        carry += l1.val + (l2.val <span class="hljs-keyword">if</span> l2 <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>)  <span class="hljs-comment"># 这个语句不需要修正是否为零的长度</span><br>        l1.val = carry % <span class="hljs-number">10</span>  <span class="hljs-comment"># 每个节点保存一个数位</span><br>        l1.<span class="hljs-built_in">next</span> = self.addTwoNumbers(l1.<span class="hljs-built_in">next</span>, l2.<span class="hljs-built_in">next</span> <span class="hljs-keyword">if</span> l2 <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>, carry // <span class="hljs-number">10</span>)  <span class="hljs-comment"># 进位 已经正确的决定l2的长度</span><br>        <span class="hljs-comment">#carry</span><br>        <span class="hljs-keyword">return</span> l1<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">addTwoNumbers</span>(<span class="hljs-params">self, l1: <span class="hljs-type">Optional</span>[ListNode], l2: <span class="hljs-type">Optional</span>[ListNode]</span>) -&gt; <span class="hljs-type">Optional</span>[ListNode]:<br>        cur = dummy = ListNode()  <span class="hljs-comment"># 哨兵节点</span><br>        carry = <span class="hljs-number">0</span>  <span class="hljs-comment"># 进位</span><br>        <span class="hljs-keyword">while</span> l1 <span class="hljs-keyword">or</span> l2 <span class="hljs-keyword">or</span> carry:  <span class="hljs-comment"># 有一个不是空节点，或者还有进位，就继续迭代</span><br>            carry += (l1.val <span class="hljs-keyword">if</span> l1 <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>) + (l2.val <span class="hljs-keyword">if</span> l2 <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>)  <span class="hljs-comment"># 节点值和进位加在一起</span><br>            cur.<span class="hljs-built_in">next</span> = ListNode(carry % <span class="hljs-number">10</span>)  <span class="hljs-comment"># 每个节点保存一个数位</span><br>            carry //= <span class="hljs-number">10</span>  <span class="hljs-comment"># 新的进位</span><br>            cur = cur.<span class="hljs-built_in">next</span>  <span class="hljs-comment"># 下一个节点</span><br>            <span class="hljs-keyword">if</span> l1: l1 = l1.<span class="hljs-built_in">next</span>  <span class="hljs-comment"># 下一个节点</span><br>            <span class="hljs-keyword">if</span> l2: l2 = l2.<span class="hljs-built_in">next</span>  <span class="hljs-comment"># 下一个节点</span><br>        <span class="hljs-keyword">return</span> dummy.<span class="hljs-built_in">next</span>  <span class="hljs-comment"># 哨兵节点的下一个节点就是头节点</span><br><br><br></code></pre></td></tr></table></figure><h4 id="无重复字符的最长子串-3"><a href="#无重复字符的最长子串-3" class="headerlink" title="无重复字符的最长子串 -3"></a>无重复字符的最长子串 -3</h4><p>给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment">#滑动窗口以及 哈希表</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">lengthOfLongestSubstring</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">int</span>: <span class="hljs-comment">#这个应该是定义了内部变量的以及函数的返回类型</span><br>        dic, res, i = &#123;&#125;, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(s)):<br>            <span class="hljs-keyword">if</span> s[j] <span class="hljs-keyword">in</span> dic: <span class="hljs-comment">#如果在表的位置上查到了这个的值也就是重复了</span><br>            <span class="hljs-comment"># 识别出每一个重复的左指标,以及这个采取缩减的方式,完成了一起更新,还有比较的模式</span><br>                i = <span class="hljs-built_in">max</span>(dic[s[j]], i) <span class="hljs-comment"># 更新左指针 i</span><br>            dic[s[j]] = j <span class="hljs-comment"># 在表的s[j]放入 在字符串s中的位置 也就是可以一一映射的</span><br>            res = <span class="hljs-built_in">max</span>(res, j - i) <span class="hljs-comment"># 更新结果</span><br>        <span class="hljs-keyword">return</span> res<br><br><span class="hljs-comment">#动态规划加hash 鉴定为脑瘫东西</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">lengthOfLongestSubstring</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        dic = &#123;&#125;<br>        res = tmp = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(s)):<br>            i = dic.get(s[j], -<span class="hljs-number">1</span>) <span class="hljs-comment"># 获取索引 i</span><br>            dic[s[j]] = j <span class="hljs-comment"># 更新哈希表</span><br>            <br>            tmp = tmp + <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> tmp &lt; j - i <span class="hljs-keyword">else</span> j - i <span class="hljs-comment"># dp[j - 1] -&gt; dp[j]</span><br>            res = <span class="hljs-built_in">max</span>(res, tmp) <span class="hljs-comment"># max(dp[j - 1], dp[j])</span><br>        <span class="hljs-keyword">return</span> res<br><br></code></pre></td></tr></table></figure><h4 id="寻找两个正序数组的中位数-4"><a href="#寻找两个正序数组的中位数-4" class="headerlink" title="寻找两个正序数组的中位数 -4"></a>寻找两个正序数组的中位数 -4</h4><p>时间复杂度为 $$ \log(m+n) $$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">findMedianSortedArrays</span>(<span class="hljs-params">self, nums1: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], nums2: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">float</span>:<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_k_min</span>(<span class="hljs-params">nums1, start1, end1, nums2, start2, end2, k</span>):<br>            remain1 = end1 - start1 + <span class="hljs-number">1</span><br>            remain2 = end2 - start2 + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> remain1 == <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">return</span> nums2[start2 + k - <span class="hljs-number">1</span>]<br>            <span class="hljs-keyword">if</span> remain2 == <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">return</span> nums1[start1 + k - <span class="hljs-number">1</span>]<br>            <span class="hljs-keyword">if</span> k == <span class="hljs-number">1</span>:<br>                <span class="hljs-keyword">return</span> <span class="hljs-built_in">min</span>(nums1[start1], nums2[start2])<br>            i = start1 + <span class="hljs-built_in">min</span>(remain1, k // <span class="hljs-number">2</span>) - <span class="hljs-number">1</span><br>            j = start2 + <span class="hljs-built_in">min</span>(remain2, k // <span class="hljs-number">2</span>) - <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> nums1[i] &lt;= nums2[j]:<br>                <span class="hljs-keyword">return</span> get_k_min(nums1, i+<span class="hljs-number">1</span>, end1, nums2, start2, end2, k - (i - start1 + <span class="hljs-number">1</span>))<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">return</span> get_k_min(nums1, start1, end1, nums2, j+<span class="hljs-number">1</span>, end2, k - (j - start2 + <span class="hljs-number">1</span>))<br><br>        m, n = <span class="hljs-built_in">len</span>(nums1), <span class="hljs-built_in">len</span>(nums2)<br>        mid1 = (m + n + <span class="hljs-number">1</span>) // <span class="hljs-number">2</span><br>        mid2 = (m + n + <span class="hljs-number">2</span>) // <span class="hljs-number">2</span><br>        a = get_k_min(nums1, <span class="hljs-number">0</span>, m-<span class="hljs-number">1</span>, nums2, <span class="hljs-number">0</span>, n-<span class="hljs-number">1</span>, mid1)<br>        b = get_k_min(nums1, <span class="hljs-number">0</span>, m-<span class="hljs-number">1</span>, nums2, <span class="hljs-number">0</span>, n-<span class="hljs-number">1</span>, mid2)<br>        <span class="hljs-keyword">return</span> (a + b) / <span class="hljs-number">2</span><br><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>leetcode</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>nlp_paper</title>
    <link href="/2023/08/26/nlp-paper/"/>
    <url>/2023/08/26/nlp-paper/</url>
    
    <content type="html"><![CDATA[<h1 id="paper-read"><a href="#paper-read" class="headerlink" title="paper-read"></a>paper-read</h1><h2 id="A-Survey-on-Large-Language-Model-based-Autonomous-Agents"><a href="#A-Survey-on-Large-Language-Model-based-Autonomous-Agents" class="headerlink" title="A Survey on Large Language Model based Autonomous Agents"></a>A Survey on Large Language Model based Autonomous Agents</h2><h4 id="Learning-from-Interactive-Human-Feedback"><a href="#Learning-from-Interactive-Human-Feedback" class="headerlink" title="Learning from Interactive Human Feedback"></a>Learning from Interactive Human Feedback</h4>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>NLP_huggingface🤗</title>
    <link href="/2023/08/20/NLP/"/>
    <url>/2023/08/20/NLP/</url>
    
    <content type="html"><![CDATA[<h1 id="NLP-huggingface🤗"><a href="#NLP-huggingface🤗" class="headerlink" title="NLP_huggingface🤗"></a>NLP_huggingface🤗</h1><h2 id="BASE"><a href="#BASE" class="headerlink" title="BASE"></a>BASE</h2><p>参考链接 <a href="https://huggingface.co/learn/nlp-course/">NLP_course</a></p><h3 id="unigram-tokenization"><a href="#unigram-tokenization" class="headerlink" title="unigram tokenization"></a>unigram tokenization</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">encode_word</span>(<span class="hljs-params">word, model</span>):<br>    best_segmentations = [&#123;<span class="hljs-string">&quot;start&quot;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-number">1</span>&#125;] + [<br>        &#123;<span class="hljs-string">&quot;start&quot;</span>: <span class="hljs-literal">None</span>, <span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-literal">None</span>&#125; <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(word))<br>    ]<br>    <span class="hljs-comment">#至少每一种字长都有留下来对应的一个值.同时在位次上对应END,里面的start对应了在这个END中,在哪里有最好的分词的方法.</span><br>    <span class="hljs-keyword">for</span> start_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(word)):<br>        <span class="hljs-comment"># This should be properly filled by the previous steps of the loop</span><br>        best_score_at_start = best_segmentations[start_idx][<span class="hljs-string">&quot;score&quot;</span>]<br>        <span class="hljs-keyword">for</span> end_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(start_idx + <span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(word) + <span class="hljs-number">1</span>):<br>            token = word[start_idx:end_idx] <span class="hljs-comment"># toke截取了一组值,之后通过查表进行比较</span><br>            <span class="hljs-keyword">if</span> token <span class="hljs-keyword">in</span> model <span class="hljs-keyword">and</span> best_score_at_start <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                score = model[token] + best_score_at_start<br>                <span class="hljs-comment"># If we have found a better segmentation ending at end_idx, we update</span><br>                <span class="hljs-keyword">if</span> (<br>                    best_segmentations[end_idx][<span class="hljs-string">&quot;score&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span><br>                    <span class="hljs-keyword">or</span> best_segmentations[end_idx][<span class="hljs-string">&quot;score&quot;</span>] &gt; score<br>                ):<br>                <span class="hljs-comment">#这里取的是-log相当于是一个递减的函数,如果频率高,反而得到的值越低,所以这里选择高频率的留下,</span><br>                <span class="hljs-comment">#关于继承前面的值,这里的含义指的是:start end都含有一定的值,start的分词+新增的词块频率够高的情况才更新END的模块</span><br>                <span class="hljs-comment">#下面对应了两种情况,一种是后续没有end_idx直接打上标签 另一种是在当前的start + 增的 比后续的低则更改??</span><br>                    best_segmentations[end_idx] = &#123;<span class="hljs-string">&quot;start&quot;</span>: start_idx, <span class="hljs-string">&quot;score&quot;</span>: score&#125;<br><br>    segmentation = best_segmentations[-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">if</span> segmentation[<span class="hljs-string">&quot;score&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-comment"># We did not find a tokenization of the word -&gt; unknown</span><br>        <span class="hljs-keyword">return</span> [<span class="hljs-string">&quot;&lt;unk&gt;&quot;</span>], <span class="hljs-literal">None</span><br><br>    score = segmentation[<span class="hljs-string">&quot;score&quot;</span>]<br>    start = segmentation[<span class="hljs-string">&quot;start&quot;</span>]<br>    end = <span class="hljs-built_in">len</span>(word)<br>    tokens = []<br>    <span class="hljs-keyword">while</span> start != <span class="hljs-number">0</span>:<br>        tokens.insert(<span class="hljs-number">0</span>, word[start:end])<br>        next_start = best_segmentations[start][<span class="hljs-string">&quot;start&quot;</span>]<br>        end = start<br>        start = next_start<br>    tokens.insert(<span class="hljs-number">0</span>, word[start:end])<br>    <span class="hljs-keyword">return</span> tokens, score<br><span class="hljs-comment"># 但是为什么是最后的一个?</span><br></code></pre></td></tr></table></figure><h2 id="MAIN-NLP-TASKS"><a href="#MAIN-NLP-TASKS" class="headerlink" title="MAIN NLP TASKS"></a>MAIN NLP TASKS</h2><h3 id="Token-classification"><a href="#Token-classification" class="headerlink" title="Token classification"></a>Token classification</h3><h4 id="preparing-the-data"><a href="#preparing-the-data" class="headerlink" title="preparing the data"></a>preparing the data</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br>raw_datasets = load_dataset(<span class="hljs-string">&quot;conll2003&quot;</span>)<br><br><span class="hljs-comment"># 数据形式</span><br><br>DatasetDict(&#123;<br>    train: Dataset(&#123;<br>        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],<br>        num_rows: <span class="hljs-number">14041</span><br>    &#125;)<br>    validation: Dataset(&#123;<br>        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],<br>        num_rows: <span class="hljs-number">3250</span><br>    &#125;)<br>    test: Dataset(&#123;<br>        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],<br>        num_rows: <span class="hljs-number">3453</span><br>    &#125;)<br>&#125;)<br><span class="hljs-comment">#the last column is called tokens, but it contains words in the sense that these are pre-tokenized inputs that still need to go through the tokenizer for subword tokenization</span><br><br><span class="hljs-comment"># 数据形式</span><br>ner_feature = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].features[<span class="hljs-string">&quot;ner_tags&quot;</span>]<br><br><span class="hljs-type">Sequence</span>(feature=ClassLabel(num_classes=<span class="hljs-number">9</span>, names=[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>, <span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;I-ORG&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;I-LOC&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>), length=-<span class="hljs-number">1</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)<br><br><span class="hljs-comment"># 表示这里的训练队列的类型</span><br></code></pre></td></tr></table></figure><p>解构数据表示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>words = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;tokens&quot;</span>]<br>labels = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]<br>line1 = <span class="hljs-string">&quot;&quot;</span><br>line2 = <span class="hljs-string">&quot;&quot;</span><br><span class="hljs-keyword">for</span> word, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(words, labels):<span class="hljs-comment">#不仅取出了两个列表中的元素,同时把这两个对应的数组压缩成元组</span><br>    full_label = label_names[label]<br>    max_length = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">len</span>(word), <span class="hljs-built_in">len</span>(full_label))<br>    line1 += word + <span class="hljs-string">&quot; &quot;</span> * (max_length - <span class="hljs-built_in">len</span>(word) + <span class="hljs-number">1</span>)<br>    line2 += full_label + <span class="hljs-string">&quot; &quot;</span> * (max_length - <span class="hljs-built_in">len</span>(full_label) + <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h4 id="数据加工"><a href="#数据加工" class="headerlink" title="数据加工"></a>数据加工</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>model_checkpoint = <span class="hljs-string">&quot;bert-base-cased&quot;</span><br>tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)<br><br>inputs = tokenizer(raw_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;tokens&quot;</span>],is_split_into_words = <span class="hljs-literal">True</span>)<br><br>inputs.word_ids()<span class="hljs-comment">#可以正确的对齐每一个tokens的单词的位置</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#这个函数相当于分裂同时打上标签</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">align_labels_with_tokens</span>(<span class="hljs-params">labels,word_ids</span>):<br>    <span class="hljs-comment">#labels是来自于ner_tags</span><br>    new_labels = []<br>    current_word = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">for</span> word_id <span class="hljs-keyword">in</span> word_ids:<br>        <span class="hljs-keyword">if</span> word_id != current_word:<span class="hljs-comment">#区分是否是一个新的单词</span><br>            current_word = word_id<br>            label = -<span class="hljs-number">100</span> <span class="hljs-keyword">if</span> word_id <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> labels[word_id]<br>            new_labels.append(label)<span class="hljs-comment">#放入新的label</span><br>        <span class="hljs-keyword">elif</span> word_id = <span class="hljs-literal">None</span>:<br>            new_labels.append(-<span class="hljs-number">100</span>)<br>        <span class="hljs-keyword">else</span>:<br>            label = labels[word_id]<span class="hljs-comment">#是在当前的labels中</span><br>            <span class="hljs-keyword">if</span> label % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>:<br>                label += <span class="hljs-number">1</span> <span class="hljs-comment">#相当于把B中的值转换为I,如果是同一个单词的情况下</span><br>            new_labels.append(label)<br>    <span class="hljs-keyword">return</span> new_labels<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_and_align_labels</span>(<span class="hljs-params">examples</span>):<br>    tokenized_inputs = tokenizer(examples[<span class="hljs-string">&quot;tokens&quot;</span>],truncation = <span class="hljs-literal">True</span>, is_split_into_words =<span class="hljs-literal">True</span>)<br>    all_labels = example[<span class="hljs-string">&quot;ner_tags&quot;</span>]<br>    new_labels = []<br>    <span class="hljs-keyword">for</span> i,labels <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(all_labels):<br>        word_ids = tokenized_inputs.word_ids(i)<br>        new_labels.append(align_labels_with_tokens(labels,word_ids))<br>    <br>    tokenized_input[<span class="hljs-string">&quot;labels&quot;</span>] = new_labels<br>    <span class="hljs-keyword">return</span> tokenized_inputs<br><br><span class="hljs-comment">#这里基本相当于是在下面进行了调用,但是这里仍然没有完成把所有的对齐附带上padding</span><br><br><span class="hljs-comment">#以下完成数据集的训练</span><br>tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(<br>    tokenize_and_align_labels,<span class="hljs-comment">#这里的原理应该相当于直接把这个raw数据集传入进去,然后直接依照相关的函数进行输出</span><br>    batched = <span class="hljs-literal">True</span>,<br>    remove_columns = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].column_names,<span class="hljs-comment">#这里相当于把训练后的这一列删除掉</span><br>)<br><br></code></pre></td></tr></table></figure><h4 id="Fine-tuning-the-modle-with-trainer-API"><a href="#Fine-tuning-the-modle-with-trainer-API" class="headerlink" title="Fine-tuning the modle with trainer API"></a>Fine-tuning the modle with trainer API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForTokenClassification<br>data_collator = DataClollatorForTokenClassification(tokenizer = tokenizer)<br><span class="hljs-comment">#这里没有对齐的值默认打上了-100的标签</span><br></code></pre></td></tr></table></figure><h4 id="Metrics-度量指标"><a href="#Metrics-度量指标" class="headerlink" title="Metrics 度量指标"></a>Metrics 度量指标</h4><p>利用seqeval进行度量该指标</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> evalutate<br>metric = evaluate.load(<span class="hljs-string">&quot;seqeval&quot;</span>)<br><br>labels = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]<br>labels = [label_names[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> labels]<br><span class="hljs-comment">#这里相当于把原先的偏移寻址转换成了正常的可读入字符串的形式</span><br>predictions = labels.copy()<br>predictions[<span class="hljs-number">2</span>] = <span class="hljs-string">&quot;0&quot;</span><br>metric.compute(predictions= [predictions],reference = [labels])<br></code></pre></td></tr></table></figure><p>计算度量函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrcis</span>(<span class="hljs-params">eval_preds</span>):<br>    logis,labels = eval_preds<br>    predictions = np.argmax(logits,axis =-<span class="hljs-number">1</span>)<span class="hljs-comment">#true 是真的值,prediction是一个以训练结果导出来的值</span><br>    true_labels = [[label_namse[l] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> label <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels] <span class="hljs-comment"># 啥?</span><br>    true_predictions = [ [label_name[p] <span class="hljs-keyword">for</span> (p,l) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction,label) <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>] <span class="hljs-keyword">for</span> prediction,label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions,labels)]<br>    all_metrics = metrci.compute(predictions = ture_predictions, references = true_labels)<br><br></code></pre></td></tr></table></figure><h4 id="defining-the-Model"><a href="#defining-the-Model" class="headerlink" title="defining the Model"></a>defining the Model</h4><p>设置一个相反的字典</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">id2label = &#123;i:label <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(label_names)&#125;<br>lable2id = &#123;v,k <span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> id2label.items()&#125;<br></code></pre></td></tr></table></figure><p>在传入相关的模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification<br>model = AutoModelForTokenClassification.from_pretrained(<br>    model_checkpoint,<br>    id2label = id2label<br>    label2id = label2id<br>)<br></code></pre></td></tr></table></figure><h4 id="Fine-tuning-the-model"><a href="#Fine-tuning-the-model" class="headerlink" title="Fine-tuning the model"></a>Fine-tuning the model</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login<br>notebook_login()<br><span class="hljs-comment">#调用训练参数</span><br><span class="hljs-keyword">from</span> transformes <span class="hljs-keyword">import</span> TrainingArguments<br>args = TrainingArguments(<br>    <span class="hljs-string">&quot;bert-finetune-ner&quot;</span>,<br>    evaluation_strategy = <span class="hljs-string">&quot;epoch&quot;</span>,<br>    save_strategy = <span class="hljs-string">&quot;epoch&quot;</span>,<br>    learning_rate = <span class="hljs-number">2e05</span>,<br>    num_train_epochs= <span class="hljs-number">3</span><br>    weight_decay= <span class="hljs-number">0.01</span>.<br>    push_to_hub = <span class="hljs-literal">True</span>,<br>)<br><span class="hljs-comment">#构建一个trainer</span><br><span class="hljs-keyword">from</span>  transformers <span class="hljs-keyword">import</span> Trainer<br><br>trainer = Trainer(<br>    model = model,<br>    args =args,<br>    train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],<br>    eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],<br>    data_collator = data_collator,<br>    compyte_metrics= compute_metrics,<br>    tokenizer = tokenizer,<br>)<br>trainer.train()<br>trainer.push_to_hub(commit_message= <span class="hljs-string">&quot;Training complete&quot;</span>)<br></code></pre></td></tr></table></figure><p>以上的模型在每一次训练的时候,都会上传到hub中</p><h4 id="传统的训练流程举例"><a href="#传统的训练流程举例" class="headerlink" title="传统的训练流程举例"></a>传统的训练流程举例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br>train_dataloader = DataLoader(<br>    tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],<br>    shuffle = <span class="hljs-literal">True</span>,<br>    collate_fn = data_collator,<br>    batch_size = <span class="hljs-number">8</span>,<br><br>)<br>eval_dataloader = DataLoader(<br>    tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],<br>    collate_fn= data_collator,<br>    batch_size = <span class="hljs-number">8</span><br>)<br><br><span class="hljs-comment">#构建模型</span><br><br>model = AutoModelForTokenXlassification.from_pretrained(<br>    model_checkpoint,<br>    id2label = id2label,<br>    label2id  = label2id,<br>)<br><br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW<br>optimizer = AdamW(model.parameters(),lr= <span class="hljs-number">2e-5</span>)<br><br><span class="hljs-comment">#加速器模块</span><br><br><span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator<br>accelerator = Accelerator()<br>modle,optimizer,train_dataloader,eval_dataloader = accelerator.prepare(<br>    modle,optimizer,train_dataloader,eval_dataloader<br>)<br><br><span class="hljs-comment">#???</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler<br>num_train_epochs = <span class="hljs-number">3</span><br>num_update_steps_per_epoch = <span class="hljs-built_in">len</span>(train_dataloader)<br>num_training_steps = num_train_epochs * num_update_steps_per_epoch <span class="hljs-comment">#全部训练完的epoch</span><br>lr_scheduler = get_scheduler(<br>    <span class="hljs-string">&quot;linear&quot;</span>,<br>    optimizer = optimizer.<br>    num_warmup_steps = <span class="hljs-number">0</span>,<br>    num_training_steps = num_training_steps<br>)<br><br></code></pre></td></tr></table></figure><h4 id="上传到仓库"><a href="#上传到仓库" class="headerlink" title="上传到仓库"></a>上传到仓库</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository,get_full_repo_name<br>model_name = <span class="hljs-string">&quot;bert-finetune-ner-accelerate&quot;</span><br>repo_name = get_full_repo_name(model_name)<span class="hljs-comment">#加上原来的地址.</span><br><br></code></pre></td></tr></table></figure><h4 id="Train-loop"><a href="#Train-loop" class="headerlink" title="Train loop"></a>Train loop</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">postprocess</span>(<span class="hljs-params">predictions,labels</span>):<br>    predictions = predictions.detach().cpu().clone().numpy()<br>    labels = labels.detach().cpu().clone().numpy()<br>    <span class="hljs-comment">#从GPU中拷贝数据并转换为numpy数据</span><br><br>    true_labels = [ [label_names[l] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> label <span class="hljs-keyword">if</span> l != <span class="hljs-number">100</span>] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels]<br>    true_predictions = [ [label_names[p] <span class="hljs-keyword">for</span> (p,l) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction,label) <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>]<br>    <span class="hljs-keyword">for</span> prediction , label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, labels)]<br>    <span class="hljs-keyword">return</span> true_labels,true_predictions<br><br><span class="hljs-comment">#训练中</span><br><span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> torch<br>progress_bar = tqdm((<span class="hljs-built_in">range</span>(num_training_steps)))<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_train_epochs):<br>    model.train()<br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:<br>        outputs = model(**batch)<br>        loss = outputs.loss<br>        accelerator.backward(loss)<br>        optimizer.step()<br>        lr_scheduler.step()<br>        optimizer.zero_grad()<br>        progress_bar.update(<span class="hljs-number">1</span>)<br>    <br>    model.<span class="hljs-built_in">eval</span>()<br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> eval_dataloader:<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            outputs = model(**batch)<br>        <br>        predictions = outputs/logits.argmax(dim=-<span class="hljs-number">1</span>)<br>        labels = batch[<span class="hljs-string">&quot;labels&quot;</span>]<br></code></pre></td></tr></table></figure><p>部分跳过🤣👉🏻🤡</p><h3 id="Fine-tuning-a-masked-language-model"><a href="#Fine-tuning-a-masked-language-model" class="headerlink" title="Fine-tuning a masked language model"></a>Fine-tuning a masked language model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMaskedLM<br>model_checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased&quot;</span><br>model = AutoModelForMaskedLM.from_pretrained(model_Checkpoint)<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br>tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)<br><br><span class="hljs-keyword">import</span> torch<br>inputs = tokenizer(text,return_tensors= <span class="hljs-string">&quot;pt&quot;</span>)<span class="hljs-comment">#按照pytorch张量输出</span><br>token_logits = modle(**inputs).logits<br>mask_token_index = torch.where(inputs[input_ids]== tokenizer.mask_token_id)[<span class="hljs-number">1</span>]<br>mask_token_logits = token_logits[<span class="hljs-number">0</span>,mask_token_index,:]<br>top_5_token = torch.topk(mask_token_logits,<span class="hljs-number">5</span>,dim = <span class="hljs-number">1</span>).indices[<span class="hljs-number">0</span>],tolist()<br><br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br><br>imdb_dataset = load_dataset(<span class="hljs-string">&quot;imdb&quot;</span>)<br>sample = imdb_dataset[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>))<br><span class="hljs-comment">#注意可以通过数据集的特定部分的.shuffle来选择打乱数据集</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):<br>    result = tokenizer(examples[<span class="hljs-string">&quot;text&quot;</span>])<br>    <span class="hljs-keyword">if</span> tokenizer.is_fast:<br>        result[<span class="hljs-string">&quot;word_ids&quot;</span>] = [result.word_ids(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(result[<span class="hljs-string">&quot;input_ids&quot;</span>]))] <span class="hljs-comment">#word_ids相当于分词器映射到了第几个单词上面 这里相当于对于不同的句子组建立了不同的值</span><br>    <span class="hljs-keyword">return</span> result<br><br>tokenizer.model_max_length <span class="hljs-comment"># 分词器最大的文本容纳量</span><br><br><span class="hljs-comment">#连锁</span><br>tokenized_samples = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][:<span class="hljs-number">3</span>]<br><span class="hljs-keyword">for</span> idx,sample <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tokenized_samples[<span class="hljs-string">&quot;input_ids&quot;</span>]):<br>    <span class="hljs-built_in">print</span>(f <span class="hljs-string">&quot;&gt;&gt;&#123;ids&#125;&quot;</span>)<br><br><br>concatenated_examples = &#123;<br>    <span class="hljs-comment">#以下相当于把多个不同的列表合成为一个共同的列表</span><br>    k:<span class="hljs-built_in">sum</span>(tokenized_samples[k],[]) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> examples.keys()<span class="hljs-comment">#生成字典的键的值</span><br>&#125;<span class="hljs-comment"># k是一系列的键</span><br>total_length = <span class="hljs-built_in">len</span>(concatenated_examples[<span class="hljs-string">&quot;input_ids&quot;</span>]) <span class="hljs-comment">#951</span><br><br>Chunk = &#123;<br>    k:[t[i:i+chunk_size] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,total_length,chunk_size)]<br>    <span class="hljs-keyword">for</span> k ,t <span class="hljs-keyword">in</span> concatenated_exampls.items() <span class="hljs-comment">#相当于元素的整合再按照chunk_size的切割</span><br>&#125;<br><br><br><br></code></pre></td></tr></table></figure><p><strong>同时对于最后一个chunk出现的不均匀的情况,采用直接填充,或者直接丢弃的方法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">group_texts</span>(<span class="hljs-params">examples</span>):<br>    concatenated_examples = &#123;k:<span class="hljs-built_in">sum</span>(examples[k],[]) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> examples.keys()&#125;<br>    total_length = <span class="hljs-built_in">len</span>(concatenated_examples[<span class="hljs-built_in">list</span>(examples.keys())[<span class="hljs-number">0</span>]])<br>    total_length = (total_length // chunk_size) *chunk_size<br><br>    result = &#123;<br>        k:[t[i:i+chunk_size]<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,total_legth,chunk_size)] <span class="hljs-keyword">for</span> k,t inconcatenated_examples.items()<br>    &#125;<br><br>    result[<span class="hljs-string">&quot;labels&quot;</span>]= result[<span class="hljs-string">&quot;input_ids&quot;</span>].copy()<br>    <span class="hljs-keyword">return</span> result<br><br>lm_datasets = tokenzied_datasets.<span class="hljs-built_in">map</span>(group_texts,batched = <span class="hljs-literal">True</span>)    <br><br></code></pre></td></tr></table></figure><h4 id="Fine-tuning-DistilBERt-with-the-Trainer-API"><a href="#Fine-tuning-DistilBERt-with-the-Trainer-API" class="headerlink" title="Fine-tuning DistilBERt with the Trainer API"></a>Fine-tuning DistilBERt with the Trainer API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformer <span class="hljs-keyword">import</span> DataCollatorForlanguageModeling<br>data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer,mlm_probability = <span class="hljs-number">0.15</span> )<br><br>samples = [lm_dataset[<span class="hljs-string">&quot;train&quot;</span>][i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>)]<br><span class="hljs-keyword">for</span> sample <span class="hljs-keyword">in</span> samples:<br>    _ = sample.popp(<span class="hljs-string">&quot;word_ids&quot;</span>) <span class="hljs-comment">#这个会弹出key对应的value 并删除这个键对值</span><br><br><span class="hljs-keyword">import</span> collections<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> default_data_collator<br><br>ww_prolbability = <span class="hljs-number">0.2</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">whole_word_masking_data_collator</span>(<span class="hljs-params">features</span>):<br>    <span class="hljs-comment">#features是最外的字典</span><br>    <span class="hljs-comment">#feature是 键对值</span><br>    <span class="hljs-keyword">for</span> feature <span class="hljs-keyword">in</span> features:<br>        word_ids = feature.pop(<span class="hljs-string">&quot;word_ids&quot;</span>)<br>        mapping = collections.defaultdict(<span class="hljs-built_in">list</span>) <span class="hljs-comment">#mapping内部元素是一种列表</span><br>        current_word_index = -<span class="hljs-number">1</span><br>        current_word = <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">for</span> idx,word_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(word_ids):<br>            <span class="hljs-keyword">if</span> word_id <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                <span class="hljs-keyword">if</span> word_id != current_word:<br>                    current_word = word_id<br>                    <span class="hljs-comment">#单词数量加1</span><br>                    current_word_index += <span class="hljs-number">1</span><br>                mapping[current_word_index].append(idx)<span class="hljs-comment">#在当前单词的位置上映射对应的token的位置</span><br>    <span class="hljs-comment"># 随机的遮蔽相关的字符</span><br>    mask = np.random.binomial(<span class="hljs-number">1</span>,wwm_probability,(<span class="hljs-built_in">len</span>(mapping))) <span class="hljs-comment">#在mapping上的每一个元素都做二项分布,概率有wwm生成,同时生成一个列表 含有1,0等元素 </span><br>    <span class="hljs-comment">#这里满足了一整个单词遮蔽的方式</span><br><br><br>    <span class="hljs-comment">#同时原来的labels和input_ids都是保留一样的值</span><br>    input_ids = feature[<span class="hljs-string">&quot;input_ids&quot;</span>] <br>    labels = feautre[<span class="hljs-string">&quot;labels&quot;</span>]<br>    new_labels = [-<span class="hljs-number">100</span>] *<span class="hljs-built_in">len</span>(labels) <span class="hljs-comment">#创建一个长度为len 每一个元素都是[ -100]的列表 , </span><br>    <span class="hljs-keyword">for</span> word_id <span class="hljs-keyword">in</span> np.where(mask)[<span class="hljs-number">0</span>]: <span class="hljs-comment">#当作布尔行代数来看</span><br>        word_id = word_id.item()<br>        <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> mapping[word_id]:<br>            new_labels[idx] = labels[idx] <span class="hljs-comment">#其他的默认是-100? 这里保留着遮蔽的那些词?</span><br>            input_ids[idx] = tokenizer.mask_token_id <span class="hljs-comment">#这里应该是相当于遮蔽了?</span><br><br>    feature[<span class="hljs-string">&quot;labels&quot;</span>] = new_labels<br><br>    <span class="hljs-keyword">return</span> default_data_collator(features)<br><br>train_size =<span class="hljs-number">10_000</span><br>test_size = <span class="hljs-built_in">int</span>(<span class="hljs-number">0.1</span> * train_size) <span class="hljs-comment">#int() 表示类型转换为整数</span><br><br>downsampled_dataset = lm_datasets[<span class="hljs-string">&quot;train&quot;</span>].train_test_split(<br>    train_size = train_size, test_size=test_size, seed = <span class="hljs-number">42</span><br>)<br><br></code></pre></td></tr></table></figure><h4 id="训练数据库"><a href="#训练数据库" class="headerlink" title="训练数据库"></a>训练数据库</h4><p>给trainer定义参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transfromers <span class="hljs-keyword">import</span> TrainingArguments<br><br>batch_size = <span class="hljs-number">64</span><br>logging_steps = <span class="hljs-built_in">len</span>(downsampled_dataset[<span class="hljs-string">&quot;train&quot;</span>]) //batch_size<br>model_name = model_checkpoint.split(<span class="hljs-string">&quot;/&quot;</span>)[-<span class="hljs-number">1</span>] <span class="hljs-comment">#按照/的形式切割,并取出最后一个值</span><br>training_args = TrainingArguments(<br>    output_dir = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;model_name&#125;</span>-finetune-immdb&quot;</span>,<br>    overwrite_output_dir = <span class="hljs-literal">True</span>,<br>    evaluation_strategy = <span class="hljs-string">&quot;epocoh&quot;</span>,<br>    learning_rate = <span class="hljs-number">2e-5</span>,<br>    weight_decay = <span class="hljs-number">0.01</span>,<br>    per_device_train_batch_size = batch_size,<br>    per_device_eval_batch_size = batch_size,<br>    push_to_hub = <span class="hljs-literal">True</span>,<br>    fp16 = <span class="hljs-literal">True</span>,<br>    logging_steps = logging_steps,<br>)<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer<br>trainer = Trainer(<br>    model = model,<br>    args = training_args,<br>    train_dataset = downsampled_dataset[<span class="hljs-string">&quot;train&quot;</span>],<br>    eval_dataselt = downsampled_dataset[<span class="hljs-string">&quot;test&quot;</span>],<br>    data_collator = data_collator,<br>    tokenizer = tokenizer,<br>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">insert_random_mask</span>(<span class="hljs-params">batch</span>):<br>    features = [<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(batch,t)) <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(*batch.values())] <br>    <span class="hljs-comment">#zip(*batch.value())会对一个key的东西压缩成为一个元组通常，它用于将多个列表或序列的元素按照相同索引位置配对在一起。 </span><br>    <span class="hljs-comment">#t相当于是一个元组, 用每一个key和元组中的元素进行配对</span><br>    masked_inputs = data_collator(features)<br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;masked_&quot;</span>+k:v.numpy()<span class="hljs-keyword">for</span> k,v <span class="hljs-keyword">in</span> masked_inputs.items()&#125;<br>    <span class="hljs-comment">#这个相当于在原字典之前加上“masked_&quot;的前缀</span><br><br>downsampled_dataset = downsampled_dataset.remove_columns([<span class="hljs-string">&quot;word_ids&quot;</span>])<br>eval_dataset = downsampled_dataset[<span class="hljs-string">&quot;test&quot;</span>].<span class="hljs-built_in">map</span>(<br>    insert_random_mask,<br>    batched = <span class="hljs-literal">True</span>,<br>    remove_columns = downsampled_dataset[<span class="hljs-string">&quot;test&quot;</span>].column_names,<br>)<br><br>eval_dataset = eval_dataset.rename_columns(<br>    &#123;<br>        <span class="hljs-string">&quot;masked_input_ids&quot;</span>: <span class="hljs-string">&quot;input_ids&quot;</span>,<br>        <span class="hljs-string">&quot;masked_attention_mask&quot;</span>: <span class="hljs-string">&quot;attention_mask&quot;</span>,<br>        <span class="hljs-string">&quot;masked_labels&quot;</span>: <span class="hljs-string">&quot;labels&quot;</span>,<br>    &#125;<br>)<br><br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> default_data_collator<br><br>batch_size =<span class="hljs-number">64</span><br>train_dataloader = DataLoader(<br>    downsampled_dataset[<span class="hljs-string">&quot;train&quot;</span>],<br>    shuffle = <span class="hljs-literal">True</span>,<br>    batch_size = batch_size,<br>    collate_fn = data_collator<br>)<br><br>eval_dataloader = DataLoader(<br>    eval_dataset,batch_size = batch_size.collate_fn = default_data_collator<br>)<br><br>model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW<br>optimizer = AdamW(model.parameters(),lr= <span class="hljs-number">5e-5</span>)<br><br><span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator<br><br>accelerator = Accelerator()<br>model,optimizer,train_dataloader,eval_dataloader = accelerator.prepare(<br>    model,optimizer,train_dataloader,eval_dataloader<br>)<br><br></code></pre></td></tr></table></figure><h3 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h3><h4 id="loaddata"><a href="#loaddata" class="headerlink" title="loaddata"></a>loaddata</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br>raw_datasets = load_dataset(<span class="hljs-string">&quot;kde4&quot;</span>, lang1=<span class="hljs-string">&quot;en&quot;</span>, lang2=<span class="hljs-string">&quot;fr&quot;</span>)<br>split_datasets = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].train_test_split(train_size=<span class="hljs-number">0.9</span>, seed=<span class="hljs-number">20</span>) <span class="hljs-comment">#选择训练集和测试集</span><br><br>split_datasets[<span class="hljs-string">&quot;validation&quot;</span>] = split_datasets.pop(<span class="hljs-string">&quot;test&quot;</span>) <span class="hljs-comment">#重命名</span><br><br>split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>] <span class="hljs-comment">#两种id 和translation-&gt;字典 同时en,fr</span><br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br><br>model_checkpoint = <span class="hljs-string">&quot;Helsinki-NLP/opus-mt-en-fr&quot;</span><br>translator = pipeline(<span class="hljs-string">&quot;translation&quot;</span>, model=model_checkpoint)<br>translator(<span class="hljs-string">&quot;Default to expanded threads&quot;</span>)<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><br>model_checkpoint = <span class="hljs-string">&quot;Helsinki-NLP/opus-mt-en-fr&quot;</span><br>tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br><br><span class="hljs-comment">#tokenizer完成</span><br><br>en_sentence = split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>][<span class="hljs-string">&quot;en&quot;</span>]<br>fr_sentence = split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>][<span class="hljs-string">&quot;fr&quot;</span>]<br><br>inputs = tokenizer(en_sentence, text_target=fr_sentence)<br><br><span class="hljs-comment">#input结果生成</span><br>&#123;<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">47591</span>, <span class="hljs-number">12</span>, <span class="hljs-number">9842</span>, <span class="hljs-number">19634</span>, <span class="hljs-number">9</span>, <span class="hljs-number">0</span>], <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&#x27;labels&#x27;</span>: [<span class="hljs-number">577</span>, <span class="hljs-number">5891</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3184</span>, <span class="hljs-number">16</span>, <span class="hljs-number">2542</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1710</span>, <span class="hljs-number">0</span>]&#125;<br><span class="hljs-comment">#没有理解错误的情况下:input_ids应该用的是对应的每一个单词在语料库的位置,labels对应的法语的位置 #同时这个注意要指定参数</span><br><span class="hljs-built_in">print</span>(tokenizer.convert_ids_to_tokens(inputs[<span class="hljs-string">&quot;labels&quot;</span>])) <span class="hljs-comment">#这里用的是把id转换成tokens的一种函数才能合理的看出是什么东西</span><br><br>max_length = <span class="hljs-number">128</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):<br>    inputs = [ex[<span class="hljs-string">&quot;en&quot;</span>] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;translation&quot;</span>]]<br>    targets = [ex[<span class="hljs-string">&quot;fr&quot;</span>] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;translation&quot;</span>]]<br>    <span class="hljs-comment">#切割</span><br>    model_inputs = tokenizer(<br>        inputs, text_target=targets, max_length=max_length, truncation=<span class="hljs-literal">True</span><br>    )<br>    <span class="hljs-keyword">return</span> model_inputs<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSeq2SeqLM<br><br>model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForSeq2Seq<br><br>data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)<br><span class="hljs-comment">#the padding value used to pad the labels should be -100 and not the padding token of the tokenizer, to make sure those padded values are ignored in the loss computation. it takes the tokenizer used to preprocess the inputs, but it also takes the model. This is because this data collator will also be responsible for preparing the decoder input IDs, which are shifted versions of the labels with a special token at the beginning. Since this shift is done slightly differently for different architectures, the DataCollatorForSeq2Seq needs to know the model object:</span><br><br><span class="hljs-comment">#for ex</span><br>batch = data_collator([tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)])<br>batch.keys()<br>dict_keys([<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;labels&#x27;</span>, <span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>])<br>batch[<span class="hljs-string">&quot;labels&quot;</span>]<br>batch[<span class="hljs-string">&quot;decoder_input_ids&quot;</span>]  <span class="hljs-comment"># see that they are shifted versions of the labels:</span><br><br></code></pre></td></tr></table></figure><h4 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> evaluate<br>metric = evaluate.load(<span class="hljs-string">&quot;sacrebleu&quot;</span>)<br>predictions = [<br>    <span class="hljs-string">&quot;This plugin lets you translate web pages between several languages automatically.&quot;</span><br>]<br>references = [<br>    [<br>        <span class="hljs-string">&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span><br>    ]<br>]<br><span class="hljs-comment"># the predictions should be a list of sentences, but the references should be a list of lists of sentences.</span><br><br>metric.compute(predictions=predictions, references=references)<span class="hljs-comment">#调用函数评判翻译结果的好坏</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_preds</span>):<br>    preds, labels = eval_preds<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(preds,<span class="hljs-built_in">tuple</span>):<span class="hljs-comment">#检查对象类型是不是元组 //一种相关的函数</span><br>        preds = preds[<span class="hljs-number">0</span>]<br>    <br>    decoded_preds = tokenizer.batch_decode(preds,skip_special_toknes = <span class="hljs-literal">True</span>) <span class="hljs-comment">#这里应该是已经完成了替换,所以不需要在这里进行更改</span><br>    labes = np.where(labels != -<span class="hljs-number">100</span>,labels,tokenizer.pad_token_id) <span class="hljs-comment">#分别代表了检索的值,在哪检索,不符合的值替换成什么</span><br>    decoded_labels = tokenizer.batch_decode(labels,skip_special_tokens =<span class="hljs-literal">True</span>)<br><br>    decoded_preds = [pred.strip() <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> decoded_preds] <span class="hljs-comment">#去除字符串两侧的空白字符（包括空格、制表符、换行符等</span><br>    decoded_labels = [[label.strip()] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> decoded_labels]<br><br>    result = metric.compute(predictions=decoded_preds, references=decoded_labels) <span class="hljs-comment">#计算出结果</span><br>    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;bleu&quot;</span>: result[<span class="hljs-string">&quot;score&quot;</span>]&#125;<br></code></pre></td></tr></table></figure><p>评估函数</p><h4 id="Fine-tuning-the-model-1"><a href="#Fine-tuning-the-model-1" class="headerlink" title="Fine-tuning the model"></a>Fine-tuning the model</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainingArguments<br><br>args = Seq2SeqTrainingArguments(<br>    <span class="hljs-string">f&quot;marian-finetuned-kde4-en-to-fr&quot;</span>,<br>    evaluation_strategy=<span class="hljs-string">&quot;no&quot;</span>,<br>    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>    learning_rate=<span class="hljs-number">2e-5</span>,<br>    per_device_train_batch_size=<span class="hljs-number">32</span>,<br>    per_device_eval_batch_size=<span class="hljs-number">64</span>,<br>    weight_decay=<span class="hljs-number">0.01</span>,<br>    save_total_limit=<span class="hljs-number">3</span>,<br>    num_train_epochs=<span class="hljs-number">3</span>,<br>    predict_with_generate=<span class="hljs-literal">True</span>,<br>    fp16=<span class="hljs-literal">True</span>,<br>    push_to_hub=<span class="hljs-literal">True</span>,<br>)<br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainingArguments<br><br>args = Seq2SeqTrainingArguments(<br>    <span class="hljs-string">f&quot;marian-finetuned-kde4-en-to-fr&quot;</span>,<br>    evaluation_strategy=<span class="hljs-string">&quot;no&quot;</span>,<br>    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,<br>    learning_rate=<span class="hljs-number">2e-5</span>,<br>    per_device_train_batch_size=<span class="hljs-number">32</span>,<br>    per_device_eval_batch_size=<span class="hljs-number">64</span>,<br>    weight_decay=<span class="hljs-number">0.01</span>,<br>    save_total_limit=<span class="hljs-number">3</span>,<br>    num_train_epochs=<span class="hljs-number">3</span>,<br>    predict_with_generate=<span class="hljs-literal">True</span>,<br>    fp16=<span class="hljs-literal">True</span>,<span class="hljs-comment">#在GPU上加速训练</span><br>    push_to_hub=<span class="hljs-literal">True</span>,<br>)<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainer<br><br>trainer = Seq2SeqTrainer(<br>    model,<br>    args,<br>    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],<br>    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],<br>    data_collator=data_collator,<br>    tokenizer=tokenizer,<br>    compute_metrics=compute_metrics,<br>)<br></code></pre></td></tr></table></figure><h3 id="summation"><a href="#summation" class="headerlink" title="summation"></a>summation</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python">english_dataset.set_format(<span class="hljs-string">&quot;pandas&quot;</span>)<span class="hljs-comment">#转换数据类型</span><br>english_df = english_dataset[<span class="hljs-string">&quot;train&quot;</span>][:]<br><span class="hljs-comment"># Show counts for top 20 products</span><br>english_df[<span class="hljs-string">&quot;product_category&quot;</span>].value_counts()[:<span class="hljs-number">20</span>]<span class="hljs-comment">#统计出现次数最多的两个</span><br><br><span class="hljs-comment">#数据过滤</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">filter_books</span>(<span class="hljs-params">example</span>):<br>    <span class="hljs-keyword">return</span> (<br>        example[<span class="hljs-string">&quot;product_category&quot;</span>] == <span class="hljs-string">&quot;book&quot;</span><br>        <span class="hljs-keyword">or</span> example[<span class="hljs-string">&quot;product_category&quot;</span>] == <span class="hljs-string">&quot;digital_ebook_purchase&quot;</span><br>    )<br><br>english_dataset.reset_format() <span class="hljs-comment">#重新设置数据的格式</span><br>spanish_books = spanish_dataset.<span class="hljs-built_in">filter</span>(filter_books) <span class="hljs-comment">#应该是利用数据的格式,按照返回值来过滤数据</span><br>english_books = english_dataset.<span class="hljs-built_in">filter</span>(filter_books)<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>NLP_hug</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>c++_learn</title>
    <link href="/2023/07/26/c-learn/"/>
    <url>/2023/07/26/c-learn/</url>
    
    <content type="html"><![CDATA[<h1 id="c-语言的学习"><a href="#c-语言的学习" class="headerlink" title="c++语言的学习"></a>c++语言的学习</h1><h2 id="类"><a href="#类" class="headerlink" title="类"></a>类</h2><p>通过class定义一种类似于结构体的东西,public表示外部可以调取,private定义内部可以调用.同时可以在内部声明一些函数,函数内部可以在外面完成.</p><h2 id="vector-容器"><a href="#vector-容器" class="headerlink" title="vector 容器"></a>vector 容器</h2><h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><ol><li><strong>顺序性</strong>:顺序容器的元素是严格线性的,类似于数组</li><li>动态的数组,可以通过指针操作</li><li>可以感知内存的</li></ol><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3>]]></content>
    
    
    
    <tags>
      
      <tag>c++</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>测试</title>
    <link href="/2023/07/19/%E6%B5%8B%E8%AF%95/"/>
    <url>/2023/07/19/%E6%B5%8B%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<p>测试</p><p>引用方式</p><img src="/2023/07/20/%E6%B5%8B%E8%AF%95/%E6%88%AA%E5%B1%8F.png" class="" title="引用方式1">]]></content>
    
    
    
    <tags>
      
      <tag>for testing</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>helloHexo</title>
    <link href="/2023/07/19/helloHexo/"/>
    <url>/2023/07/19/helloHexo/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/07/19/hello-world/"/>
    <url>/2023/07/19/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
